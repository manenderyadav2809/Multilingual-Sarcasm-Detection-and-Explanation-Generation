{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import string\n",
    "import regex as re\n",
    "import time\n",
    "import torch.optim as optim\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>headline</th>\n",
       "      <th>valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sarcastic</td>\n",
       "      <td>dateline nbc report inspired by actual events</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sarcastic</td>\n",
       "      <td>goldfish dying to be petted just once</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nonsarcastic</td>\n",
       "      <td>scalia's utter moral failure exposed</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nonsarcastic</td>\n",
       "      <td>video captures courthouse beating of inmate ac...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nonsarcastic</td>\n",
       "      <td>bernie sanders has a very lonely but very comm...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          label                                           headline  valid\n",
       "0     sarcastic      dateline nbc report inspired by actual events  False\n",
       "1     sarcastic              goldfish dying to be petted just once  False\n",
       "2  nonsarcastic               scalia's utter moral failure exposed  False\n",
       "3  nonsarcastic  video captures courthouse beating of inmate ac...  False\n",
       "4  nonsarcastic  bernie sanders has a very lonely but very comm...  False"
      ]
     },
     "execution_count": 790,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Headlines.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26709 entries, 0 to 26708\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   label     26709 non-null  object\n",
      " 1   headline  26709 non-null  object\n",
      " 2   valid     26709 non-null  bool  \n",
      "dtypes: bool(1), object(2)\n",
      "memory usage: 443.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>headline</th>\n",
       "      <th>valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sarcastic</td>\n",
       "      <td>dateline nbc report inspired by actual events</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sarcastic</td>\n",
       "      <td>goldfish dying to be petted just once</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nonsarcastic</td>\n",
       "      <td>scalia's utter moral failure exposed</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nonsarcastic</td>\n",
       "      <td>video captures courthouse beating of inmate ac...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nonsarcastic</td>\n",
       "      <td>bernie sanders has a very lonely but very comm...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26704</th>\n",
       "      <td>nonsarcastic</td>\n",
       "      <td>kim kardashian channels cruella de vil, plus m...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26705</th>\n",
       "      <td>sarcastic</td>\n",
       "      <td>students thankful standardized curriculum spar...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26706</th>\n",
       "      <td>sarcastic</td>\n",
       "      <td>mortgage market collapse threatens nation's ba...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26707</th>\n",
       "      <td>nonsarcastic</td>\n",
       "      <td>the outrageous dessert you can make in a slow ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26708</th>\n",
       "      <td>nonsarcastic</td>\n",
       "      <td>michelle obama hails 'black panther' for inspi...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26709 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              label                                           headline  valid\n",
       "0         sarcastic      dateline nbc report inspired by actual events  False\n",
       "1         sarcastic              goldfish dying to be petted just once  False\n",
       "2      nonsarcastic               scalia's utter moral failure exposed  False\n",
       "3      nonsarcastic  video captures courthouse beating of inmate ac...  False\n",
       "4      nonsarcastic  bernie sanders has a very lonely but very comm...  False\n",
       "...             ...                                                ...    ...\n",
       "26704  nonsarcastic  kim kardashian channels cruella de vil, plus m...   True\n",
       "26705     sarcastic  students thankful standardized curriculum spar...   True\n",
       "26706     sarcastic  mortgage market collapse threatens nation's ba...   True\n",
       "26707  nonsarcastic  the outrageous dessert you can make in a slow ...   True\n",
       "26708  nonsarcastic  michelle obama hails 'black panther' for inspi...   True\n",
       "\n",
       "[26709 rows x 3 columns]"
      ]
     },
     "execution_count": 792,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(df[\"label\"])\n",
    "headlines = list(df[\"headline\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dateline nbc report inspired by actual events',\n",
       " 'goldfish dying to be petted just once',\n",
       " \"scalia's utter moral failure exposed\",\n",
       " 'video captures courthouse beating of inmate accused of killing chicago child',\n",
       " 'bernie sanders has a very lonely but very committed following on wall street',\n",
       " 'yoga, mindfulness and weight management',\n",
       " 'gwen stefani teases possible no doubt album',\n",
       " 'an invitation to do something about the environment',\n",
       " \"'mr. falafel' owner does not actually like being addressed as mr. falafel\",\n",
       " 'new york bomber sought an isis-inspired attack with failed device, investigators say']"
      ]
     },
     "execution_count": 794,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = int(0.8*len(headlines))\n",
    "val_len = int(0.1*len(headlines))\n",
    "train_labels = labels[:train_len]\n",
    "val_labels = labels[train_len:train_len+val_len]\n",
    "test_labels = labels[train_len+val_len:]\n",
    "train_data = headlines[:train_len]\n",
    "val_data = headlines[train_len:train_len+val_len]\n",
    "test_data = headlines[train_len+val_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21367 2670 2672\n",
      "20513 2558 2565\n",
      "20513 2558 2565\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data), len(val_data), len(test_data))\n",
    "# remove sentences longer than 15 words\n",
    "def remove_long_sentences(data, labels):\n",
    "    new_data = []\n",
    "    new_labels = []\n",
    "    for i in range(len(data)):\n",
    "        words = data[i].split()\n",
    "        if len(words) <= 15:\n",
    "            new_data.append(data[i])\n",
    "            new_labels.append(labels[i])\n",
    "\n",
    "    return new_data, new_labels\n",
    "\n",
    "train_data, train_labels = remove_long_sentences(train_data, train_labels)\n",
    "val_data, val_labels = remove_long_sentences(val_data, val_labels)\n",
    "test_data, test_labels = remove_long_sentences(test_data, test_labels)\n",
    "\n",
    "label_mapping = {'sarcastic': 0, 'nonsarcastic': 1}   # 0 for sarcastic, 1 for non-sarcastic\n",
    "train_labels = [label_mapping[label] for label in train_labels]\n",
    "val_labels = [label_mapping[label] for label in val_labels]\n",
    "test_labels = [label_mapping[label] for label in test_labels]\n",
    "\n",
    "\n",
    "print(len(train_data), len(val_data), len(test_data))\n",
    "print(len(train_labels), len(val_labels), len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(sent):\n",
    "    sent = sent.encode('ascii', 'ignore').decode('ascii')           \n",
    "    sent = re.sub(r'https?:\\/\\/\\S+', '', sent)\n",
    "    sent = re.sub(r\"www\\.[a-z]?\\.?(com)+|[a-z]+\\.(com)\", '', sent)\n",
    "    sent = re.sub(\"#[A-Za-z0-9_]+\", '', sent)\n",
    "    sent = re.sub(\"[0-9_]+\", \"\", sent)\n",
    "    sent = re.sub(r\"[^\\w\\s\\0-9.]+|\\.(?=.*\\.)\", \"\", sent)\n",
    "    sent = re.sub(r'[^\\w\\s]', \" \", sent)\n",
    "    sent = re.sub(' +', ' ', sent)\n",
    "    sent = re.sub(r\"^\\s+|\\s+$\", \"\", sent)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(headlines,g_dict, labels):\n",
    "    final_tokenized_data=[]\n",
    "    final_labels = []\n",
    "    # for string in headlines:\n",
    "    #     sentences = sent_tokenize(string)\n",
    "    #     for line in sentences:\n",
    "    #         temp_line = clean_data(line.lower())\n",
    "    #         tokens = word_tokenize(temp_line)\n",
    "    #         for i, word in enumerate(tokens):\n",
    "    #             if word not in g_dict.keys():\n",
    "    #                 tokens[i]= \"<unk>\"\n",
    "    #         tokens = ['<sos>']+tokens+['<eos>']\n",
    "    #         final_tokenized_data.append(tokens)\n",
    "    # return final_tokenized_data\n",
    "    for i in range(len(headlines)):\n",
    "        temp_line = clean_data(headlines[i].lower())\n",
    "        tokens = word_tokenize(temp_line)\n",
    "        for j, word in enumerate(tokens):\n",
    "            if word not in g_dict.keys():\n",
    "                tokens[j]= \"<unk>\"\n",
    "        tokens = ['<sos>']+tokens+['<eos>']\n",
    "        final_tokenized_data.append(tokens)\n",
    "        final_labels.append(labels[i])\n",
    "    return final_tokenized_data, final_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_for_cls(headlines,g_dict):\n",
    "    final_tokenized_data=[]\n",
    "    for string in headlines:\n",
    "        temp_line = clean_data(string.lower())\n",
    "        tokens = word_tokenize(temp_line)\n",
    "        for i, word in enumerate(tokens):\n",
    "            if word not in g_dict.keys():\n",
    "                tokens[i]= \"<unk>\"\n",
    "        final_tokenized_data.append(tokens)\n",
    "    return final_tokenized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_dict = {}\n",
    "wordtoint_glove = {}\n",
    "inttoword_glove = {}\n",
    "count = 0\n",
    "with open(\"archive/glove.6B.50d.txt\",\"r\") as f:\n",
    "    for line in f:\n",
    "        glove_sent = line.split(' ')\n",
    "        key = glove_sent[0]\n",
    "        value = glove_sent[1:]\n",
    "        value = list(map(float, value))\n",
    "        glove_dict[key] = value\n",
    "        wordtoint_glove[key] = count\n",
    "        inttoword_glove[count] = key\n",
    "        count += 1\n",
    "\n",
    "glove_dict[\"<unk>\"] = np.zeros(50)\n",
    "glove_dict[\"<sos>\"] = np.ones(50)\n",
    "glove_dict[\"<eos>\"] = np.ones(50)*2\n",
    "glove_dict[\"<pad>\"] = np.ones(50)*3\n",
    "\n",
    "wordtoint_glove[\"<unk>\"] = count\n",
    "inttoword_glove[count] = \"<unk>\"\n",
    "count+=1\n",
    "wordtoint_glove[\"<sos>\"] = count\n",
    "inttoword_glove[count] = \"<sos>\"\n",
    "count+=1\n",
    "wordtoint_glove[\"<eos>\"] = count\n",
    "inttoword_glove[count] = \"<eos>\"\n",
    "count+=1\n",
    "wordtoint_glove[\"<pad>\"] = count\n",
    "inttoword_glove[count] = \"<pad>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20513 2558 2565\n",
      "20513 2558 2565\n",
      "20513 2558 2565\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data), len(val_data), len(test_data))\n",
    "\n",
    "final_train_data, final_train_labels = pre_process(train_data, glove_dict, train_labels)\n",
    "final_val_data, final_val_labels = pre_process(val_data, glove_dict, val_labels)\n",
    "final_test_data, final_test_labels = pre_process(test_data, glove_dict, test_labels)\n",
    "\n",
    "print(len(final_train_data), len(final_val_data), len(final_test_data))\n",
    "print(len(final_train_labels), len(final_val_labels), len(final_test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<sos>',\n",
       "  'dateline',\n",
       "  'nbc',\n",
       "  'report',\n",
       "  'inspired',\n",
       "  'by',\n",
       "  'actual',\n",
       "  'events',\n",
       "  '<eos>'],\n",
       " ['<sos>', 'goldfish', 'dying', 'to', 'be', 'petted', 'just', 'once', '<eos>'],\n",
       " ['<sos>', 'scalia', 's', 'utter', 'moral', 'failure', 'exposed', '<eos>'],\n",
       " ['<sos>',\n",
       "  'video',\n",
       "  'captures',\n",
       "  'courthouse',\n",
       "  'beating',\n",
       "  'of',\n",
       "  'inmate',\n",
       "  'accused',\n",
       "  'of',\n",
       "  'killing',\n",
       "  'chicago',\n",
       "  'child',\n",
       "  '<eos>'],\n",
       " ['<sos>',\n",
       "  'bernie',\n",
       "  'sanders',\n",
       "  'has',\n",
       "  'a',\n",
       "  'very',\n",
       "  'lonely',\n",
       "  'but',\n",
       "  'very',\n",
       "  'committed',\n",
       "  'following',\n",
       "  'on',\n",
       "  'wall',\n",
       "  'street',\n",
       "  '<eos>']]"
      ]
     },
     "execution_count": 802,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_train_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_vocab = []\n",
    "for line in final_train_data:\n",
    "    list_vocab.extend(line)\n",
    "    \n",
    "array_vocab = np.array(list_vocab)\n",
    "vocab, frequency_words = np.unique(array_vocab, return_counts=True)\n",
    "\n",
    "vocab_dict = {}\n",
    "count=0\n",
    "for i in range(len(vocab)):\n",
    "    if frequency_words[i]>3:\n",
    "        vocab_dict[vocab[i]] = count\n",
    "        count+=1\n",
    "\n",
    "vocab_dict[\"<pad>\"] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding\n",
    "def padding(sentences):\n",
    "    max_len = 0\n",
    "    for sent in sentences:\n",
    "        if len(sent)>max_len:\n",
    "            max_len = len(sent)\n",
    "    for i, sent in enumerate(sentences):\n",
    "        if len(sent)<max_len:\n",
    "            sentences[i] = sent + ['<pad>']*(max_len-len(sent))\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20513 2558 2565\n",
      "[['<sos>', 'dateline', 'nbc', 'report', 'inspired', 'by', 'actual', 'events', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'goldfish', 'dying', 'to', 'be', 'petted', 'just', 'once', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'scalia', 's', 'utter', 'moral', 'failure', 'exposed', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'video', 'captures', 'courthouse', 'beating', 'of', 'inmate', 'accused', 'of', 'killing', 'chicago', 'child', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<sos>', 'bernie', 'sanders', 'has', 'a', 'very', 'lonely', 'but', 'very', 'committed', 'following', 'on', 'wall', 'street', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']]\n"
     ]
    }
   ],
   "source": [
    "# in final_train_data, pad all the sentences\n",
    "final_train_data = padding(final_train_data)\n",
    "final_val_data = padding(final_val_data)\n",
    "final_test_data = padding(final_test_data)\n",
    "\n",
    "print(len(final_train_data), len(final_val_data), len(final_test_data))\n",
    "print(final_train_data[:5])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, labels, wordtoint, inttoword):\n",
    "        self.data = data\n",
    "        self.wordtoint = wordtoint\n",
    "        self.inttoword = inttoword\n",
    "        self.labels = labels\n",
    "        words_sentences = []\n",
    "        for sentence in self.data:\n",
    "            words = [word if word in self.wordtoint else \"<unk>\" for word in sentence]\n",
    "            words_sentences.append(words)\n",
    "\n",
    "        self.words_sentences = words_sentences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.words_sentences)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x = torch.tensor([self.wordtoint[word] for word in self.words_sentences[index]])\n",
    "        y = torch.tensor(self.labels[index])\n",
    "        return x, y  # Return a one-dimensional target tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "# print(len(final_train_data), len(train_labels), len(final_val_data), len(val_labels), len(final_test_data), len(test_labels))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(Dataset(final_train_data, final_train_labels, vocab_dict, inttoword_glove), batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(Dataset(final_val_data, final_val_labels, vocab_dict, inttoword_glove), batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(Dataset(final_test_data, final_test_labels, vocab_dict, inttoword_glove), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 600\n",
    "embedding_size = 600\n",
    "num_layers = 1\n",
    "num_classes = 2\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        out, (h_n, c_n) = self.lstm(x)\n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(len(vocab_dict), hidden_size, num_classes, num_layers).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, num_epochs, optimizer, criterion):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            # print(\"Output shape:\", output.shape)\n",
    "            # print(\"Target shape:\", target.shape)\n",
    "            loss = criterion(output.squeeze(), target)\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total += target.size(0)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            correct += (predicted == target).sum().item()\n",
    "            print(\"Epoch: {}, Batch: {}, Loss: {}, Accuracy: {}\".format(epoch, batch_idx, loss.item(), (correct/total)*100))\n",
    "        train_losses.append(total_loss/len(train_loader))\n",
    "        train_acc.append((correct/total)*100)\n",
    "        print(\"Epoch: {}, Training Loss: {}\".format(epoch, total_loss/len(train_loader)))\n",
    "        val_loss = 0\n",
    "        val_total = 0\n",
    "        val_correct = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(val_loader):\n",
    "                data = data.to(device)\n",
    "                target = target.to(device)\n",
    "                output = model(data)\n",
    "                loss = criterion(output.squeeze(), target)\n",
    "                val_loss += loss.item()\n",
    "                val_total += target.size(0)\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                val_correct += (predicted == target).sum().item()\n",
    "            val_losses.append(val_loss/len(val_loader))\n",
    "            val_acc.append((val_correct/val_total)*100)\n",
    "            print(\"Epoch: {}, Validation Loss: {}, Validation Accuracy: {}\".format(epoch, val_loss/len(val_loader), (val_correct/val_total)*100))\n",
    "    return train_losses, val_losses, train_acc, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 0, Loss: 0.6936159729957581, Accuracy: 42.96875\n",
      "Epoch: 0, Batch: 1, Loss: 2.1822524070739746, Accuracy: 47.65625\n",
      "Epoch: 0, Batch: 2, Loss: 1.0162992477416992, Accuracy: 51.041666666666664\n",
      "Epoch: 0, Batch: 3, Loss: 0.6782487034797668, Accuracy: 53.515625\n",
      "Epoch: 0, Batch: 4, Loss: 0.8161976933479309, Accuracy: 50.15625\n",
      "Epoch: 0, Batch: 5, Loss: 0.753948450088501, Accuracy: 49.21875\n",
      "Epoch: 0, Batch: 6, Loss: 0.7301640510559082, Accuracy: 48.10267857142857\n",
      "Epoch: 0, Batch: 7, Loss: 0.7004614472389221, Accuracy: 47.265625\n",
      "Epoch: 0, Batch: 8, Loss: 0.6883935928344727, Accuracy: 48.09027777777778\n",
      "Epoch: 0, Batch: 9, Loss: 0.6889710426330566, Accuracy: 48.75\n",
      "Epoch: 0, Batch: 10, Loss: 0.6490573883056641, Accuracy: 50.42613636363637\n",
      "Epoch: 0, Batch: 11, Loss: 0.6752417087554932, Accuracy: 51.171875\n",
      "Epoch: 0, Batch: 12, Loss: 0.7025417685508728, Accuracy: 51.38221153846154\n",
      "Epoch: 0, Batch: 13, Loss: 0.7064882516860962, Accuracy: 51.5625\n",
      "Epoch: 0, Batch: 14, Loss: 0.6894631385803223, Accuracy: 51.927083333333336\n",
      "Epoch: 0, Batch: 15, Loss: 0.6847741603851318, Accuracy: 52.294921875\n",
      "Epoch: 0, Batch: 16, Loss: 0.7129676342010498, Accuracy: 52.29779411764706\n",
      "Epoch: 0, Batch: 17, Loss: 0.710905134677887, Accuracy: 52.30034722222222\n",
      "Epoch: 0, Batch: 18, Loss: 0.6624922156333923, Accuracy: 52.83717105263158\n",
      "Epoch: 0, Batch: 19, Loss: 0.6623893976211548, Accuracy: 53.3203125\n",
      "Epoch: 0, Batch: 20, Loss: 0.6974524259567261, Accuracy: 53.311011904761905\n",
      "Epoch: 0, Batch: 21, Loss: 0.6811079382896423, Accuracy: 53.515625\n",
      "Epoch: 0, Batch: 22, Loss: 0.6734734773635864, Accuracy: 53.80434782608695\n",
      "Epoch: 0, Batch: 23, Loss: 0.6854538321495056, Accuracy: 53.90625\n",
      "Epoch: 0, Batch: 24, Loss: 0.6721254587173462, Accuracy: 54.1875\n",
      "Epoch: 0, Batch: 25, Loss: 0.676857590675354, Accuracy: 54.387019230769226\n",
      "Epoch: 0, Batch: 26, Loss: 0.6752731204032898, Accuracy: 54.60069444444444\n",
      "Epoch: 0, Batch: 27, Loss: 0.6773045063018799, Accuracy: 54.77120535714286\n",
      "Epoch: 0, Batch: 28, Loss: 0.6907806396484375, Accuracy: 54.741379310344826\n",
      "Epoch: 0, Batch: 29, Loss: 0.7093106508255005, Accuracy: 54.479166666666664\n",
      "Epoch: 0, Batch: 30, Loss: 0.6850830912590027, Accuracy: 54.53629032258065\n",
      "Epoch: 0, Batch: 31, Loss: 0.6926779747009277, Accuracy: 54.4921875\n",
      "Epoch: 0, Batch: 32, Loss: 0.6886840462684631, Accuracy: 54.498106060606055\n",
      "Epoch: 0, Batch: 33, Loss: 0.6751721501350403, Accuracy: 54.6875\n",
      "Epoch: 0, Batch: 34, Loss: 0.6759717464447021, Accuracy: 54.86607142857143\n",
      "Epoch: 0, Batch: 35, Loss: 0.679205596446991, Accuracy: 54.99131944444444\n",
      "Epoch: 0, Batch: 36, Loss: 0.6893694400787354, Accuracy: 54.96199324324324\n",
      "Epoch: 0, Batch: 37, Loss: 0.68571937084198, Accuracy: 54.99588815789473\n",
      "Epoch: 0, Batch: 38, Loss: 0.6711257696151733, Accuracy: 55.18830128205128\n",
      "Epoch: 0, Batch: 39, Loss: 0.6944646835327148, Accuracy: 55.1171875\n",
      "Epoch: 0, Batch: 40, Loss: 0.6624065637588501, Accuracy: 55.35442073170732\n",
      "Epoch: 0, Batch: 41, Loss: 0.6538646817207336, Accuracy: 55.654761904761905\n",
      "Epoch: 0, Batch: 42, Loss: 0.6631853580474854, Accuracy: 55.850290697674424\n",
      "Epoch: 0, Batch: 43, Loss: 0.6987214088439941, Accuracy: 55.77059659090909\n",
      "Epoch: 0, Batch: 44, Loss: 0.6829069256782532, Accuracy: 55.79861111111111\n",
      "Epoch: 0, Batch: 45, Loss: 0.672482430934906, Accuracy: 55.893342391304344\n",
      "Epoch: 0, Batch: 46, Loss: 0.6803410053253174, Accuracy: 55.934175531914896\n",
      "Epoch: 0, Batch: 47, Loss: 0.6716181039810181, Accuracy: 56.022135416666664\n",
      "Epoch: 0, Batch: 48, Loss: 0.7066762447357178, Accuracy: 55.94706632653062\n",
      "Epoch: 0, Batch: 49, Loss: 0.702205240726471, Accuracy: 55.89062500000001\n",
      "Epoch: 0, Batch: 50, Loss: 0.6794618368148804, Accuracy: 55.943627450980394\n",
      "Epoch: 0, Batch: 51, Loss: 0.6941230893135071, Accuracy: 55.91947115384615\n",
      "Epoch: 0, Batch: 52, Loss: 0.6911725997924805, Accuracy: 55.91096698113207\n",
      "Epoch: 0, Batch: 53, Loss: 0.7051228880882263, Accuracy: 55.844907407407405\n",
      "Epoch: 0, Batch: 54, Loss: 0.6723570823669434, Accuracy: 55.92329545454545\n",
      "Epoch: 0, Batch: 55, Loss: 0.6885340809822083, Accuracy: 55.91517857142857\n",
      "Epoch: 0, Batch: 56, Loss: 0.7014833688735962, Accuracy: 55.838815789473685\n",
      "Epoch: 0, Batch: 57, Loss: 0.6850075721740723, Accuracy: 55.832435344827594\n",
      "Epoch: 0, Batch: 58, Loss: 0.6929112076759338, Accuracy: 55.79978813559322\n",
      "Epoch: 0, Batch: 59, Loss: 0.6755549311637878, Accuracy: 55.872395833333336\n",
      "Epoch: 0, Batch: 60, Loss: 0.6820622682571411, Accuracy: 55.917008196721305\n",
      "Epoch: 0, Batch: 61, Loss: 0.6795960068702698, Accuracy: 55.97278225806451\n",
      "Epoch: 0, Batch: 62, Loss: 0.6826331615447998, Accuracy: 56.01438492063492\n",
      "Epoch: 0, Batch: 63, Loss: 0.6804316639900208, Accuracy: 56.0546875\n",
      "Epoch: 0, Batch: 64, Loss: 0.7003806829452515, Accuracy: 55.93749999999999\n",
      "Epoch: 0, Batch: 65, Loss: 0.6953447461128235, Accuracy: 55.859375\n",
      "Epoch: 0, Batch: 66, Loss: 0.6880247592926025, Accuracy: 55.83022388059702\n",
      "Epoch: 0, Batch: 67, Loss: 0.6817735433578491, Accuracy: 55.84788602941176\n",
      "Epoch: 0, Batch: 68, Loss: 0.6903780698776245, Accuracy: 55.79710144927537\n",
      "Epoch: 0, Batch: 69, Loss: 0.6867293119430542, Accuracy: 55.825892857142854\n",
      "Epoch: 0, Batch: 70, Loss: 0.6805107593536377, Accuracy: 55.8868838028169\n",
      "Epoch: 0, Batch: 71, Loss: 0.6841895580291748, Accuracy: 55.90277777777778\n",
      "Epoch: 0, Batch: 72, Loss: 0.6869543790817261, Accuracy: 55.90753424657534\n",
      "Epoch: 0, Batch: 73, Loss: 0.6884940266609192, Accuracy: 55.891047297297305\n",
      "Epoch: 0, Batch: 74, Loss: 0.6831141710281372, Accuracy: 55.91666666666667\n",
      "Epoch: 0, Batch: 75, Loss: 0.6811364889144897, Accuracy: 55.94161184210527\n",
      "Epoch: 0, Batch: 76, Loss: 0.6888406872749329, Accuracy: 55.91517857142857\n",
      "Epoch: 0, Batch: 77, Loss: 0.6818389296531677, Accuracy: 55.92948717948718\n",
      "Epoch: 0, Batch: 78, Loss: 0.6935315728187561, Accuracy: 55.89398734177215\n",
      "Epoch: 0, Batch: 79, Loss: 0.6701997518539429, Accuracy: 55.97656250000001\n",
      "Epoch: 0, Batch: 80, Loss: 0.6879801750183105, Accuracy: 55.970293209876544\n",
      "Epoch: 0, Batch: 81, Loss: 0.66370689868927, Accuracy: 56.05945121951219\n",
      "Epoch: 0, Batch: 82, Loss: 0.6604171991348267, Accuracy: 56.1558734939759\n",
      "Epoch: 0, Batch: 83, Loss: 0.6816078424453735, Accuracy: 56.147693452380956\n",
      "Epoch: 0, Batch: 84, Loss: 0.6533194780349731, Accuracy: 56.25\n",
      "Epoch: 0, Batch: 85, Loss: 0.6979865431785583, Accuracy: 56.17732558139535\n",
      "Epoch: 0, Batch: 86, Loss: 0.666770339012146, Accuracy: 56.223060344827594\n",
      "Epoch: 0, Batch: 87, Loss: 0.6576905250549316, Accuracy: 56.29438920454546\n",
      "Epoch: 0, Batch: 88, Loss: 0.6681273579597473, Accuracy: 56.32900280898876\n",
      "Epoch: 0, Batch: 89, Loss: 0.667636513710022, Accuracy: 56.36284722222222\n",
      "Epoch: 0, Batch: 90, Loss: 0.6920257210731506, Accuracy: 56.31009615384615\n",
      "Epoch: 0, Batch: 91, Loss: 0.6652047634124756, Accuracy: 56.300951086956516\n",
      "Epoch: 0, Batch: 92, Loss: 0.6486125588417053, Accuracy: 56.342405913978496\n",
      "Epoch: 0, Batch: 93, Loss: 0.6634902954101562, Accuracy: 56.34973404255319\n",
      "Epoch: 0, Batch: 94, Loss: 0.6321756839752197, Accuracy: 56.42269736842105\n",
      "Epoch: 0, Batch: 95, Loss: 0.6585026979446411, Accuracy: 56.429036458333336\n",
      "Epoch: 0, Batch: 96, Loss: 0.6469973921775818, Accuracy: 56.45940721649485\n",
      "Epoch: 0, Batch: 97, Loss: 0.666044294834137, Accuracy: 56.449298469387756\n",
      "Epoch: 0, Batch: 98, Loss: 0.6425458192825317, Accuracy: 56.502525252525245\n",
      "Epoch: 0, Batch: 99, Loss: 0.6422667503356934, Accuracy: 56.52343749999999\n",
      "Epoch: 0, Batch: 100, Loss: 0.6692619919776917, Accuracy: 56.51299504950495\n",
      "Epoch: 0, Batch: 101, Loss: 0.6858627796173096, Accuracy: 56.41850490196079\n",
      "Epoch: 0, Batch: 102, Loss: 0.651340126991272, Accuracy: 56.447208737864074\n",
      "Epoch: 0, Batch: 103, Loss: 0.6214287877082825, Accuracy: 56.51292067307693\n",
      "Epoch: 0, Batch: 104, Loss: 0.635633111000061, Accuracy: 56.5327380952381\n",
      "Epoch: 0, Batch: 105, Loss: 0.6360992789268494, Accuracy: 56.55955188679245\n",
      "Epoch: 0, Batch: 106, Loss: 0.6026703715324402, Accuracy: 56.63697429906542\n",
      "Epoch: 0, Batch: 107, Loss: 0.657243013381958, Accuracy: 56.655092592592595\n",
      "Epoch: 0, Batch: 108, Loss: 0.6537639498710632, Accuracy: 56.644208715596335\n",
      "Epoch: 0, Batch: 109, Loss: 0.6327658891677856, Accuracy: 56.74005681818181\n",
      "Epoch: 0, Batch: 110, Loss: 0.6206795573234558, Accuracy: 56.87640765765766\n",
      "Epoch: 0, Batch: 111, Loss: 0.606553316116333, Accuracy: 57.02427455357143\n",
      "Epoch: 0, Batch: 112, Loss: 0.6158126592636108, Accuracy: 57.12112831858407\n",
      "Epoch: 0, Batch: 113, Loss: 0.6298679709434509, Accuracy: 57.20942982456141\n",
      "Epoch: 0, Batch: 114, Loss: 0.6029600501060486, Accuracy: 57.37771739130435\n",
      "Epoch: 0, Batch: 115, Loss: 0.5938670635223389, Accuracy: 57.48922413793104\n",
      "Epoch: 0, Batch: 116, Loss: 0.5822345614433289, Accuracy: 57.66559829059828\n",
      "Epoch: 0, Batch: 117, Loss: 0.5595158338546753, Accuracy: 57.85222457627118\n",
      "Epoch: 0, Batch: 118, Loss: 0.5587694644927979, Accuracy: 58.00945378151261\n",
      "Epoch: 0, Batch: 119, Loss: 0.5719761252403259, Accuracy: 58.15104166666667\n",
      "Epoch: 0, Batch: 120, Loss: 0.5976976752281189, Accuracy: 58.24509297520662\n",
      "Epoch: 0, Batch: 121, Loss: 0.5828756093978882, Accuracy: 58.356813524590166\n",
      "Epoch: 0, Batch: 122, Loss: 0.5664767026901245, Accuracy: 58.492123983739845\n",
      "Epoch: 0, Batch: 123, Loss: 0.5621750950813293, Accuracy: 58.62525201612904\n",
      "Epoch: 0, Batch: 124, Loss: 0.5444977879524231, Accuracy: 58.768750000000004\n",
      "Epoch: 0, Batch: 125, Loss: 0.5844936370849609, Accuracy: 58.860367063492056\n",
      "Epoch: 0, Batch: 126, Loss: 0.5700229406356812, Accuracy: 58.96899606299213\n",
      "Epoch: 0, Batch: 127, Loss: 0.5516195893287659, Accuracy: 59.075927734375\n",
      "Epoch: 0, Batch: 128, Loss: 0.5238645076751709, Accuracy: 59.21753875968992\n",
      "Epoch: 0, Batch: 129, Loss: 0.5744486451148987, Accuracy: 59.33293269230769\n",
      "Epoch: 0, Batch: 130, Loss: 0.5585251450538635, Accuracy: 59.422709923664115\n",
      "Epoch: 0, Batch: 131, Loss: 0.6517991423606873, Accuracy: 59.47561553030303\n",
      "Epoch: 0, Batch: 132, Loss: 0.5489760637283325, Accuracy: 59.57471804511278\n",
      "Epoch: 0, Batch: 133, Loss: 0.5336489677429199, Accuracy: 59.70149253731343\n",
      "Epoch: 0, Batch: 134, Loss: 0.5894089937210083, Accuracy: 59.79745370370371\n",
      "Epoch: 0, Batch: 135, Loss: 0.5219331383705139, Accuracy: 59.94944852941176\n",
      "Epoch: 0, Batch: 136, Loss: 0.49723905324935913, Accuracy: 60.08211678832117\n",
      "Epoch: 0, Batch: 137, Loss: 0.4784882962703705, Accuracy: 60.207201086956516\n",
      "Epoch: 0, Batch: 138, Loss: 0.5121861696243286, Accuracy: 60.34172661870504\n",
      "Epoch: 0, Batch: 139, Loss: 0.5349069833755493, Accuracy: 60.44642857142857\n",
      "Epoch: 0, Batch: 140, Loss: 0.5019044280052185, Accuracy: 60.57734929078015\n",
      "Epoch: 0, Batch: 141, Loss: 0.5430554151535034, Accuracy: 60.651408450704224\n",
      "Epoch: 0, Batch: 142, Loss: 0.510009765625, Accuracy: 60.76267482517482\n",
      "Epoch: 0, Batch: 143, Loss: 0.4983564019203186, Accuracy: 60.87782118055556\n",
      "Epoch: 0, Batch: 144, Loss: 0.5245095491409302, Accuracy: 60.959051724137936\n",
      "Epoch: 0, Batch: 145, Loss: 0.41002169251441956, Accuracy: 61.119434931506845\n",
      "Epoch: 0, Batch: 146, Loss: 0.445449560880661, Accuracy: 61.256377551020414\n",
      "Epoch: 0, Batch: 147, Loss: 0.4906654357910156, Accuracy: 61.370354729729726\n",
      "Epoch: 0, Batch: 148, Loss: 0.4674818813800812, Accuracy: 61.48280201342282\n",
      "Epoch: 0, Batch: 149, Loss: 0.4787355363368988, Accuracy: 61.59375\n",
      "Epoch: 0, Batch: 150, Loss: 0.5039169192314148, Accuracy: 61.67735927152318\n",
      "Epoch: 0, Batch: 151, Loss: 0.49453407526016235, Accuracy: 61.75472861842105\n",
      "Epoch: 0, Batch: 152, Loss: 0.49597951769828796, Accuracy: 61.84640522875817\n",
      "Epoch: 0, Batch: 153, Loss: 0.41572442650794983, Accuracy: 61.962256493506494\n",
      "Epoch: 0, Batch: 154, Loss: 0.44965919852256775, Accuracy: 62.086693548387096\n",
      "Epoch: 0, Batch: 155, Loss: 0.5881927013397217, Accuracy: 62.13441506410257\n",
      "Epoch: 0, Batch: 156, Loss: 0.4609392583370209, Accuracy: 62.23626592356688\n",
      "Epoch: 0, Batch: 157, Loss: 0.42200297117233276, Accuracy: 62.37143987341772\n",
      "Epoch: 0, Batch: 158, Loss: 0.5137225389480591, Accuracy: 62.43612421383647\n",
      "Epoch: 0, Batch: 159, Loss: 0.440310537815094, Accuracy: 62.54394531250001\n",
      "Epoch: 0, Batch: 160, Loss: 0.4005965292453766, Accuracy: 62.58470238385414\n",
      "Epoch: 0, Training Loss: 0.6438525174715504\n",
      "Epoch: 0, Validation Loss: 0.4588153839111328, Validation Accuracy: 78.81157154026583\n",
      "Epoch: 1, Batch: 0, Loss: 0.42394784092903137, Accuracy: 81.25\n",
      "Epoch: 1, Batch: 1, Loss: 0.384344220161438, Accuracy: 82.421875\n",
      "Epoch: 1, Batch: 2, Loss: 0.4588530659675598, Accuracy: 81.77083333333334\n",
      "Epoch: 1, Batch: 3, Loss: 0.41944578289985657, Accuracy: 82.2265625\n",
      "Epoch: 1, Batch: 4, Loss: 0.323310911655426, Accuracy: 83.59375\n",
      "Epoch: 1, Batch: 5, Loss: 0.39763903617858887, Accuracy: 83.33333333333334\n",
      "Epoch: 1, Batch: 6, Loss: 0.4140281081199646, Accuracy: 83.25892857142857\n",
      "Epoch: 1, Batch: 7, Loss: 0.48855265974998474, Accuracy: 82.421875\n",
      "Epoch: 1, Batch: 8, Loss: 0.4185926020145416, Accuracy: 82.29166666666666\n",
      "Epoch: 1, Batch: 9, Loss: 0.40914589166641235, Accuracy: 82.265625\n",
      "Epoch: 1, Batch: 10, Loss: 0.4060616195201874, Accuracy: 82.03125\n",
      "Epoch: 1, Batch: 11, Loss: 0.4250779449939728, Accuracy: 81.90104166666666\n",
      "Epoch: 1, Batch: 12, Loss: 0.47703540325164795, Accuracy: 81.55048076923077\n",
      "Epoch: 1, Batch: 13, Loss: 0.3257182538509369, Accuracy: 82.03125\n",
      "Epoch: 1, Batch: 14, Loss: 0.3631550371646881, Accuracy: 82.08333333333333\n",
      "Epoch: 1, Batch: 15, Loss: 0.3993670642375946, Accuracy: 81.982421875\n",
      "Epoch: 1, Batch: 16, Loss: 0.3923301100730896, Accuracy: 81.98529411764706\n",
      "Epoch: 1, Batch: 17, Loss: 0.4285268485546112, Accuracy: 81.98784722222221\n",
      "Epoch: 1, Batch: 18, Loss: 0.46992984414100647, Accuracy: 81.94901315789474\n",
      "Epoch: 1, Batch: 19, Loss: 0.38341695070266724, Accuracy: 82.1484375\n",
      "Epoch: 1, Batch: 20, Loss: 0.4406541585922241, Accuracy: 82.06845238095238\n",
      "Epoch: 1, Batch: 21, Loss: 0.34523507952690125, Accuracy: 82.24431818181817\n",
      "Epoch: 1, Batch: 22, Loss: 0.42985543608665466, Accuracy: 82.30298913043478\n",
      "Epoch: 1, Batch: 23, Loss: 0.48289012908935547, Accuracy: 82.16145833333334\n",
      "Epoch: 1, Batch: 24, Loss: 0.31675684452056885, Accuracy: 82.25\n",
      "Epoch: 1, Batch: 25, Loss: 0.4523904025554657, Accuracy: 82.12139423076923\n",
      "Epoch: 1, Batch: 26, Loss: 0.4016069173812866, Accuracy: 82.17592592592592\n",
      "Epoch: 1, Batch: 27, Loss: 0.35333386063575745, Accuracy: 82.28236607142857\n",
      "Epoch: 1, Batch: 28, Loss: 0.44169360399246216, Accuracy: 82.19288793103449\n",
      "Epoch: 1, Batch: 29, Loss: 0.38536491990089417, Accuracy: 82.23958333333333\n",
      "Epoch: 1, Batch: 30, Loss: 0.4182359278202057, Accuracy: 82.1320564516129\n",
      "Epoch: 1, Batch: 31, Loss: 0.3288564682006836, Accuracy: 82.275390625\n",
      "Epoch: 1, Batch: 32, Loss: 0.41156747937202454, Accuracy: 82.22064393939394\n",
      "Epoch: 1, Batch: 33, Loss: 0.46400102972984314, Accuracy: 82.12316176470588\n",
      "Epoch: 1, Batch: 34, Loss: 0.3402204215526581, Accuracy: 82.1875\n",
      "Epoch: 1, Batch: 35, Loss: 0.3954610824584961, Accuracy: 82.18315972222221\n",
      "Epoch: 1, Batch: 36, Loss: 0.3622520864009857, Accuracy: 82.22128378378379\n",
      "Epoch: 1, Batch: 37, Loss: 0.3814209997653961, Accuracy: 82.27796052631578\n",
      "Epoch: 1, Batch: 38, Loss: 0.3867647647857666, Accuracy: 82.29166666666666\n",
      "Epoch: 1, Batch: 39, Loss: 0.3589800000190735, Accuracy: 82.3046875\n",
      "Epoch: 1, Batch: 40, Loss: 0.40173009037971497, Accuracy: 82.27896341463415\n",
      "Epoch: 1, Batch: 41, Loss: 0.46324610710144043, Accuracy: 82.19866071428571\n",
      "Epoch: 1, Batch: 42, Loss: 0.5318558812141418, Accuracy: 82.06758720930233\n",
      "Epoch: 1, Batch: 43, Loss: 0.3655718266963959, Accuracy: 82.1377840909091\n",
      "Epoch: 1, Batch: 44, Loss: 0.3863068222999573, Accuracy: 82.1875\n",
      "Epoch: 1, Batch: 45, Loss: 0.36018240451812744, Accuracy: 82.25203804347827\n",
      "Epoch: 1, Batch: 46, Loss: 0.3664766848087311, Accuracy: 82.28058510638297\n",
      "Epoch: 1, Batch: 47, Loss: 0.4558112323284149, Accuracy: 82.19401041666666\n",
      "Epoch: 1, Batch: 48, Loss: 0.42645028233528137, Accuracy: 82.15880102040816\n",
      "Epoch: 1, Batch: 49, Loss: 0.48899903893470764, Accuracy: 82.09375\n",
      "Epoch: 1, Batch: 50, Loss: 0.5159780383110046, Accuracy: 81.92401960784314\n",
      "Epoch: 1, Batch: 51, Loss: 0.4310396909713745, Accuracy: 81.86598557692307\n",
      "Epoch: 1, Batch: 52, Loss: 0.35391131043434143, Accuracy: 81.86910377358491\n",
      "Epoch: 1, Batch: 53, Loss: 0.4258965253829956, Accuracy: 81.79976851851852\n",
      "Epoch: 1, Batch: 54, Loss: 0.4301169216632843, Accuracy: 81.81818181818183\n",
      "Epoch: 1, Batch: 55, Loss: 0.32438963651657104, Accuracy: 81.94754464285714\n",
      "Epoch: 1, Batch: 56, Loss: 0.416255384683609, Accuracy: 81.89418859649122\n",
      "Epoch: 1, Batch: 57, Loss: 0.4260641932487488, Accuracy: 81.92349137931035\n",
      "Epoch: 1, Batch: 58, Loss: 0.3578817844390869, Accuracy: 81.97828389830508\n",
      "Epoch: 1, Batch: 59, Loss: 0.357963889837265, Accuracy: 81.97916666666667\n",
      "Epoch: 1, Batch: 60, Loss: 0.400748610496521, Accuracy: 81.98002049180327\n",
      "Epoch: 1, Batch: 61, Loss: 0.34077730774879456, Accuracy: 82.06905241935483\n",
      "Epoch: 1, Batch: 62, Loss: 0.3687480092048645, Accuracy: 82.15525793650794\n",
      "Epoch: 1, Batch: 63, Loss: 0.4589928984642029, Accuracy: 82.06787109375\n",
      "Epoch: 1, Batch: 64, Loss: 0.4091716706752777, Accuracy: 82.05528846153847\n",
      "Epoch: 1, Batch: 65, Loss: 0.32104018330574036, Accuracy: 82.1377840909091\n",
      "Epoch: 1, Batch: 66, Loss: 0.31206345558166504, Accuracy: 82.18283582089553\n",
      "Epoch: 1, Batch: 67, Loss: 0.4383956491947174, Accuracy: 82.14613970588235\n",
      "Epoch: 1, Batch: 68, Loss: 0.37311094999313354, Accuracy: 82.17844202898551\n",
      "Epoch: 1, Batch: 69, Loss: 0.3756353259086609, Accuracy: 82.24330357142857\n",
      "Epoch: 1, Batch: 70, Loss: 0.4342276453971863, Accuracy: 82.24031690140845\n",
      "Epoch: 1, Batch: 71, Loss: 0.2829974889755249, Accuracy: 82.30251736111111\n",
      "Epoch: 1, Batch: 72, Loss: 0.352510541677475, Accuracy: 82.30950342465754\n",
      "Epoch: 1, Batch: 73, Loss: 0.4237649142742157, Accuracy: 82.28462837837837\n",
      "Epoch: 1, Batch: 74, Loss: 0.3350332975387573, Accuracy: 82.36458333333333\n",
      "Epoch: 1, Batch: 75, Loss: 0.42958390712738037, Accuracy: 82.39103618421053\n",
      "Epoch: 1, Batch: 76, Loss: 0.34173402190208435, Accuracy: 82.36607142857143\n",
      "Epoch: 1, Batch: 77, Loss: 0.3196902573108673, Accuracy: 82.44190705128204\n",
      "Epoch: 1, Batch: 78, Loss: 0.3158758580684662, Accuracy: 82.47626582278481\n",
      "Epoch: 1, Batch: 79, Loss: 0.3723682761192322, Accuracy: 82.509765625\n",
      "Epoch: 1, Batch: 80, Loss: 0.3569786548614502, Accuracy: 82.58101851851852\n",
      "Epoch: 1, Batch: 81, Loss: 0.3051805794239044, Accuracy: 82.6219512195122\n",
      "Epoch: 1, Batch: 82, Loss: 0.41631561517715454, Accuracy: 82.56777108433735\n",
      "Epoch: 1, Batch: 83, Loss: 0.25702500343322754, Accuracy: 82.68229166666666\n",
      "Epoch: 1, Batch: 84, Loss: 0.39033347368240356, Accuracy: 82.71139705882354\n",
      "Epoch: 1, Batch: 85, Loss: 0.2923027575016022, Accuracy: 82.78524709302324\n",
      "Epoch: 1, Batch: 86, Loss: 0.33681797981262207, Accuracy: 82.83045977011494\n",
      "Epoch: 1, Batch: 87, Loss: 0.3532351553440094, Accuracy: 82.83913352272727\n",
      "Epoch: 1, Batch: 88, Loss: 0.3728668987751007, Accuracy: 82.86516853932584\n",
      "Epoch: 1, Batch: 89, Loss: 0.32619526982307434, Accuracy: 82.90798611111111\n",
      "Epoch: 1, Batch: 90, Loss: 0.36367228627204895, Accuracy: 82.92410714285714\n",
      "Epoch: 1, Batch: 91, Loss: 0.3202338218688965, Accuracy: 82.98233695652173\n",
      "Epoch: 1, Batch: 92, Loss: 0.37031108140945435, Accuracy: 82.99731182795699\n",
      "Epoch: 1, Batch: 93, Loss: 0.30644601583480835, Accuracy: 83.05352393617021\n",
      "Epoch: 1, Batch: 94, Loss: 0.3230797350406647, Accuracy: 83.08388157894737\n",
      "Epoch: 1, Batch: 95, Loss: 0.3429540693759918, Accuracy: 83.11360677083334\n",
      "Epoch: 1, Batch: 96, Loss: 0.3302296996116638, Accuracy: 83.1346649484536\n",
      "Epoch: 1, Batch: 97, Loss: 0.36810678243637085, Accuracy: 83.1313775510204\n",
      "Epoch: 1, Batch: 98, Loss: 0.2481038123369217, Accuracy: 83.19128787878788\n",
      "Epoch: 1, Batch: 99, Loss: 0.33847349882125854, Accuracy: 83.2109375\n",
      "Epoch: 1, Batch: 100, Loss: 0.4051462709903717, Accuracy: 83.21472772277228\n",
      "Epoch: 1, Batch: 101, Loss: 0.3471665382385254, Accuracy: 83.25674019607843\n",
      "Epoch: 1, Batch: 102, Loss: 0.33253106474876404, Accuracy: 83.29035194174757\n",
      "Epoch: 1, Batch: 103, Loss: 0.36160042881965637, Accuracy: 83.29326923076923\n",
      "Epoch: 1, Batch: 104, Loss: 0.3465224802494049, Accuracy: 83.32589285714286\n",
      "Epoch: 1, Batch: 105, Loss: 0.4417870044708252, Accuracy: 83.31367924528303\n",
      "Epoch: 1, Batch: 106, Loss: 0.4409378170967102, Accuracy: 83.23598130841121\n",
      "Epoch: 1, Batch: 107, Loss: 0.31503984332084656, Accuracy: 83.29716435185185\n",
      "Epoch: 1, Batch: 108, Loss: 0.3729035556316376, Accuracy: 83.28555045871559\n",
      "Epoch: 1, Batch: 109, Loss: 0.3725484311580658, Accuracy: 83.28125\n",
      "Epoch: 1, Batch: 110, Loss: 0.39684101939201355, Accuracy: 83.2347972972973\n",
      "Epoch: 1, Batch: 111, Loss: 0.2974744439125061, Accuracy: 83.27985491071429\n",
      "Epoch: 1, Batch: 112, Loss: 0.4544886648654938, Accuracy: 83.24115044247787\n",
      "Epoch: 1, Batch: 113, Loss: 0.4333508312702179, Accuracy: 83.23053728070175\n",
      "Epoch: 1, Batch: 114, Loss: 0.3591945469379425, Accuracy: 83.25407608695652\n",
      "Epoch: 1, Batch: 115, Loss: 0.32986512780189514, Accuracy: 83.29741379310344\n",
      "Epoch: 1, Batch: 116, Loss: 0.35571154952049255, Accuracy: 83.30662393162393\n",
      "Epoch: 1, Batch: 117, Loss: 0.37711793184280396, Accuracy: 83.30905720338984\n",
      "Epoch: 1, Batch: 118, Loss: 0.3863479495048523, Accuracy: 83.31801470588235\n",
      "Epoch: 1, Batch: 119, Loss: 0.3708624541759491, Accuracy: 83.30078125\n",
      "Epoch: 1, Batch: 120, Loss: 0.3048814833164215, Accuracy: 83.33548553719008\n",
      "Epoch: 1, Batch: 121, Loss: 0.42712271213531494, Accuracy: 83.3311987704918\n",
      "Epoch: 1, Batch: 122, Loss: 0.4154786467552185, Accuracy: 83.3079268292683\n",
      "Epoch: 1, Batch: 123, Loss: 0.411264032125473, Accuracy: 83.2976310483871\n",
      "Epoch: 1, Batch: 124, Loss: 0.3995301127433777, Accuracy: 83.28750000000001\n",
      "Epoch: 1, Batch: 125, Loss: 0.37403184175491333, Accuracy: 83.30233134920636\n",
      "Epoch: 1, Batch: 126, Loss: 0.442481130361557, Accuracy: 83.26156496062993\n",
      "Epoch: 1, Batch: 127, Loss: 0.35546937584877014, Accuracy: 83.2763671875\n",
      "Epoch: 1, Batch: 128, Loss: 0.31501805782318115, Accuracy: 83.29093992248062\n",
      "Epoch: 1, Batch: 129, Loss: 0.3298543095588684, Accuracy: 83.3173076923077\n",
      "Epoch: 1, Batch: 130, Loss: 0.3202901780605316, Accuracy: 83.31345419847328\n",
      "Epoch: 1, Batch: 131, Loss: 0.38469210267066956, Accuracy: 83.32149621212122\n",
      "Epoch: 1, Batch: 132, Loss: 0.3493088483810425, Accuracy: 83.31179511278195\n",
      "Epoch: 1, Batch: 133, Loss: 0.4069189131259918, Accuracy: 83.31389925373134\n",
      "Epoch: 1, Batch: 134, Loss: 0.33089783787727356, Accuracy: 83.33333333333334\n",
      "Epoch: 1, Batch: 135, Loss: 0.31724491715431213, Accuracy: 83.34673713235294\n",
      "Epoch: 1, Batch: 136, Loss: 0.37244266271591187, Accuracy: 83.34283759124088\n",
      "Epoch: 1, Batch: 137, Loss: 0.28472357988357544, Accuracy: 83.39560688405797\n",
      "Epoch: 1, Batch: 138, Loss: 0.3714691698551178, Accuracy: 83.39703237410072\n",
      "Epoch: 1, Batch: 139, Loss: 0.35877785086631775, Accuracy: 83.3984375\n",
      "Epoch: 1, Batch: 140, Loss: 0.37722423672676086, Accuracy: 83.41090425531915\n",
      "Epoch: 1, Batch: 141, Loss: 0.31037938594818115, Accuracy: 83.43419894366197\n",
      "Epoch: 1, Batch: 142, Loss: 0.46235203742980957, Accuracy: 83.40253496503497\n",
      "Epoch: 1, Batch: 143, Loss: 0.27700313925743103, Accuracy: 83.45269097222221\n",
      "Epoch: 1, Batch: 144, Loss: 0.3016132116317749, Accuracy: 83.48599137931035\n",
      "Epoch: 1, Batch: 145, Loss: 0.3311331272125244, Accuracy: 83.50278253424658\n",
      "Epoch: 1, Batch: 146, Loss: 0.2604465186595917, Accuracy: 83.5406037414966\n",
      "Epoch: 1, Batch: 147, Loss: 0.4386870861053467, Accuracy: 83.51984797297297\n",
      "Epoch: 1, Batch: 148, Loss: 0.29393908381462097, Accuracy: 83.55180369127517\n",
      "Epoch: 1, Batch: 149, Loss: 0.346002459526062, Accuracy: 83.5625\n",
      "Epoch: 1, Batch: 150, Loss: 0.23573274910449982, Accuracy: 83.62479304635761\n",
      "Epoch: 1, Batch: 151, Loss: 0.3438839912414551, Accuracy: 83.63486842105263\n",
      "Epoch: 1, Batch: 152, Loss: 0.33135074377059937, Accuracy: 83.64481209150327\n",
      "Epoch: 1, Batch: 153, Loss: 0.3514878749847412, Accuracy: 83.63940746753246\n",
      "Epoch: 1, Batch: 154, Loss: 0.30595773458480835, Accuracy: 83.65423387096774\n",
      "Epoch: 1, Batch: 155, Loss: 0.3746451735496521, Accuracy: 83.64883814102564\n",
      "Epoch: 1, Batch: 156, Loss: 0.29692697525024414, Accuracy: 83.67834394904459\n",
      "Epoch: 1, Batch: 157, Loss: 0.3780577778816223, Accuracy: 83.68275316455697\n",
      "Epoch: 1, Batch: 158, Loss: 0.2931564748287201, Accuracy: 83.71658805031447\n",
      "Epoch: 1, Batch: 159, Loss: 0.49401983618736267, Accuracy: 83.681640625\n",
      "Epoch: 1, Batch: 160, Loss: 0.29105260968208313, Accuracy: 83.69326768390776\n",
      "Epoch: 1, Training Loss: 0.3750426643383429\n",
      "Epoch: 1, Validation Loss: 0.357867069542408, Validation Accuracy: 83.85457388584831\n",
      "Epoch: 2, Batch: 0, Loss: 0.29814091324806213, Accuracy: 88.28125\n",
      "Epoch: 2, Batch: 1, Loss: 0.2685999572277069, Accuracy: 91.015625\n",
      "Epoch: 2, Batch: 2, Loss: 0.26046332716941833, Accuracy: 90.88541666666666\n",
      "Epoch: 2, Batch: 3, Loss: 0.17930968105793, Accuracy: 91.40625\n",
      "Epoch: 2, Batch: 4, Loss: 0.19509370625019073, Accuracy: 91.40625\n",
      "Epoch: 2, Batch: 5, Loss: 0.2401742935180664, Accuracy: 90.88541666666666\n",
      "Epoch: 2, Batch: 6, Loss: 0.23243491351604462, Accuracy: 90.95982142857143\n",
      "Epoch: 2, Batch: 7, Loss: 0.24493947625160217, Accuracy: 91.015625\n",
      "Epoch: 2, Batch: 8, Loss: 0.2230232059955597, Accuracy: 91.05902777777779\n",
      "Epoch: 2, Batch: 9, Loss: 0.2378779500722885, Accuracy: 91.015625\n",
      "Epoch: 2, Batch: 10, Loss: 0.1871386021375656, Accuracy: 91.19318181818183\n",
      "Epoch: 2, Batch: 11, Loss: 0.20758843421936035, Accuracy: 91.34114583333334\n",
      "Epoch: 2, Batch: 12, Loss: 0.2505131661891937, Accuracy: 91.2860576923077\n",
      "Epoch: 2, Batch: 13, Loss: 0.21389761567115784, Accuracy: 91.29464285714286\n",
      "Epoch: 2, Batch: 14, Loss: 0.21964000165462494, Accuracy: 91.25\n",
      "Epoch: 2, Batch: 15, Loss: 0.2505530118942261, Accuracy: 91.30859375\n",
      "Epoch: 2, Batch: 16, Loss: 0.24455103278160095, Accuracy: 91.26838235294117\n",
      "Epoch: 2, Batch: 17, Loss: 0.16403304040431976, Accuracy: 91.27604166666666\n",
      "Epoch: 2, Batch: 18, Loss: 0.14845837652683258, Accuracy: 91.48848684210526\n",
      "Epoch: 2, Batch: 19, Loss: 0.23693686723709106, Accuracy: 91.484375\n",
      "Epoch: 2, Batch: 20, Loss: 0.2002805918455124, Accuracy: 91.44345238095238\n",
      "Epoch: 2, Batch: 21, Loss: 0.2993701100349426, Accuracy: 91.33522727272727\n",
      "Epoch: 2, Batch: 22, Loss: 0.27000054717063904, Accuracy: 91.30434782608695\n",
      "Epoch: 2, Batch: 23, Loss: 0.18373076617717743, Accuracy: 91.34114583333334\n",
      "Epoch: 2, Batch: 24, Loss: 0.22400403022766113, Accuracy: 91.40625\n",
      "Epoch: 2, Batch: 25, Loss: 0.2897951006889343, Accuracy: 91.2860576923077\n",
      "Epoch: 2, Batch: 26, Loss: 0.28141090273857117, Accuracy: 91.20370370370371\n",
      "Epoch: 2, Batch: 27, Loss: 0.25347208976745605, Accuracy: 91.15513392857143\n",
      "Epoch: 2, Batch: 28, Loss: 0.19108980894088745, Accuracy: 91.16379310344827\n",
      "Epoch: 2, Batch: 29, Loss: 0.2364782989025116, Accuracy: 91.11979166666667\n",
      "Epoch: 2, Batch: 30, Loss: 0.18041178584098816, Accuracy: 91.22983870967742\n",
      "Epoch: 2, Batch: 31, Loss: 0.1639043390750885, Accuracy: 91.2841796875\n",
      "Epoch: 2, Batch: 32, Loss: 0.17089326679706573, Accuracy: 91.33522727272727\n",
      "Epoch: 2, Batch: 33, Loss: 0.14052216708660126, Accuracy: 91.38327205882352\n",
      "Epoch: 2, Batch: 34, Loss: 0.19751589000225067, Accuracy: 91.36160714285714\n",
      "Epoch: 2, Batch: 35, Loss: 0.22901836037635803, Accuracy: 91.36284722222221\n",
      "Epoch: 2, Batch: 36, Loss: 0.25130513310432434, Accuracy: 91.38513513513513\n",
      "Epoch: 2, Batch: 37, Loss: 0.25002503395080566, Accuracy: 91.36513157894737\n",
      "Epoch: 2, Batch: 38, Loss: 0.18699751794338226, Accuracy: 91.42628205128204\n",
      "Epoch: 2, Batch: 39, Loss: 0.22517916560173035, Accuracy: 91.42578125\n",
      "Epoch: 2, Batch: 40, Loss: 0.2520484924316406, Accuracy: 91.46341463414635\n",
      "Epoch: 2, Batch: 41, Loss: 0.287157267332077, Accuracy: 91.36904761904762\n",
      "Epoch: 2, Batch: 42, Loss: 0.22966070473194122, Accuracy: 91.35174418604652\n",
      "Epoch: 2, Batch: 43, Loss: 0.22511707246303558, Accuracy: 91.38849431818183\n",
      "Epoch: 2, Batch: 44, Loss: 0.3057415187358856, Accuracy: 91.26736111111111\n",
      "Epoch: 2, Batch: 45, Loss: 0.14612305164337158, Accuracy: 91.37228260869566\n",
      "Epoch: 2, Batch: 46, Loss: 0.18091166019439697, Accuracy: 91.42287234042553\n",
      "Epoch: 2, Batch: 47, Loss: 0.20102885365486145, Accuracy: 91.43880208333334\n",
      "Epoch: 2, Batch: 48, Loss: 0.2610127329826355, Accuracy: 91.42219387755102\n",
      "Epoch: 2, Batch: 49, Loss: 0.21861566603183746, Accuracy: 91.453125\n",
      "Epoch: 2, Batch: 50, Loss: 0.24619987607002258, Accuracy: 91.45220588235294\n",
      "Epoch: 2, Batch: 51, Loss: 0.30724307894706726, Accuracy: 91.43629807692307\n",
      "Epoch: 2, Batch: 52, Loss: 0.2748914659023285, Accuracy: 91.4504716981132\n",
      "Epoch: 2, Batch: 53, Loss: 0.24701987206935883, Accuracy: 91.44965277777779\n",
      "Epoch: 2, Batch: 54, Loss: 0.2052721232175827, Accuracy: 91.47727272727273\n",
      "Epoch: 2, Batch: 55, Loss: 0.2219226360321045, Accuracy: 91.47600446428571\n",
      "Epoch: 2, Batch: 56, Loss: 0.30190280079841614, Accuracy: 91.3514254385965\n",
      "Epoch: 2, Batch: 57, Loss: 0.2595948278903961, Accuracy: 91.31196120689656\n",
      "Epoch: 2, Batch: 58, Loss: 0.176890030503273, Accuracy: 91.39300847457628\n",
      "Epoch: 2, Batch: 59, Loss: 0.245558962225914, Accuracy: 91.31510416666667\n",
      "Epoch: 2, Batch: 60, Loss: 0.14665839076042175, Accuracy: 91.38063524590164\n",
      "Epoch: 2, Batch: 61, Loss: 0.2762123942375183, Accuracy: 91.34324596774194\n",
      "Epoch: 2, Batch: 62, Loss: 0.2440311163663864, Accuracy: 91.33184523809523\n",
      "Epoch: 2, Batch: 63, Loss: 0.19272901117801666, Accuracy: 91.3330078125\n",
      "Epoch: 2, Batch: 64, Loss: 0.3474408984184265, Accuracy: 91.2860576923077\n",
      "Epoch: 2, Batch: 65, Loss: 0.2929225265979767, Accuracy: 91.25236742424242\n",
      "Epoch: 2, Batch: 66, Loss: 0.27212727069854736, Accuracy: 91.18470149253731\n",
      "Epoch: 2, Batch: 67, Loss: 0.21906927227973938, Accuracy: 91.18795955882352\n",
      "Epoch: 2, Batch: 68, Loss: 0.3549385070800781, Accuracy: 91.11186594202898\n",
      "Epoch: 2, Batch: 69, Loss: 0.2780666649341583, Accuracy: 91.10491071428571\n",
      "Epoch: 2, Batch: 70, Loss: 0.2263060063123703, Accuracy: 91.08714788732394\n",
      "Epoch: 2, Batch: 71, Loss: 0.2116328924894333, Accuracy: 91.10243055555556\n",
      "Epoch: 2, Batch: 72, Loss: 0.26440322399139404, Accuracy: 91.10659246575342\n",
      "Epoch: 2, Batch: 73, Loss: 0.27201420068740845, Accuracy: 91.08952702702703\n",
      "Epoch: 2, Batch: 74, Loss: 0.18727751076221466, Accuracy: 91.10416666666666\n",
      "Epoch: 2, Batch: 75, Loss: 0.2475525438785553, Accuracy: 91.06702302631578\n",
      "Epoch: 2, Batch: 76, Loss: 0.3554820716381073, Accuracy: 91.02069805194806\n",
      "Epoch: 2, Batch: 77, Loss: 0.23783467710018158, Accuracy: 91.02564102564102\n",
      "Epoch: 2, Batch: 78, Loss: 0.1999332159757614, Accuracy: 91.05023734177216\n",
      "Epoch: 2, Batch: 79, Loss: 0.1733981817960739, Accuracy: 91.09375\n",
      "Epoch: 2, Batch: 80, Loss: 0.20312272012233734, Accuracy: 91.09760802469135\n",
      "Epoch: 2, Batch: 81, Loss: 0.2585613429546356, Accuracy: 91.05373475609755\n",
      "Epoch: 2, Batch: 82, Loss: 0.22915610671043396, Accuracy: 91.03915662650603\n",
      "Epoch: 2, Batch: 83, Loss: 0.1572335660457611, Accuracy: 91.06212797619048\n",
      "Epoch: 2, Batch: 84, Loss: 0.19185324013233185, Accuracy: 91.07536764705883\n",
      "Epoch: 2, Batch: 85, Loss: 0.21963459253311157, Accuracy: 91.08829941860465\n",
      "Epoch: 2, Batch: 86, Loss: 0.24664753675460815, Accuracy: 91.07399425287356\n",
      "Epoch: 2, Batch: 87, Loss: 0.19664441049098969, Accuracy: 91.1044034090909\n",
      "Epoch: 2, Batch: 88, Loss: 0.18929465115070343, Accuracy: 91.12535112359551\n",
      "Epoch: 2, Batch: 89, Loss: 0.33983176946640015, Accuracy: 91.05902777777779\n",
      "Epoch: 2, Batch: 90, Loss: 0.30256372690200806, Accuracy: 91.01991758241759\n",
      "Epoch: 2, Batch: 91, Loss: 0.29030606150627136, Accuracy: 90.99014945652173\n",
      "Epoch: 2, Batch: 92, Loss: 0.2653784155845642, Accuracy: 90.96942204301075\n",
      "Epoch: 2, Batch: 93, Loss: 0.22279487550258636, Accuracy: 90.97406914893617\n",
      "Epoch: 2, Batch: 94, Loss: 0.23971429467201233, Accuracy: 90.92927631578948\n",
      "Epoch: 2, Batch: 95, Loss: 0.19532033801078796, Accuracy: 90.9423828125\n",
      "Epoch: 2, Batch: 96, Loss: 0.2185268998146057, Accuracy: 90.9471649484536\n",
      "Epoch: 2, Batch: 97, Loss: 0.20730328559875488, Accuracy: 90.95184948979592\n",
      "Epoch: 2, Batch: 98, Loss: 0.19086667895317078, Accuracy: 90.97222222222221\n",
      "Epoch: 2, Batch: 99, Loss: 0.2726283669471741, Accuracy: 90.96875\n",
      "Epoch: 2, Batch: 100, Loss: 0.18977242708206177, Accuracy: 91.00402227722772\n",
      "Epoch: 2, Batch: 101, Loss: 0.19023436307907104, Accuracy: 91.03860294117648\n",
      "Epoch: 2, Batch: 102, Loss: 0.28877219557762146, Accuracy: 91.01183252427184\n",
      "Epoch: 2, Batch: 103, Loss: 0.18124324083328247, Accuracy: 91.05318509615384\n",
      "Epoch: 2, Batch: 104, Loss: 0.2146613448858261, Accuracy: 91.07142857142857\n",
      "Epoch: 2, Batch: 105, Loss: 0.20449721813201904, Accuracy: 91.08195754716981\n",
      "Epoch: 2, Batch: 106, Loss: 0.25455811619758606, Accuracy: 91.06308411214953\n",
      "Epoch: 2, Batch: 107, Loss: 0.2367336004972458, Accuracy: 91.04456018518519\n",
      "Epoch: 2, Batch: 108, Loss: 0.21605265140533447, Accuracy: 91.01920871559633\n",
      "Epoch: 2, Batch: 109, Loss: 0.33076536655426025, Accuracy: 90.99431818181817\n",
      "Epoch: 2, Batch: 110, Loss: 0.3044557273387909, Accuracy: 90.95579954954955\n",
      "Epoch: 2, Batch: 111, Loss: 0.2503458559513092, Accuracy: 90.95982142857143\n",
      "Epoch: 2, Batch: 112, Loss: 0.23685859143733978, Accuracy: 90.9637721238938\n",
      "Epoch: 2, Batch: 113, Loss: 0.262345552444458, Accuracy: 90.94024122807018\n",
      "Epoch: 2, Batch: 114, Loss: 0.2699280083179474, Accuracy: 90.91032608695652\n",
      "Epoch: 2, Batch: 115, Loss: 0.21800774335861206, Accuracy: 90.92133620689656\n",
      "Epoch: 2, Batch: 116, Loss: 0.2502211630344391, Accuracy: 90.91212606837607\n",
      "Epoch: 2, Batch: 117, Loss: 0.3513871431350708, Accuracy: 90.88320974576271\n",
      "Epoch: 2, Batch: 118, Loss: 0.23900151252746582, Accuracy: 90.89417016806722\n",
      "Epoch: 2, Batch: 119, Loss: 0.2328176498413086, Accuracy: 90.8984375\n",
      "Epoch: 2, Batch: 120, Loss: 0.1782376766204834, Accuracy: 90.91554752066115\n",
      "Epoch: 2, Batch: 121, Loss: 0.2196863442659378, Accuracy: 90.92597336065575\n",
      "Epoch: 2, Batch: 122, Loss: 0.2551555633544922, Accuracy: 90.92352642276423\n",
      "Epoch: 2, Batch: 123, Loss: 0.2828991115093231, Accuracy: 90.90851814516128\n",
      "Epoch: 2, Batch: 124, Loss: 0.16861802339553833, Accuracy: 90.95\n",
      "Epoch: 2, Batch: 125, Loss: 0.2802831828594208, Accuracy: 90.93501984126983\n",
      "Epoch: 2, Batch: 126, Loss: 0.20814697444438934, Accuracy: 90.95103346456693\n",
      "Epoch: 2, Batch: 127, Loss: 0.31508901715278625, Accuracy: 90.93017578125\n",
      "Epoch: 2, Batch: 128, Loss: 0.22113144397735596, Accuracy: 90.93386627906976\n",
      "Epoch: 2, Batch: 129, Loss: 0.1746375411748886, Accuracy: 90.9795673076923\n",
      "Epoch: 2, Batch: 130, Loss: 0.256605327129364, Accuracy: 90.95300572519083\n",
      "Epoch: 2, Batch: 131, Loss: 0.2807610034942627, Accuracy: 90.9268465909091\n",
      "Epoch: 2, Batch: 132, Loss: 0.30246105790138245, Accuracy: 90.8952067669173\n",
      "Epoch: 2, Batch: 133, Loss: 0.16454453766345978, Accuracy: 90.91651119402985\n",
      "Epoch: 2, Batch: 134, Loss: 0.22181670367717743, Accuracy: 90.91435185185185\n",
      "Epoch: 2, Batch: 135, Loss: 0.19520437717437744, Accuracy: 90.91222426470588\n",
      "Epoch: 2, Batch: 136, Loss: 0.23904074728488922, Accuracy: 90.89872262773723\n",
      "Epoch: 2, Batch: 137, Loss: 0.2782790958881378, Accuracy: 90.89673913043478\n",
      "Epoch: 2, Batch: 138, Loss: 0.2437981516122818, Accuracy: 90.86668165467626\n",
      "Epoch: 2, Batch: 139, Loss: 0.25340574979782104, Accuracy: 90.86495535714286\n",
      "Epoch: 2, Batch: 140, Loss: 0.2879174053668976, Accuracy: 90.84109042553192\n",
      "Epoch: 2, Batch: 141, Loss: 0.22591868042945862, Accuracy: 90.85607394366197\n",
      "Epoch: 2, Batch: 142, Loss: 0.3449142277240753, Accuracy: 90.81621503496503\n",
      "Epoch: 2, Batch: 143, Loss: 0.2388758808374405, Accuracy: 90.8203125\n",
      "Epoch: 2, Batch: 144, Loss: 0.323248952627182, Accuracy: 90.81357758620689\n",
      "Epoch: 2, Batch: 145, Loss: 0.28042933344841003, Accuracy: 90.79088184931507\n",
      "Epoch: 2, Batch: 146, Loss: 0.31233692169189453, Accuracy: 90.74723639455783\n",
      "Epoch: 2, Batch: 147, Loss: 0.25606587529182434, Accuracy: 90.73585304054053\n",
      "Epoch: 2, Batch: 148, Loss: 0.16022741794586182, Accuracy: 90.7613255033557\n",
      "Epoch: 2, Batch: 149, Loss: 0.22729097306728363, Accuracy: 90.75520833333334\n",
      "Epoch: 2, Batch: 150, Loss: 0.25436416268348694, Accuracy: 90.74399834437085\n",
      "Epoch: 2, Batch: 151, Loss: 0.19215065240859985, Accuracy: 90.76377467105263\n",
      "Epoch: 2, Batch: 152, Loss: 0.2411516010761261, Accuracy: 90.77308006535948\n",
      "Epoch: 2, Batch: 153, Loss: 0.20974373817443848, Accuracy: 90.80255681818183\n",
      "Epoch: 2, Batch: 154, Loss: 0.26580554246902466, Accuracy: 90.78125\n",
      "Epoch: 2, Batch: 155, Loss: 0.23475207388401031, Accuracy: 90.77524038461539\n",
      "Epoch: 2, Batch: 156, Loss: 0.23138411343097687, Accuracy: 90.76433121019109\n",
      "Epoch: 2, Batch: 157, Loss: 0.25548920035362244, Accuracy: 90.74861550632912\n",
      "Epoch: 2, Batch: 158, Loss: 0.23533105850219727, Accuracy: 90.74783805031447\n",
      "Epoch: 2, Batch: 159, Loss: 0.20702344179153442, Accuracy: 90.7568359375\n",
      "Epoch: 2, Batch: 160, Loss: 0.3063257336616516, Accuracy: 90.75708087554234\n",
      "Epoch: 2, Training Loss: 0.23797084918673733\n",
      "Epoch: 2, Validation Loss: 0.3535968132317066, Validation Accuracy: 85.69194683346365\n",
      "Epoch: 3, Batch: 0, Loss: 0.148996964097023, Accuracy: 96.875\n",
      "Epoch: 3, Batch: 1, Loss: 0.10588355362415314, Accuracy: 97.65625\n",
      "Epoch: 3, Batch: 2, Loss: 0.09667909890413284, Accuracy: 97.39583333333334\n",
      "Epoch: 3, Batch: 3, Loss: 0.15444642305374146, Accuracy: 96.6796875\n",
      "Epoch: 3, Batch: 4, Loss: 0.17432110011577606, Accuracy: 95.9375\n",
      "Epoch: 3, Batch: 5, Loss: 0.15915295481681824, Accuracy: 95.703125\n",
      "Epoch: 3, Batch: 6, Loss: 0.09609208256006241, Accuracy: 95.98214285714286\n",
      "Epoch: 3, Batch: 7, Loss: 0.08318908512592316, Accuracy: 96.19140625\n",
      "Epoch: 3, Batch: 8, Loss: 0.12357260286808014, Accuracy: 96.18055555555556\n",
      "Epoch: 3, Batch: 9, Loss: 0.11810420453548431, Accuracy: 96.328125\n",
      "Epoch: 3, Batch: 10, Loss: 0.1587110310792923, Accuracy: 96.30681818181817\n",
      "Epoch: 3, Batch: 11, Loss: 0.15686915814876556, Accuracy: 96.09375\n",
      "Epoch: 3, Batch: 12, Loss: 0.044622063636779785, Accuracy: 96.33413461538461\n",
      "Epoch: 3, Batch: 13, Loss: 0.16147921979427338, Accuracy: 96.14955357142857\n",
      "Epoch: 3, Batch: 14, Loss: 0.07862789928913116, Accuracy: 96.25\n",
      "Epoch: 3, Batch: 15, Loss: 0.13296400010585785, Accuracy: 96.337890625\n",
      "Epoch: 3, Batch: 16, Loss: 0.1403069794178009, Accuracy: 96.27757352941177\n",
      "Epoch: 3, Batch: 17, Loss: 0.08478676527738571, Accuracy: 96.26736111111111\n",
      "Epoch: 3, Batch: 18, Loss: 0.1453406661748886, Accuracy: 96.25822368421053\n",
      "Epoch: 3, Batch: 19, Loss: 0.13323290646076202, Accuracy: 96.2109375\n",
      "Epoch: 3, Batch: 20, Loss: 0.23890839517116547, Accuracy: 96.05654761904762\n",
      "Epoch: 3, Batch: 21, Loss: 0.1176476925611496, Accuracy: 96.09375\n",
      "Epoch: 3, Batch: 22, Loss: 0.2217884510755539, Accuracy: 96.02581521739131\n",
      "Epoch: 3, Batch: 23, Loss: 0.09325574338436127, Accuracy: 96.06119791666666\n",
      "Epoch: 3, Batch: 24, Loss: 0.15052509307861328, Accuracy: 96.03125\n",
      "Epoch: 3, Batch: 25, Loss: 0.08819490671157837, Accuracy: 96.06370192307693\n",
      "Epoch: 3, Batch: 26, Loss: 0.1662827581167221, Accuracy: 96.06481481481481\n",
      "Epoch: 3, Batch: 27, Loss: 0.10189758986234665, Accuracy: 96.09375\n",
      "Epoch: 3, Batch: 28, Loss: 0.08967694640159607, Accuracy: 96.09375\n",
      "Epoch: 3, Batch: 29, Loss: 0.10960310697555542, Accuracy: 96.11979166666667\n",
      "Epoch: 3, Batch: 30, Loss: 0.12923580408096313, Accuracy: 96.11895161290323\n",
      "Epoch: 3, Batch: 31, Loss: 0.201628640294075, Accuracy: 96.0205078125\n",
      "Epoch: 3, Batch: 32, Loss: 0.12856340408325195, Accuracy: 96.04640151515152\n",
      "Epoch: 3, Batch: 33, Loss: 0.09104941785335541, Accuracy: 96.04779411764706\n",
      "Epoch: 3, Batch: 34, Loss: 0.12989099323749542, Accuracy: 96.04910714285714\n",
      "Epoch: 3, Batch: 35, Loss: 0.14501990377902985, Accuracy: 96.05034722222221\n",
      "Epoch: 3, Batch: 36, Loss: 0.13960015773773193, Accuracy: 96.0304054054054\n",
      "Epoch: 3, Batch: 37, Loss: 0.2403699904680252, Accuracy: 95.94983552631578\n",
      "Epoch: 3, Batch: 38, Loss: 0.12410065531730652, Accuracy: 95.93349358974359\n",
      "Epoch: 3, Batch: 39, Loss: 0.14483483135700226, Accuracy: 95.95703125\n",
      "Epoch: 3, Batch: 40, Loss: 0.10254298895597458, Accuracy: 95.97942073170732\n",
      "Epoch: 3, Batch: 41, Loss: 0.07217829674482346, Accuracy: 96.01934523809523\n",
      "Epoch: 3, Batch: 42, Loss: 0.10890144854784012, Accuracy: 96.03924418604652\n",
      "Epoch: 3, Batch: 43, Loss: 0.10759993642568588, Accuracy: 96.07599431818183\n",
      "Epoch: 3, Batch: 44, Loss: 0.12560924887657166, Accuracy: 96.07638888888889\n",
      "Epoch: 3, Batch: 45, Loss: 0.12391624599695206, Accuracy: 96.09375\n",
      "Epoch: 3, Batch: 46, Loss: 0.09082607924938202, Accuracy: 96.11037234042553\n",
      "Epoch: 3, Batch: 47, Loss: 0.04942081868648529, Accuracy: 96.17513020833334\n",
      "Epoch: 3, Batch: 48, Loss: 0.1494164764881134, Accuracy: 96.14158163265306\n",
      "Epoch: 3, Batch: 49, Loss: 0.06716818362474442, Accuracy: 96.1875\n",
      "Epoch: 3, Batch: 50, Loss: 0.17294694483280182, Accuracy: 96.12438725490196\n",
      "Epoch: 3, Batch: 51, Loss: 0.1354794204235077, Accuracy: 96.07872596153845\n",
      "Epoch: 3, Batch: 52, Loss: 0.20092496275901794, Accuracy: 96.03478773584906\n",
      "Epoch: 3, Batch: 53, Loss: 0.10185258090496063, Accuracy: 96.05034722222221\n",
      "Epoch: 3, Batch: 54, Loss: 0.09493473172187805, Accuracy: 96.02272727272727\n",
      "Epoch: 3, Batch: 55, Loss: 0.22006702423095703, Accuracy: 95.95424107142857\n",
      "Epoch: 3, Batch: 56, Loss: 0.10202538222074509, Accuracy: 95.94298245614034\n",
      "Epoch: 3, Batch: 57, Loss: 0.14778411388397217, Accuracy: 95.94558189655173\n",
      "Epoch: 3, Batch: 58, Loss: 0.1842435598373413, Accuracy: 95.93485169491525\n",
      "Epoch: 3, Batch: 59, Loss: 0.12048691511154175, Accuracy: 95.9375\n",
      "Epoch: 3, Batch: 60, Loss: 0.13709568977355957, Accuracy: 95.94006147540983\n",
      "Epoch: 3, Batch: 61, Loss: 0.21446841955184937, Accuracy: 95.89213709677419\n",
      "Epoch: 3, Batch: 62, Loss: 0.07122939825057983, Accuracy: 95.93253968253968\n",
      "Epoch: 3, Batch: 63, Loss: 0.10269731283187866, Accuracy: 95.93505859375\n",
      "Epoch: 3, Batch: 64, Loss: 0.09742473810911179, Accuracy: 95.94951923076923\n",
      "Epoch: 3, Batch: 65, Loss: 0.09511364996433258, Accuracy: 95.97537878787878\n",
      "Epoch: 3, Batch: 66, Loss: 0.15476828813552856, Accuracy: 95.95382462686567\n",
      "Epoch: 3, Batch: 67, Loss: 0.1464591920375824, Accuracy: 95.93290441176471\n",
      "Epoch: 3, Batch: 68, Loss: 0.12332876026630402, Accuracy: 95.93523550724638\n",
      "Epoch: 3, Batch: 69, Loss: 0.10097445547580719, Accuracy: 95.94866071428572\n",
      "Epoch: 3, Batch: 70, Loss: 0.18628717958927155, Accuracy: 95.89568661971832\n",
      "Epoch: 3, Batch: 71, Loss: 0.1292319893836975, Accuracy: 95.86588541666666\n",
      "Epoch: 3, Batch: 72, Loss: 0.10314207524061203, Accuracy: 95.8904109589041\n",
      "Epoch: 3, Batch: 73, Loss: 0.12983852624893188, Accuracy: 95.88260135135135\n",
      "Epoch: 3, Batch: 74, Loss: 0.18180778622627258, Accuracy: 95.80208333333333\n",
      "Epoch: 3, Batch: 75, Loss: 0.19482505321502686, Accuracy: 95.78536184210526\n",
      "Epoch: 3, Batch: 76, Loss: 0.07822933793067932, Accuracy: 95.8198051948052\n",
      "Epoch: 3, Batch: 77, Loss: 0.0977887362241745, Accuracy: 95.84334935897436\n",
      "Epoch: 3, Batch: 78, Loss: 0.1945006102323532, Accuracy: 95.81685126582279\n",
      "Epoch: 3, Batch: 79, Loss: 0.10681996494531631, Accuracy: 95.8203125\n",
      "Epoch: 3, Batch: 80, Loss: 0.13971668481826782, Accuracy: 95.79475308641975\n",
      "Epoch: 3, Batch: 81, Loss: 0.08489637821912766, Accuracy: 95.81745426829268\n",
      "Epoch: 3, Batch: 82, Loss: 0.1596701592206955, Accuracy: 95.78313253012048\n",
      "Epoch: 3, Batch: 83, Loss: 0.1654376983642578, Accuracy: 95.76822916666666\n",
      "Epoch: 3, Batch: 84, Loss: 0.10843122750520706, Accuracy: 95.79044117647058\n",
      "Epoch: 3, Batch: 85, Loss: 0.18827657401561737, Accuracy: 95.76671511627907\n",
      "Epoch: 3, Batch: 86, Loss: 0.07651196420192719, Accuracy: 95.7794540229885\n",
      "Epoch: 3, Batch: 87, Loss: 0.09880853444337845, Accuracy: 95.80078125\n",
      "Epoch: 3, Batch: 88, Loss: 0.14553019404411316, Accuracy: 95.81285112359551\n",
      "Epoch: 3, Batch: 89, Loss: 0.1411769986152649, Accuracy: 95.79861111111111\n",
      "Epoch: 3, Batch: 90, Loss: 0.13620713353157043, Accuracy: 95.79326923076923\n",
      "Epoch: 3, Batch: 91, Loss: 0.12174347788095474, Accuracy: 95.81351902173914\n",
      "Epoch: 3, Batch: 92, Loss: 0.14674222469329834, Accuracy: 95.80813172043011\n",
      "Epoch: 3, Batch: 93, Loss: 0.1560823619365692, Accuracy: 95.7779255319149\n",
      "Epoch: 3, Batch: 94, Loss: 0.10021540522575378, Accuracy: 95.76480263157895\n",
      "Epoch: 3, Batch: 95, Loss: 0.14205218851566315, Accuracy: 95.751953125\n",
      "Epoch: 3, Batch: 96, Loss: 0.13818910717964172, Accuracy: 95.74742268041237\n",
      "Epoch: 3, Batch: 97, Loss: 0.09972863644361496, Accuracy: 95.74298469387756\n",
      "Epoch: 3, Batch: 98, Loss: 0.1052454337477684, Accuracy: 95.74652777777779\n",
      "Epoch: 3, Batch: 99, Loss: 0.17421168088912964, Accuracy: 95.734375\n",
      "Epoch: 3, Batch: 100, Loss: 0.11296448111534119, Accuracy: 95.72246287128714\n",
      "Epoch: 3, Batch: 101, Loss: 0.13098326325416565, Accuracy: 95.7107843137255\n",
      "Epoch: 3, Batch: 102, Loss: 0.17518815398216248, Accuracy: 95.68416262135922\n",
      "Epoch: 3, Batch: 103, Loss: 0.07850096374750137, Accuracy: 95.69561298076923\n",
      "Epoch: 3, Batch: 104, Loss: 0.1736592948436737, Accuracy: 95.65476190476191\n",
      "Epoch: 3, Batch: 105, Loss: 0.1884574592113495, Accuracy: 95.60731132075472\n",
      "Epoch: 3, Batch: 106, Loss: 0.11261314898729324, Accuracy: 95.5972546728972\n",
      "Epoch: 3, Batch: 107, Loss: 0.113621786236763, Accuracy: 95.59461805555556\n",
      "Epoch: 3, Batch: 108, Loss: 0.1809971183538437, Accuracy: 95.57052752293578\n",
      "Epoch: 3, Batch: 109, Loss: 0.07965665310621262, Accuracy: 95.58948863636364\n",
      "Epoch: 3, Batch: 110, Loss: 0.10812817513942719, Accuracy: 95.57995495495496\n",
      "Epoch: 3, Batch: 111, Loss: 0.18390873074531555, Accuracy: 95.57059151785714\n",
      "Epoch: 3, Batch: 112, Loss: 0.2227083146572113, Accuracy: 95.53373893805309\n",
      "Epoch: 3, Batch: 113, Loss: 0.1523430347442627, Accuracy: 95.53179824561403\n",
      "Epoch: 3, Batch: 114, Loss: 0.10779371112585068, Accuracy: 95.55027173913044\n",
      "Epoch: 3, Batch: 115, Loss: 0.07883459329605103, Accuracy: 95.56169181034483\n",
      "Epoch: 3, Batch: 116, Loss: 0.14422135055065155, Accuracy: 95.57959401709401\n",
      "Epoch: 3, Batch: 117, Loss: 0.13334782421588898, Accuracy: 95.58395127118644\n",
      "Epoch: 3, Batch: 118, Loss: 0.155221626162529, Accuracy: 95.59480042016807\n",
      "Epoch: 3, Batch: 119, Loss: 0.23937560617923737, Accuracy: 95.56640625\n",
      "Epoch: 3, Batch: 120, Loss: 0.15066514909267426, Accuracy: 95.56430785123968\n",
      "Epoch: 3, Batch: 121, Loss: 0.13824081420898438, Accuracy: 95.55584016393442\n",
      "Epoch: 3, Batch: 122, Loss: 0.1604950875043869, Accuracy: 95.5665650406504\n",
      "Epoch: 3, Batch: 123, Loss: 0.19181416928768158, Accuracy: 95.55191532258065\n",
      "Epoch: 3, Batch: 124, Loss: 0.1187448799610138, Accuracy: 95.55\n",
      "Epoch: 3, Batch: 125, Loss: 0.07121528685092926, Accuracy: 95.57291666666666\n",
      "Epoch: 3, Batch: 126, Loss: 0.11575960367918015, Accuracy: 95.58932086614173\n",
      "Epoch: 3, Batch: 127, Loss: 0.1658869832754135, Accuracy: 95.574951171875\n",
      "Epoch: 3, Batch: 128, Loss: 0.13525456190109253, Accuracy: 95.57291666666666\n",
      "Epoch: 3, Batch: 129, Loss: 0.0889136791229248, Accuracy: 95.57692307692308\n",
      "Epoch: 3, Batch: 130, Loss: 0.20071086287498474, Accuracy: 95.55104961832062\n",
      "Epoch: 3, Batch: 131, Loss: 0.07969065755605698, Accuracy: 95.56699810606061\n",
      "Epoch: 3, Batch: 132, Loss: 0.13586510717868805, Accuracy: 95.55921052631578\n",
      "Epoch: 3, Batch: 133, Loss: 0.1236688643693924, Accuracy: 95.55153917910447\n",
      "Epoch: 3, Batch: 134, Loss: 0.05428207665681839, Accuracy: 95.57291666666666\n",
      "Epoch: 3, Batch: 135, Loss: 0.24597741663455963, Accuracy: 95.54227941176471\n",
      "Epoch: 3, Batch: 136, Loss: 0.20347470045089722, Accuracy: 95.52349452554745\n",
      "Epoch: 3, Batch: 137, Loss: 0.16316737234592438, Accuracy: 95.52196557971014\n",
      "Epoch: 3, Batch: 138, Loss: 0.08825422823429108, Accuracy: 95.53169964028777\n",
      "Epoch: 3, Batch: 139, Loss: 0.0444776676595211, Accuracy: 95.55245535714286\n",
      "Epoch: 3, Batch: 140, Loss: 0.17921677231788635, Accuracy: 95.51750886524822\n",
      "Epoch: 3, Batch: 141, Loss: 0.11571591347455978, Accuracy: 95.52706866197182\n",
      "Epoch: 3, Batch: 142, Loss: 0.1284453421831131, Accuracy: 95.5201048951049\n",
      "Epoch: 3, Batch: 143, Loss: 0.11572413146495819, Accuracy: 95.52951388888889\n",
      "Epoch: 3, Batch: 144, Loss: 0.11181200295686722, Accuracy: 95.53879310344827\n",
      "Epoch: 3, Batch: 145, Loss: 0.08313573896884918, Accuracy: 95.55329623287672\n",
      "Epoch: 3, Batch: 146, Loss: 0.1205453872680664, Accuracy: 95.53571428571429\n",
      "Epoch: 3, Batch: 147, Loss: 0.12193497270345688, Accuracy: 95.53420608108108\n",
      "Epoch: 3, Batch: 148, Loss: 0.176417738199234, Accuracy: 95.51698825503355\n",
      "Epoch: 3, Batch: 149, Loss: 0.08633114397525787, Accuracy: 95.52083333333333\n",
      "Epoch: 3, Batch: 150, Loss: 0.0816274881362915, Accuracy: 95.54014900662253\n",
      "Epoch: 3, Batch: 151, Loss: 0.1699090152978897, Accuracy: 95.51809210526315\n",
      "Epoch: 3, Batch: 152, Loss: 0.1043616235256195, Accuracy: 95.5218545751634\n",
      "Epoch: 3, Batch: 153, Loss: 0.09759371727705002, Accuracy: 95.52556818181817\n",
      "Epoch: 3, Batch: 154, Loss: 0.15226833522319794, Accuracy: 95.51411290322581\n",
      "Epoch: 3, Batch: 155, Loss: 0.09138749539852142, Accuracy: 95.52283653846155\n",
      "Epoch: 3, Batch: 156, Loss: 0.16500301659107208, Accuracy: 95.51652070063695\n",
      "Epoch: 3, Batch: 157, Loss: 0.13586702942848206, Accuracy: 95.52017405063292\n",
      "Epoch: 3, Batch: 158, Loss: 0.07882804423570633, Accuracy: 95.52869496855347\n",
      "Epoch: 3, Batch: 159, Loss: 0.13894014060497284, Accuracy: 95.5224609375\n",
      "Epoch: 3, Batch: 160, Loss: 0.17286594212055206, Accuracy: 95.51991420075075\n",
      "Epoch: 3, Training Loss: 0.13217204519958228\n",
      "Epoch: 3, Validation Loss: 0.399478055536747, Validation Accuracy: 85.02736512900704\n",
      "Epoch: 4, Batch: 0, Loss: 0.05289663374423981, Accuracy: 98.4375\n",
      "Epoch: 4, Batch: 1, Loss: 0.07733194530010223, Accuracy: 98.4375\n",
      "Epoch: 4, Batch: 2, Loss: 0.03129109740257263, Accuracy: 98.69791666666666\n",
      "Epoch: 4, Batch: 3, Loss: 0.04334941506385803, Accuracy: 98.6328125\n",
      "Epoch: 4, Batch: 4, Loss: 0.06640904396772385, Accuracy: 98.75\n",
      "Epoch: 4, Batch: 5, Loss: 0.07798104733228683, Accuracy: 98.56770833333334\n",
      "Epoch: 4, Batch: 6, Loss: 0.0663173571228981, Accuracy: 98.54910714285714\n",
      "Epoch: 4, Batch: 7, Loss: 0.043998993933200836, Accuracy: 98.53515625\n",
      "Epoch: 4, Batch: 8, Loss: 0.042571406811475754, Accuracy: 98.61111111111111\n",
      "Epoch: 4, Batch: 9, Loss: 0.07121315598487854, Accuracy: 98.515625\n",
      "Epoch: 4, Batch: 10, Loss: 0.07918012887239456, Accuracy: 98.29545454545455\n",
      "Epoch: 4, Batch: 11, Loss: 0.03410285711288452, Accuracy: 98.37239583333334\n",
      "Epoch: 4, Batch: 12, Loss: 0.07484038174152374, Accuracy: 98.37740384615384\n",
      "Epoch: 4, Batch: 13, Loss: 0.05386923998594284, Accuracy: 98.38169642857143\n",
      "Epoch: 4, Batch: 14, Loss: 0.04552982375025749, Accuracy: 98.4375\n",
      "Epoch: 4, Batch: 15, Loss: 0.10981424152851105, Accuracy: 98.33984375\n",
      "Epoch: 4, Batch: 16, Loss: 0.053381528705358505, Accuracy: 98.29963235294117\n",
      "Epoch: 4, Batch: 17, Loss: 0.06485439836978912, Accuracy: 98.35069444444444\n",
      "Epoch: 4, Batch: 18, Loss: 0.09216801822185516, Accuracy: 98.3141447368421\n",
      "Epoch: 4, Batch: 19, Loss: 0.035372547805309296, Accuracy: 98.3203125\n",
      "Epoch: 4, Batch: 20, Loss: 0.05173782631754875, Accuracy: 98.28869047619048\n",
      "Epoch: 4, Batch: 21, Loss: 0.04447118565440178, Accuracy: 98.3309659090909\n",
      "Epoch: 4, Batch: 22, Loss: 0.06004146859049797, Accuracy: 98.36956521739131\n",
      "Epoch: 4, Batch: 23, Loss: 0.12432729452848434, Accuracy: 98.27473958333334\n",
      "Epoch: 4, Batch: 24, Loss: 0.07064037024974823, Accuracy: 98.21875\n",
      "Epoch: 4, Batch: 25, Loss: 0.057814668864011765, Accuracy: 98.19711538461539\n",
      "Epoch: 4, Batch: 26, Loss: 0.05479846149682999, Accuracy: 98.17708333333334\n",
      "Epoch: 4, Batch: 27, Loss: 0.035450395196676254, Accuracy: 98.21428571428571\n",
      "Epoch: 4, Batch: 28, Loss: 0.07232905179262161, Accuracy: 98.16810344827587\n",
      "Epoch: 4, Batch: 29, Loss: 0.03112078458070755, Accuracy: 98.203125\n",
      "Epoch: 4, Batch: 30, Loss: 0.03451809287071228, Accuracy: 98.21068548387096\n",
      "Epoch: 4, Batch: 31, Loss: 0.07550187408924103, Accuracy: 98.193359375\n",
      "Epoch: 4, Batch: 32, Loss: 0.052072539925575256, Accuracy: 98.17708333333334\n",
      "Epoch: 4, Batch: 33, Loss: 0.15580303966999054, Accuracy: 98.16176470588235\n",
      "Epoch: 4, Batch: 34, Loss: 0.06905300915241241, Accuracy: 98.14732142857143\n",
      "Epoch: 4, Batch: 35, Loss: 0.06065775081515312, Accuracy: 98.13368055555556\n",
      "Epoch: 4, Batch: 36, Loss: 0.08834008872509003, Accuracy: 98.12077702702703\n",
      "Epoch: 4, Batch: 37, Loss: 0.07686509937047958, Accuracy: 98.12911184210526\n",
      "Epoch: 4, Batch: 38, Loss: 0.05282196030020714, Accuracy: 98.15705128205127\n",
      "Epoch: 4, Batch: 39, Loss: 0.05751625820994377, Accuracy: 98.14453125\n",
      "Epoch: 4, Batch: 40, Loss: 0.15933038294315338, Accuracy: 98.07545731707317\n",
      "Epoch: 4, Batch: 41, Loss: 0.07052912563085556, Accuracy: 98.046875\n",
      "Epoch: 4, Batch: 42, Loss: 0.07671238481998444, Accuracy: 98.03779069767442\n",
      "Epoch: 4, Batch: 43, Loss: 0.07898474484682083, Accuracy: 98.02911931818183\n",
      "Epoch: 4, Batch: 44, Loss: 0.11960510164499283, Accuracy: 97.98611111111111\n",
      "Epoch: 4, Batch: 45, Loss: 0.15938319265842438, Accuracy: 97.97894021739131\n",
      "Epoch: 4, Batch: 46, Loss: 0.07276169210672379, Accuracy: 98.00531914893617\n",
      "Epoch: 4, Batch: 47, Loss: 0.13869799673557281, Accuracy: 97.96549479166666\n",
      "Epoch: 4, Batch: 48, Loss: 0.03657323122024536, Accuracy: 97.9751275510204\n",
      "Epoch: 4, Batch: 49, Loss: 0.06198382377624512, Accuracy: 97.984375\n",
      "Epoch: 4, Batch: 50, Loss: 0.027056630700826645, Accuracy: 98.02389705882352\n",
      "Epoch: 4, Batch: 51, Loss: 0.06758135557174683, Accuracy: 98.046875\n",
      "Epoch: 4, Batch: 52, Loss: 0.05441940948367119, Accuracy: 98.05424528301887\n",
      "Epoch: 4, Batch: 53, Loss: 0.08483428508043289, Accuracy: 98.01793981481481\n",
      "Epoch: 4, Batch: 54, Loss: 0.08628161251544952, Accuracy: 98.01136363636364\n",
      "Epoch: 4, Batch: 55, Loss: 0.08985298871994019, Accuracy: 97.97712053571429\n",
      "Epoch: 4, Batch: 56, Loss: 0.05592264235019684, Accuracy: 97.97149122807018\n",
      "Epoch: 4, Batch: 57, Loss: 0.022235289216041565, Accuracy: 98.00646551724138\n",
      "Epoch: 4, Batch: 58, Loss: 0.028643157333135605, Accuracy: 98.04025423728814\n",
      "Epoch: 4, Batch: 59, Loss: 0.036129046231508255, Accuracy: 98.046875\n",
      "Epoch: 4, Batch: 60, Loss: 0.0585368275642395, Accuracy: 98.05327868852459\n",
      "Epoch: 4, Batch: 61, Loss: 0.07781632244586945, Accuracy: 98.02167338709677\n",
      "Epoch: 4, Batch: 62, Loss: 0.0948360338807106, Accuracy: 97.97867063492063\n",
      "Epoch: 4, Batch: 63, Loss: 0.13286595046520233, Accuracy: 97.96142578125\n",
      "Epoch: 4, Batch: 64, Loss: 0.03529096022248268, Accuracy: 97.98076923076923\n",
      "Epoch: 4, Batch: 65, Loss: 0.044442594051361084, Accuracy: 97.98768939393939\n",
      "Epoch: 4, Batch: 66, Loss: 0.11901389062404633, Accuracy: 97.97108208955224\n",
      "Epoch: 4, Batch: 67, Loss: 0.021851200610399246, Accuracy: 97.98943014705883\n",
      "Epoch: 4, Batch: 68, Loss: 0.1203775405883789, Accuracy: 97.96195652173914\n",
      "Epoch: 4, Batch: 69, Loss: 0.01817558892071247, Accuracy: 97.99107142857143\n",
      "Epoch: 4, Batch: 70, Loss: 0.0481271967291832, Accuracy: 98.00836267605634\n",
      "Epoch: 4, Batch: 71, Loss: 0.09081389755010605, Accuracy: 98.01432291666666\n",
      "Epoch: 4, Batch: 72, Loss: 0.07636146247386932, Accuracy: 98.00941780821918\n",
      "Epoch: 4, Batch: 73, Loss: 0.06052010878920555, Accuracy: 98.00464527027027\n",
      "Epoch: 4, Batch: 74, Loss: 0.042621828615665436, Accuracy: 98.01041666666667\n",
      "Epoch: 4, Batch: 75, Loss: 0.08047456294298172, Accuracy: 98.00575657894737\n",
      "Epoch: 4, Batch: 76, Loss: 0.025778422132134438, Accuracy: 98.01136363636364\n",
      "Epoch: 4, Batch: 77, Loss: 0.02599455788731575, Accuracy: 98.02684294871796\n",
      "Epoch: 4, Batch: 78, Loss: 0.06773120909929276, Accuracy: 98.02215189873418\n",
      "Epoch: 4, Batch: 79, Loss: 0.0766269639134407, Accuracy: 98.0078125\n",
      "Epoch: 4, Batch: 80, Loss: 0.048880480229854584, Accuracy: 98.02276234567901\n",
      "Epoch: 4, Batch: 81, Loss: 0.0663934126496315, Accuracy: 98.01829268292683\n",
      "Epoch: 4, Batch: 82, Loss: 0.03778170421719551, Accuracy: 98.03275602409639\n",
      "Epoch: 4, Batch: 83, Loss: 0.10413915663957596, Accuracy: 98.01897321428571\n",
      "Epoch: 4, Batch: 84, Loss: 0.0775095671415329, Accuracy: 98.01470588235294\n",
      "Epoch: 4, Batch: 85, Loss: 0.06785202026367188, Accuracy: 98.01053779069767\n",
      "Epoch: 4, Batch: 86, Loss: 0.06930196285247803, Accuracy: 98.02442528735632\n",
      "Epoch: 4, Batch: 87, Loss: 0.054216813296079636, Accuracy: 98.02024147727273\n",
      "Epoch: 4, Batch: 88, Loss: 0.08913777023553848, Accuracy: 98.01615168539325\n",
      "Epoch: 4, Batch: 89, Loss: 0.05016489326953888, Accuracy: 98.02083333333333\n",
      "Epoch: 4, Batch: 90, Loss: 0.04529082030057907, Accuracy: 98.01682692307693\n",
      "Epoch: 4, Batch: 91, Loss: 0.08696519583463669, Accuracy: 98.02139945652173\n",
      "Epoch: 4, Batch: 92, Loss: 0.02686367742717266, Accuracy: 98.03427419354838\n",
      "Epoch: 4, Batch: 93, Loss: 0.06766802072525024, Accuracy: 98.03025265957447\n",
      "Epoch: 4, Batch: 94, Loss: 0.06432552635669708, Accuracy: 98.04276315789474\n",
      "Epoch: 4, Batch: 95, Loss: 0.05448194593191147, Accuracy: 98.046875\n",
      "Epoch: 4, Batch: 96, Loss: 0.04264700785279274, Accuracy: 98.05090206185567\n",
      "Epoch: 4, Batch: 97, Loss: 0.06488247215747833, Accuracy: 98.05484693877551\n",
      "Epoch: 4, Batch: 98, Loss: 0.07630789279937744, Accuracy: 98.05082070707071\n",
      "Epoch: 4, Batch: 99, Loss: 0.052597127854824066, Accuracy: 98.0546875\n",
      "Epoch: 4, Batch: 100, Loss: 0.10554578900337219, Accuracy: 98.05074257425743\n",
      "Epoch: 4, Batch: 101, Loss: 0.12926970422267914, Accuracy: 98.03155637254902\n",
      "Epoch: 4, Batch: 102, Loss: 0.027025897055864334, Accuracy: 98.05066747572816\n",
      "Epoch: 4, Batch: 103, Loss: 0.07162097096443176, Accuracy: 98.05438701923077\n",
      "Epoch: 4, Batch: 104, Loss: 0.10526744276285172, Accuracy: 98.03571428571428\n",
      "Epoch: 4, Batch: 105, Loss: 0.0927998498082161, Accuracy: 98.0247641509434\n",
      "Epoch: 4, Batch: 106, Loss: 0.0842849388718605, Accuracy: 98.0286214953271\n",
      "Epoch: 4, Batch: 107, Loss: 0.1450178027153015, Accuracy: 98.01070601851852\n",
      "Epoch: 4, Batch: 108, Loss: 0.1414930820465088, Accuracy: 97.99311926605505\n",
      "Epoch: 4, Batch: 109, Loss: 0.1329442858695984, Accuracy: 97.97585227272727\n",
      "Epoch: 4, Batch: 110, Loss: 0.058716919273138046, Accuracy: 97.98001126126125\n",
      "Epoch: 4, Batch: 111, Loss: 0.05876798555254936, Accuracy: 97.97712053571429\n",
      "Epoch: 4, Batch: 112, Loss: 0.05090807005763054, Accuracy: 97.98119469026548\n",
      "Epoch: 4, Batch: 113, Loss: 0.1057421937584877, Accuracy: 97.97149122807018\n",
      "Epoch: 4, Batch: 114, Loss: 0.07349436730146408, Accuracy: 97.96875\n",
      "Epoch: 4, Batch: 115, Loss: 0.03250482305884361, Accuracy: 97.97279094827587\n",
      "Epoch: 4, Batch: 116, Loss: 0.0973103940486908, Accuracy: 97.96340811965813\n",
      "Epoch: 4, Batch: 117, Loss: 0.06508496403694153, Accuracy: 97.96080508474576\n",
      "Epoch: 4, Batch: 118, Loss: 0.03893670812249184, Accuracy: 97.96481092436974\n",
      "Epoch: 4, Batch: 119, Loss: 0.0841534361243248, Accuracy: 97.95572916666667\n",
      "Epoch: 4, Batch: 120, Loss: 0.12800835072994232, Accuracy: 97.9403409090909\n",
      "Epoch: 4, Batch: 121, Loss: 0.12492918223142624, Accuracy: 97.93160860655738\n",
      "Epoch: 4, Batch: 122, Loss: 0.061540376394987106, Accuracy: 97.92936991869918\n",
      "Epoch: 4, Batch: 123, Loss: 0.060658421367406845, Accuracy: 97.92716733870968\n",
      "Epoch: 4, Batch: 124, Loss: 0.04719266667962074, Accuracy: 97.925\n",
      "Epoch: 4, Batch: 125, Loss: 0.07589141279459, Accuracy: 97.92286706349206\n",
      "Epoch: 4, Batch: 126, Loss: 0.08139923214912415, Accuracy: 97.92076771653542\n",
      "Epoch: 4, Batch: 127, Loss: 0.047251682728528976, Accuracy: 97.918701171875\n",
      "Epoch: 4, Batch: 128, Loss: 0.0629415437579155, Accuracy: 97.92877906976744\n",
      "Epoch: 4, Batch: 129, Loss: 0.04219495505094528, Accuracy: 97.92067307692308\n",
      "Epoch: 4, Batch: 130, Loss: 0.15896478295326233, Accuracy: 97.89479961832062\n",
      "Epoch: 4, Batch: 131, Loss: 0.04502794146537781, Accuracy: 97.90482954545455\n",
      "Epoch: 4, Batch: 132, Loss: 0.1015406921505928, Accuracy: 97.89708646616542\n",
      "Epoch: 4, Batch: 133, Loss: 0.09345433115959167, Accuracy: 97.88945895522389\n",
      "Epoch: 4, Batch: 134, Loss: 0.05973149463534355, Accuracy: 97.89351851851852\n",
      "Epoch: 4, Batch: 135, Loss: 0.049874477088451385, Accuracy: 97.89751838235294\n",
      "Epoch: 4, Batch: 136, Loss: 0.04990281164646149, Accuracy: 97.90716240875912\n",
      "Epoch: 4, Batch: 137, Loss: 0.11511756479740143, Accuracy: 97.89968297101449\n",
      "Epoch: 4, Batch: 138, Loss: 0.11730484664440155, Accuracy: 97.89793165467626\n",
      "Epoch: 4, Batch: 139, Loss: 0.0937894657254219, Accuracy: 97.89620535714286\n",
      "Epoch: 4, Batch: 140, Loss: 0.05393465980887413, Accuracy: 97.90004432624113\n",
      "Epoch: 4, Batch: 141, Loss: 0.09577696025371552, Accuracy: 97.88732394366197\n",
      "Epoch: 4, Batch: 142, Loss: 0.022551119327545166, Accuracy: 97.9020979020979\n",
      "Epoch: 4, Batch: 143, Loss: 0.03061986342072487, Accuracy: 97.91666666666666\n",
      "Epoch: 4, Batch: 144, Loss: 0.09827510267496109, Accuracy: 97.91487068965517\n",
      "Epoch: 4, Batch: 145, Loss: 0.04095899313688278, Accuracy: 97.91845034246576\n",
      "Epoch: 4, Batch: 146, Loss: 0.03288302570581436, Accuracy: 97.92729591836735\n",
      "Epoch: 4, Batch: 147, Loss: 0.03489960357546806, Accuracy: 97.93074324324324\n",
      "Epoch: 4, Batch: 148, Loss: 0.1500493735074997, Accuracy: 97.90792785234899\n",
      "Epoch: 4, Batch: 149, Loss: 0.07875343412160873, Accuracy: 97.90104166666667\n",
      "Epoch: 4, Batch: 150, Loss: 0.028654353693127632, Accuracy: 97.90976821192054\n",
      "Epoch: 4, Batch: 151, Loss: 0.047058600932359695, Accuracy: 97.91324013157895\n",
      "Epoch: 4, Batch: 152, Loss: 0.13055171072483063, Accuracy: 97.90645424836602\n",
      "Epoch: 4, Batch: 153, Loss: 0.05189916118979454, Accuracy: 97.90482954545455\n",
      "Epoch: 4, Batch: 154, Loss: 0.062034789472818375, Accuracy: 97.89818548387098\n",
      "Epoch: 4, Batch: 155, Loss: 0.0729132890701294, Accuracy: 97.88661858974359\n",
      "Epoch: 4, Batch: 156, Loss: 0.057922638952732086, Accuracy: 97.88515127388536\n",
      "Epoch: 4, Batch: 157, Loss: 0.03533114865422249, Accuracy: 97.88370253164557\n",
      "Epoch: 4, Batch: 158, Loss: 0.10145639628171921, Accuracy: 97.88227201257862\n",
      "Epoch: 4, Batch: 159, Loss: 0.04934101924300194, Accuracy: 97.880859375\n",
      "Epoch: 4, Batch: 160, Loss: 0.10526885837316513, Accuracy: 97.8793935553064\n",
      "Epoch: 4, Training Loss: 0.0703992367901417\n",
      "Epoch: 4, Validation Loss: 0.5004635065793991, Validation Accuracy: 84.71462079749804\n",
      "Epoch: 5, Batch: 0, Loss: 0.04050304740667343, Accuracy: 99.21875\n",
      "Epoch: 5, Batch: 1, Loss: 0.00830012559890747, Accuracy: 99.609375\n",
      "Epoch: 5, Batch: 2, Loss: 0.05162514001131058, Accuracy: 99.21875\n",
      "Epoch: 5, Batch: 3, Loss: 0.016833048313856125, Accuracy: 99.21875\n",
      "Epoch: 5, Batch: 4, Loss: 0.012413734570145607, Accuracy: 99.375\n",
      "Epoch: 5, Batch: 5, Loss: 0.027054104954004288, Accuracy: 99.34895833333334\n",
      "Epoch: 5, Batch: 6, Loss: 0.022821329534053802, Accuracy: 99.33035714285714\n",
      "Epoch: 5, Batch: 7, Loss: 0.013096332550048828, Accuracy: 99.4140625\n",
      "Epoch: 5, Batch: 8, Loss: 0.0165934469550848, Accuracy: 99.47916666666666\n",
      "Epoch: 5, Batch: 9, Loss: 0.01759820245206356, Accuracy: 99.453125\n",
      "Epoch: 5, Batch: 10, Loss: 0.03799302130937576, Accuracy: 99.43181818181817\n",
      "Epoch: 5, Batch: 11, Loss: 0.051084619015455246, Accuracy: 99.4140625\n",
      "Epoch: 5, Batch: 12, Loss: 0.039327651262283325, Accuracy: 99.3389423076923\n",
      "Epoch: 5, Batch: 13, Loss: 0.04431069269776344, Accuracy: 99.27455357142857\n",
      "Epoch: 5, Batch: 14, Loss: 0.01187917310744524, Accuracy: 99.32291666666667\n",
      "Epoch: 5, Batch: 15, Loss: 0.06012444570660591, Accuracy: 99.31640625\n",
      "Epoch: 5, Batch: 16, Loss: 0.020202811807394028, Accuracy: 99.31066176470588\n",
      "Epoch: 5, Batch: 17, Loss: 0.10999968647956848, Accuracy: 99.21875\n",
      "Epoch: 5, Batch: 18, Loss: 0.015829365700483322, Accuracy: 99.25986842105263\n",
      "Epoch: 5, Batch: 19, Loss: 0.04465138539671898, Accuracy: 99.2578125\n",
      "Epoch: 5, Batch: 20, Loss: 0.07169835269451141, Accuracy: 99.21875\n",
      "Epoch: 5, Batch: 21, Loss: 0.03927810117602348, Accuracy: 99.18323863636364\n",
      "Epoch: 5, Batch: 22, Loss: 0.030053069815039635, Accuracy: 99.18478260869566\n",
      "Epoch: 5, Batch: 23, Loss: 0.03101620264351368, Accuracy: 99.15364583333334\n",
      "Epoch: 5, Batch: 24, Loss: 0.017377549782395363, Accuracy: 99.15625\n",
      "Epoch: 5, Batch: 25, Loss: 0.008851319551467896, Accuracy: 99.18870192307693\n",
      "Epoch: 5, Batch: 26, Loss: 0.050341591238975525, Accuracy: 99.16087962962963\n",
      "Epoch: 5, Batch: 27, Loss: 0.03343065083026886, Accuracy: 99.10714285714286\n",
      "Epoch: 5, Batch: 28, Loss: 0.008923065848648548, Accuracy: 99.13793103448276\n",
      "Epoch: 5, Batch: 29, Loss: 0.05618109554052353, Accuracy: 99.140625\n",
      "Epoch: 5, Batch: 30, Loss: 0.00647383090108633, Accuracy: 99.16834677419355\n",
      "Epoch: 5, Batch: 31, Loss: 0.0658932477235794, Accuracy: 99.1455078125\n",
      "Epoch: 5, Batch: 32, Loss: 0.021485598757863045, Accuracy: 99.14772727272727\n",
      "Epoch: 5, Batch: 33, Loss: 0.040401656180620193, Accuracy: 99.08088235294117\n",
      "Epoch: 5, Batch: 34, Loss: 0.05021684244275093, Accuracy: 99.08482142857142\n",
      "Epoch: 5, Batch: 35, Loss: 0.01993563584983349, Accuracy: 99.08854166666666\n",
      "Epoch: 5, Batch: 36, Loss: 0.00944635458290577, Accuracy: 99.11317567567568\n",
      "Epoch: 5, Batch: 37, Loss: 0.015676511451601982, Accuracy: 99.11595394736842\n",
      "Epoch: 5, Batch: 38, Loss: 0.0826743096113205, Accuracy: 99.05849358974359\n",
      "Epoch: 5, Batch: 39, Loss: 0.09201227128505707, Accuracy: 99.00390625\n",
      "Epoch: 5, Batch: 40, Loss: 0.07686486840248108, Accuracy: 99.00914634146342\n",
      "Epoch: 5, Batch: 41, Loss: 0.03241278603672981, Accuracy: 98.99553571428571\n",
      "Epoch: 5, Batch: 42, Loss: 0.03507962077856064, Accuracy: 98.98255813953489\n",
      "Epoch: 5, Batch: 43, Loss: 0.011786812916398048, Accuracy: 99.00568181818183\n",
      "Epoch: 5, Batch: 44, Loss: 0.013662968762218952, Accuracy: 99.01041666666667\n",
      "Epoch: 5, Batch: 45, Loss: 0.04954688996076584, Accuracy: 98.98097826086956\n",
      "Epoch: 5, Batch: 46, Loss: 0.046591900289058685, Accuracy: 98.96941489361703\n",
      "Epoch: 5, Batch: 47, Loss: 0.07781512290239334, Accuracy: 98.94205729166666\n",
      "Epoch: 5, Batch: 48, Loss: 0.014003085903823376, Accuracy: 98.96364795918367\n",
      "Epoch: 5, Batch: 49, Loss: 0.050052594393491745, Accuracy: 98.921875\n",
      "Epoch: 5, Batch: 50, Loss: 0.09468688070774078, Accuracy: 98.91237745098039\n",
      "Epoch: 5, Batch: 51, Loss: 0.007283574435859919, Accuracy: 98.93329326923077\n",
      "Epoch: 5, Batch: 52, Loss: 0.03409671410918236, Accuracy: 98.92393867924528\n",
      "Epoch: 5, Batch: 53, Loss: 0.03536025062203407, Accuracy: 98.92939814814815\n",
      "Epoch: 5, Batch: 54, Loss: 0.014780060388147831, Accuracy: 98.9346590909091\n",
      "Epoch: 5, Batch: 55, Loss: 0.014783812686800957, Accuracy: 98.93973214285714\n",
      "Epoch: 5, Batch: 56, Loss: 0.026362329721450806, Accuracy: 98.94462719298247\n",
      "Epoch: 5, Batch: 57, Loss: 0.05230359733104706, Accuracy: 98.92241379310344\n",
      "Epoch: 5, Batch: 58, Loss: 0.13717973232269287, Accuracy: 98.86122881355932\n",
      "Epoch: 5, Batch: 59, Loss: 0.07374285906553268, Accuracy: 98.84114583333333\n",
      "Epoch: 5, Batch: 60, Loss: 0.020349204540252686, Accuracy: 98.84733606557377\n",
      "Epoch: 5, Batch: 61, Loss: 0.032420698553323746, Accuracy: 98.85332661290323\n",
      "Epoch: 5, Batch: 62, Loss: 0.10068179666996002, Accuracy: 98.82192460317461\n",
      "Epoch: 5, Batch: 63, Loss: 0.05873546376824379, Accuracy: 98.8037109375\n",
      "Epoch: 5, Batch: 64, Loss: 0.030486732721328735, Accuracy: 98.79807692307693\n",
      "Epoch: 5, Batch: 65, Loss: 0.12736555933952332, Accuracy: 98.76893939393939\n",
      "Epoch: 5, Batch: 66, Loss: 0.12004947662353516, Accuracy: 98.75233208955224\n",
      "Epoch: 5, Batch: 67, Loss: 0.03279153257608414, Accuracy: 98.75919117647058\n",
      "Epoch: 5, Batch: 68, Loss: 0.07487257570028305, Accuracy: 98.75452898550725\n",
      "Epoch: 5, Batch: 69, Loss: 0.0549095943570137, Accuracy: 98.73883928571429\n",
      "Epoch: 5, Batch: 70, Loss: 0.054727062582969666, Accuracy: 98.7455985915493\n",
      "Epoch: 5, Batch: 71, Loss: 0.07770278304815292, Accuracy: 98.73046875\n",
      "Epoch: 5, Batch: 72, Loss: 0.040049780160188675, Accuracy: 98.73715753424658\n",
      "Epoch: 5, Batch: 73, Loss: 0.05435992777347565, Accuracy: 98.72255067567568\n",
      "Epoch: 5, Batch: 74, Loss: 0.017860068008303642, Accuracy: 98.73958333333334\n",
      "Epoch: 5, Batch: 75, Loss: 0.016446184366941452, Accuracy: 98.7561677631579\n",
      "Epoch: 5, Batch: 76, Loss: 0.02417108230292797, Accuracy: 98.76217532467533\n",
      "Epoch: 5, Batch: 77, Loss: 0.040033817291259766, Accuracy: 98.75801282051282\n",
      "Epoch: 5, Batch: 78, Loss: 0.09072331339120865, Accuracy: 98.73417721518987\n",
      "Epoch: 5, Batch: 79, Loss: 0.04328431561589241, Accuracy: 98.740234375\n",
      "Epoch: 5, Batch: 80, Loss: 0.03725757077336311, Accuracy: 98.73649691358025\n",
      "Epoch: 5, Batch: 81, Loss: 0.018206380307674408, Accuracy: 98.75190548780488\n",
      "Epoch: 5, Batch: 82, Loss: 0.06314411014318466, Accuracy: 98.73870481927712\n",
      "Epoch: 5, Batch: 83, Loss: 0.022388041019439697, Accuracy: 98.75372023809523\n",
      "Epoch: 5, Batch: 84, Loss: 0.07561413943767548, Accuracy: 98.75\n",
      "Epoch: 5, Batch: 85, Loss: 0.044696781784296036, Accuracy: 98.74636627906976\n",
      "Epoch: 5, Batch: 86, Loss: 0.11354108899831772, Accuracy: 98.72485632183908\n",
      "Epoch: 5, Batch: 87, Loss: 0.01283038966357708, Accuracy: 98.7393465909091\n",
      "Epoch: 5, Batch: 88, Loss: 0.03977762162685394, Accuracy: 98.73595505617978\n",
      "Epoch: 5, Batch: 89, Loss: 0.014074563980102539, Accuracy: 98.75\n",
      "Epoch: 5, Batch: 90, Loss: 0.02453368343412876, Accuracy: 98.74656593406593\n",
      "Epoch: 5, Batch: 91, Loss: 0.01645917259156704, Accuracy: 98.75169836956522\n",
      "Epoch: 5, Batch: 92, Loss: 0.02710641548037529, Accuracy: 98.75672043010752\n",
      "Epoch: 5, Batch: 93, Loss: 0.06532537192106247, Accuracy: 98.7533244680851\n",
      "Epoch: 5, Batch: 94, Loss: 0.04415733367204666, Accuracy: 98.75822368421052\n",
      "Epoch: 5, Batch: 95, Loss: 0.04762618988752365, Accuracy: 98.7548828125\n",
      "Epoch: 5, Batch: 96, Loss: 0.05345034599304199, Accuracy: 98.74355670103093\n",
      "Epoch: 5, Batch: 97, Loss: 0.06967244297266006, Accuracy: 98.73246173469387\n",
      "Epoch: 5, Batch: 98, Loss: 0.027523430064320564, Accuracy: 98.73737373737373\n",
      "Epoch: 5, Batch: 99, Loss: 0.04348985105752945, Accuracy: 98.7421875\n",
      "Epoch: 5, Batch: 100, Loss: 0.013111182488501072, Accuracy: 98.7546410891089\n",
      "Epoch: 5, Batch: 101, Loss: 0.06436259299516678, Accuracy: 98.74387254901961\n",
      "Epoch: 5, Batch: 102, Loss: 0.07406961917877197, Accuracy: 98.73331310679612\n",
      "Epoch: 5, Batch: 103, Loss: 0.14727331697940826, Accuracy: 98.7079326923077\n",
      "Epoch: 5, Batch: 104, Loss: 0.1088324710726738, Accuracy: 98.69791666666666\n",
      "Epoch: 5, Batch: 105, Loss: 0.04555722698569298, Accuracy: 98.69545990566037\n",
      "Epoch: 5, Batch: 106, Loss: 0.08023443818092346, Accuracy: 98.68574766355141\n",
      "Epoch: 5, Batch: 107, Loss: 0.07086022943258286, Accuracy: 98.66898148148148\n",
      "Epoch: 5, Batch: 108, Loss: 0.028266899287700653, Accuracy: 98.6740252293578\n",
      "Epoch: 5, Batch: 109, Loss: 0.0599205307662487, Accuracy: 98.65767045454545\n",
      "Epoch: 5, Batch: 110, Loss: 0.017481250688433647, Accuracy: 98.66976351351352\n",
      "Epoch: 5, Batch: 111, Loss: 0.023002704605460167, Accuracy: 98.67466517857143\n",
      "Epoch: 5, Batch: 112, Loss: 0.029580211266875267, Accuracy: 98.67948008849558\n",
      "Epoch: 5, Batch: 113, Loss: 0.0080894585698843, Accuracy: 98.69106359649122\n",
      "Epoch: 5, Batch: 114, Loss: 0.076154924929142, Accuracy: 98.6820652173913\n",
      "Epoch: 5, Batch: 115, Loss: 0.02026583068072796, Accuracy: 98.68669181034483\n",
      "Epoch: 5, Batch: 116, Loss: 0.008946124464273453, Accuracy: 98.69791666666666\n",
      "Epoch: 5, Batch: 117, Loss: 0.04025968164205551, Accuracy: 98.70233050847457\n",
      "Epoch: 5, Batch: 118, Loss: 0.015227504074573517, Accuracy: 98.70667016806722\n",
      "Epoch: 5, Batch: 119, Loss: 0.02301265299320221, Accuracy: 98.71744791666667\n",
      "Epoch: 5, Batch: 120, Loss: 0.028193965554237366, Accuracy: 98.7215909090909\n",
      "Epoch: 5, Batch: 121, Loss: 0.028258537873625755, Accuracy: 98.72566598360656\n",
      "Epoch: 5, Batch: 122, Loss: 0.036523424088954926, Accuracy: 98.7233231707317\n",
      "Epoch: 5, Batch: 123, Loss: 0.009615458548069, Accuracy: 98.7336189516129\n",
      "Epoch: 5, Batch: 124, Loss: 0.02337482199072838, Accuracy: 98.7375\n",
      "Epoch: 5, Batch: 125, Loss: 0.05288701504468918, Accuracy: 98.72891865079364\n",
      "Epoch: 5, Batch: 126, Loss: 0.014429577626287937, Accuracy: 98.73892716535433\n",
      "Epoch: 5, Batch: 127, Loss: 0.043501418083906174, Accuracy: 98.736572265625\n",
      "Epoch: 5, Batch: 128, Loss: 0.08382758498191833, Accuracy: 98.72819767441861\n",
      "Epoch: 5, Batch: 129, Loss: 0.04712161049246788, Accuracy: 98.72596153846153\n",
      "Epoch: 5, Batch: 130, Loss: 0.06289627403020859, Accuracy: 98.72375954198473\n",
      "Epoch: 5, Batch: 131, Loss: 0.02312593162059784, Accuracy: 98.72750946969697\n",
      "Epoch: 5, Batch: 132, Loss: 0.047796666622161865, Accuracy: 98.7312030075188\n",
      "Epoch: 5, Batch: 133, Loss: 0.0665525272488594, Accuracy: 98.73484141791045\n",
      "Epoch: 5, Batch: 134, Loss: 0.10883676260709763, Accuracy: 98.72106481481482\n",
      "Epoch: 5, Batch: 135, Loss: 0.04177882894873619, Accuracy: 98.71897977941177\n",
      "Epoch: 5, Batch: 136, Loss: 0.02759227715432644, Accuracy: 98.71692518248175\n",
      "Epoch: 5, Batch: 137, Loss: 0.05327858030796051, Accuracy: 98.71490036231883\n",
      "Epoch: 5, Batch: 138, Loss: 0.09624037146568298, Accuracy: 98.70728417266187\n",
      "Epoch: 5, Batch: 139, Loss: 0.023041363805532455, Accuracy: 98.7109375\n",
      "Epoch: 5, Batch: 140, Loss: 0.10691634565591812, Accuracy: 98.70899822695036\n",
      "Epoch: 5, Batch: 141, Loss: 0.07275093346834183, Accuracy: 98.70708626760563\n",
      "Epoch: 5, Batch: 142, Loss: 0.02006990648806095, Accuracy: 98.71066433566433\n",
      "Epoch: 5, Batch: 143, Loss: 0.05542248114943504, Accuracy: 98.70876736111111\n",
      "Epoch: 5, Batch: 144, Loss: 0.02495475485920906, Accuracy: 98.71228448275862\n",
      "Epoch: 5, Batch: 145, Loss: 0.07245456427335739, Accuracy: 98.70505136986301\n",
      "Epoch: 5, Batch: 146, Loss: 0.06657415628433228, Accuracy: 98.69791666666666\n",
      "Epoch: 5, Batch: 147, Loss: 0.06734666973352432, Accuracy: 98.69087837837837\n",
      "Epoch: 5, Batch: 148, Loss: 0.022196084260940552, Accuracy: 98.6944211409396\n",
      "Epoch: 5, Batch: 149, Loss: 0.036294858902692795, Accuracy: 98.69270833333333\n",
      "Epoch: 5, Batch: 150, Loss: 0.053748324513435364, Accuracy: 98.69101821192054\n",
      "Epoch: 5, Batch: 151, Loss: 0.08634555339813232, Accuracy: 98.68935032894737\n",
      "Epoch: 5, Batch: 152, Loss: 0.04234008118510246, Accuracy: 98.68770424836602\n",
      "Epoch: 5, Batch: 153, Loss: 0.017802447080612183, Accuracy: 98.69622564935064\n",
      "Epoch: 5, Batch: 154, Loss: 0.021062500774860382, Accuracy: 98.69959677419354\n",
      "Epoch: 5, Batch: 155, Loss: 0.017092181369662285, Accuracy: 98.7079326923077\n",
      "Epoch: 5, Batch: 156, Loss: 0.04989166557788849, Accuracy: 98.7062101910828\n",
      "Epoch: 5, Batch: 157, Loss: 0.01750369742512703, Accuracy: 98.70945411392405\n",
      "Epoch: 5, Batch: 158, Loss: 0.030054846778512, Accuracy: 98.70774371069182\n",
      "Epoch: 5, Batch: 159, Loss: 0.020329494029283524, Accuracy: 98.7109375\n",
      "Epoch: 5, Batch: 160, Loss: 0.1466088443994522, Accuracy: 98.70813630380734\n",
      "Epoch: 5, Training Loss: 0.0447580324202452\n",
      "Epoch: 5, Validation Loss: 0.5388987690210343, Validation Accuracy: 85.10555121188429\n",
      "Epoch: 6, Batch: 0, Loss: 0.010980182327330112, Accuracy: 100.0\n",
      "Epoch: 6, Batch: 1, Loss: 0.01847521774470806, Accuracy: 99.609375\n",
      "Epoch: 6, Batch: 2, Loss: 0.036055244505405426, Accuracy: 99.21875\n",
      "Epoch: 6, Batch: 3, Loss: 0.010407203808426857, Accuracy: 99.4140625\n",
      "Epoch: 6, Batch: 4, Loss: 0.06130188703536987, Accuracy: 99.21875\n",
      "Epoch: 6, Batch: 5, Loss: 0.008697130717337132, Accuracy: 99.34895833333334\n",
      "Epoch: 6, Batch: 6, Loss: 0.016859982162714005, Accuracy: 99.33035714285714\n",
      "Epoch: 6, Batch: 7, Loss: 0.011590205132961273, Accuracy: 99.4140625\n",
      "Epoch: 6, Batch: 8, Loss: 0.024080496281385422, Accuracy: 99.30555555555556\n",
      "Epoch: 6, Batch: 9, Loss: 0.014926561154425144, Accuracy: 99.296875\n",
      "Epoch: 6, Batch: 10, Loss: 0.01612633280456066, Accuracy: 99.36079545454545\n",
      "Epoch: 6, Batch: 11, Loss: 0.011585087515413761, Accuracy: 99.4140625\n",
      "Epoch: 6, Batch: 12, Loss: 0.014433354139328003, Accuracy: 99.45913461538461\n",
      "Epoch: 6, Batch: 13, Loss: 0.03431271016597748, Accuracy: 99.44196428571429\n",
      "Epoch: 6, Batch: 14, Loss: 0.03291259706020355, Accuracy: 99.42708333333333\n",
      "Epoch: 6, Batch: 15, Loss: 0.019440149888396263, Accuracy: 99.4140625\n",
      "Epoch: 6, Batch: 16, Loss: 0.031095454469323158, Accuracy: 99.40257352941177\n",
      "Epoch: 6, Batch: 17, Loss: 0.00704752653837204, Accuracy: 99.43576388888889\n",
      "Epoch: 6, Batch: 18, Loss: 0.01964200660586357, Accuracy: 99.42434210526315\n",
      "Epoch: 6, Batch: 19, Loss: 0.01039163675159216, Accuracy: 99.453125\n",
      "Epoch: 6, Batch: 20, Loss: 0.029445286840200424, Accuracy: 99.44196428571429\n",
      "Epoch: 6, Batch: 21, Loss: 0.01195179671049118, Accuracy: 99.46732954545455\n",
      "Epoch: 6, Batch: 22, Loss: 0.056982629001140594, Accuracy: 99.4225543478261\n",
      "Epoch: 6, Batch: 23, Loss: 0.019334563985466957, Accuracy: 99.4140625\n",
      "Epoch: 6, Batch: 24, Loss: 0.013781323097646236, Accuracy: 99.40625\n",
      "Epoch: 6, Batch: 25, Loss: 0.03421533852815628, Accuracy: 99.36899038461539\n",
      "Epoch: 6, Batch: 26, Loss: 0.009994233027100563, Accuracy: 99.36342592592592\n",
      "Epoch: 6, Batch: 27, Loss: 0.008854951709508896, Accuracy: 99.38616071428571\n",
      "Epoch: 6, Batch: 28, Loss: 0.012375914491713047, Accuracy: 99.40732758620689\n",
      "Epoch: 6, Batch: 29, Loss: 0.05300125479698181, Accuracy: 99.375\n",
      "Epoch: 6, Batch: 30, Loss: 0.022599145770072937, Accuracy: 99.36995967741935\n",
      "Epoch: 6, Batch: 31, Loss: 0.020548881962895393, Accuracy: 99.365234375\n",
      "Epoch: 6, Batch: 32, Loss: 0.03060881979763508, Accuracy: 99.36079545454545\n",
      "Epoch: 6, Batch: 33, Loss: 0.0442359559237957, Accuracy: 99.31066176470588\n",
      "Epoch: 6, Batch: 34, Loss: 0.060734741389751434, Accuracy: 99.28571428571429\n",
      "Epoch: 6, Batch: 35, Loss: 0.025613998994231224, Accuracy: 99.26215277777779\n",
      "Epoch: 6, Batch: 36, Loss: 0.07396689057350159, Accuracy: 99.23986486486487\n",
      "Epoch: 6, Batch: 37, Loss: 0.0165055301040411, Accuracy: 99.23930921052632\n",
      "Epoch: 6, Batch: 38, Loss: 0.07574587315320969, Accuracy: 99.21875\n",
      "Epoch: 6, Batch: 39, Loss: 0.06052052602171898, Accuracy: 99.19921875\n",
      "Epoch: 6, Batch: 40, Loss: 0.04010585695505142, Accuracy: 99.16158536585365\n",
      "Epoch: 6, Batch: 41, Loss: 0.03485618531703949, Accuracy: 99.14434523809523\n",
      "Epoch: 6, Batch: 42, Loss: 0.046813949942588806, Accuracy: 99.10973837209302\n",
      "Epoch: 6, Batch: 43, Loss: 0.02516961470246315, Accuracy: 99.1122159090909\n",
      "Epoch: 6, Batch: 44, Loss: 0.010064462199807167, Accuracy: 99.13194444444444\n",
      "Epoch: 6, Batch: 45, Loss: 0.012820456176996231, Accuracy: 99.15081521739131\n",
      "Epoch: 6, Batch: 46, Loss: 0.01115917693823576, Accuracy: 99.1688829787234\n",
      "Epoch: 6, Batch: 47, Loss: 0.011966487392783165, Accuracy: 99.169921875\n",
      "Epoch: 6, Batch: 48, Loss: 0.03176569566130638, Accuracy: 99.17091836734694\n",
      "Epoch: 6, Batch: 49, Loss: 0.008979903534054756, Accuracy: 99.1875\n",
      "Epoch: 6, Batch: 50, Loss: 0.0135065708309412, Accuracy: 99.18811274509804\n",
      "Epoch: 6, Batch: 51, Loss: 0.06919355690479279, Accuracy: 99.17367788461539\n",
      "Epoch: 6, Batch: 52, Loss: 0.013631858862936497, Accuracy: 99.1745283018868\n",
      "Epoch: 6, Batch: 53, Loss: 0.018903372809290886, Accuracy: 99.17534722222221\n",
      "Epoch: 6, Batch: 54, Loss: 0.05473894625902176, Accuracy: 99.16193181818181\n",
      "Epoch: 6, Batch: 55, Loss: 0.008363477885723114, Accuracy: 99.17689732142857\n",
      "Epoch: 6, Batch: 56, Loss: 0.02451360411942005, Accuracy: 99.17763157894737\n",
      "Epoch: 6, Batch: 57, Loss: 0.16456520557403564, Accuracy: 99.13793103448276\n",
      "Epoch: 6, Batch: 58, Loss: 0.06008194014430046, Accuracy: 99.13930084745762\n",
      "Epoch: 6, Batch: 59, Loss: 0.049344439059495926, Accuracy: 99.11458333333333\n",
      "Epoch: 6, Batch: 60, Loss: 0.03277771547436714, Accuracy: 99.10348360655738\n",
      "Epoch: 6, Batch: 61, Loss: 0.01207080390304327, Accuracy: 99.1179435483871\n",
      "Epoch: 6, Batch: 62, Loss: 0.005727197974920273, Accuracy: 99.13194444444444\n",
      "Epoch: 6, Batch: 63, Loss: 0.052646975964307785, Accuracy: 99.12109375\n",
      "Epoch: 6, Batch: 64, Loss: 0.030565757304430008, Accuracy: 99.12259615384616\n",
      "Epoch: 6, Batch: 65, Loss: 0.07631456851959229, Accuracy: 99.10037878787878\n",
      "Epoch: 6, Batch: 66, Loss: 0.029906775802373886, Accuracy: 99.09048507462687\n",
      "Epoch: 6, Batch: 67, Loss: 0.0075434111058712006, Accuracy: 99.10386029411765\n",
      "Epoch: 6, Batch: 68, Loss: 0.040099870413541794, Accuracy: 99.09420289855072\n",
      "Epoch: 6, Batch: 69, Loss: 0.012213258072733879, Accuracy: 99.10714285714286\n",
      "Epoch: 6, Batch: 70, Loss: 0.019872406497597694, Accuracy: 99.1087147887324\n",
      "Epoch: 6, Batch: 71, Loss: 0.01609071157872677, Accuracy: 99.11024305555556\n",
      "Epoch: 6, Batch: 72, Loss: 0.012398611754179, Accuracy: 99.12243150684932\n",
      "Epoch: 6, Batch: 73, Loss: 0.036005742847919464, Accuracy: 99.1237331081081\n",
      "Epoch: 6, Batch: 74, Loss: 0.007040325086563826, Accuracy: 99.13541666666667\n",
      "Epoch: 6, Batch: 75, Loss: 0.02958335354924202, Accuracy: 99.13651315789474\n",
      "Epoch: 6, Batch: 76, Loss: 0.023769419640302658, Accuracy: 99.12743506493507\n",
      "Epoch: 6, Batch: 77, Loss: 0.011391517706215382, Accuracy: 99.12860576923077\n",
      "Epoch: 6, Batch: 78, Loss: 0.027026653289794922, Accuracy: 99.11985759493672\n",
      "Epoch: 6, Batch: 79, Loss: 0.02887881174683571, Accuracy: 99.111328125\n",
      "Epoch: 6, Batch: 80, Loss: 0.02420293726027012, Accuracy: 99.11265432098766\n",
      "Epoch: 6, Batch: 81, Loss: 0.014469427056610584, Accuracy: 99.1139481707317\n",
      "Epoch: 6, Batch: 82, Loss: 0.00524005014449358, Accuracy: 99.1246234939759\n",
      "Epoch: 6, Batch: 83, Loss: 0.006038844585418701, Accuracy: 99.13504464285714\n",
      "Epoch: 6, Batch: 84, Loss: 0.005113524850457907, Accuracy: 99.14522058823529\n",
      "Epoch: 6, Batch: 85, Loss: 0.025594601407647133, Accuracy: 99.14607558139535\n",
      "Epoch: 6, Batch: 86, Loss: 0.013003342784941196, Accuracy: 99.1558908045977\n",
      "Epoch: 6, Batch: 87, Loss: 0.013282706961035728, Accuracy: 99.16548295454545\n",
      "Epoch: 6, Batch: 88, Loss: 0.08838208019733429, Accuracy: 99.15730337078652\n",
      "Epoch: 6, Batch: 89, Loss: 0.016393084079027176, Accuracy: 99.15798611111111\n",
      "Epoch: 6, Batch: 90, Loss: 0.05291670560836792, Accuracy: 99.15006868131869\n",
      "Epoch: 6, Batch: 91, Loss: 0.006044292822480202, Accuracy: 99.15930706521739\n",
      "Epoch: 6, Batch: 92, Loss: 0.02118726819753647, Accuracy: 99.15994623655914\n",
      "Epoch: 6, Batch: 93, Loss: 0.010010753758251667, Accuracy: 99.1688829787234\n",
      "Epoch: 6, Batch: 94, Loss: 0.011772681958973408, Accuracy: 99.17763157894737\n",
      "Epoch: 6, Batch: 95, Loss: 0.03374101221561432, Accuracy: 99.17805989583334\n",
      "Epoch: 6, Batch: 96, Loss: 0.045215193182229996, Accuracy: 99.17042525773195\n",
      "Epoch: 6, Batch: 97, Loss: 0.0043469201773405075, Accuracy: 99.17889030612244\n",
      "Epoch: 6, Batch: 98, Loss: 0.004382007289677858, Accuracy: 99.18718434343434\n",
      "Epoch: 6, Batch: 99, Loss: 0.0155318733304739, Accuracy: 99.1875\n",
      "Epoch: 6, Batch: 100, Loss: 0.004737507086247206, Accuracy: 99.19554455445545\n",
      "Epoch: 6, Batch: 101, Loss: 0.04935793578624725, Accuracy: 99.19577205882352\n",
      "Epoch: 6, Batch: 102, Loss: 0.011300673708319664, Accuracy: 99.20358009708737\n",
      "Epoch: 6, Batch: 103, Loss: 0.002072638599202037, Accuracy: 99.21123798076923\n",
      "Epoch: 6, Batch: 104, Loss: 0.006347288843244314, Accuracy: 99.21875\n",
      "Epoch: 6, Batch: 105, Loss: 0.12293991446495056, Accuracy: 99.20400943396226\n",
      "Epoch: 6, Batch: 106, Loss: 0.0027363854460418224, Accuracy: 99.21144859813083\n",
      "Epoch: 6, Batch: 107, Loss: 0.00907884631305933, Accuracy: 99.21875\n",
      "Epoch: 6, Batch: 108, Loss: 0.0354735292494297, Accuracy: 99.21158256880734\n",
      "Epoch: 6, Batch: 109, Loss: 0.018403032794594765, Accuracy: 99.21164772727272\n",
      "Epoch: 6, Batch: 110, Loss: 0.026919590309262276, Accuracy: 99.20467342342343\n",
      "Epoch: 6, Batch: 111, Loss: 0.0129964929074049, Accuracy: 99.20479910714286\n",
      "Epoch: 6, Batch: 112, Loss: 0.047732532024383545, Accuracy: 99.19109513274337\n",
      "Epoch: 6, Batch: 113, Loss: 0.03156154602766037, Accuracy: 99.19133771929825\n",
      "Epoch: 6, Batch: 114, Loss: 0.0056538814678788185, Accuracy: 99.19836956521739\n",
      "Epoch: 6, Batch: 115, Loss: 0.03081626445055008, Accuracy: 99.19854525862068\n",
      "Epoch: 6, Batch: 116, Loss: 0.04740593954920769, Accuracy: 99.18536324786325\n",
      "Epoch: 6, Batch: 117, Loss: 0.0070470767095685005, Accuracy: 99.19226694915254\n",
      "Epoch: 6, Batch: 118, Loss: 0.03144372999668121, Accuracy: 99.19248949579831\n",
      "Epoch: 6, Batch: 119, Loss: 0.06400265544652939, Accuracy: 99.1796875\n",
      "Epoch: 6, Batch: 120, Loss: 0.06931716203689575, Accuracy: 99.16064049586777\n",
      "Epoch: 6, Batch: 121, Loss: 0.02307192236185074, Accuracy: 99.16111680327869\n",
      "Epoch: 6, Batch: 122, Loss: 0.07651256024837494, Accuracy: 99.14253048780488\n",
      "Epoch: 6, Batch: 123, Loss: 0.03713734820485115, Accuracy: 99.14314516129032\n",
      "Epoch: 6, Batch: 124, Loss: 0.004830981604754925, Accuracy: 99.15\n",
      "Epoch: 6, Batch: 125, Loss: 0.018198680132627487, Accuracy: 99.15054563492063\n",
      "Epoch: 6, Batch: 126, Loss: 0.01002045813947916, Accuracy: 99.1572342519685\n",
      "Epoch: 6, Batch: 127, Loss: 0.025283418595790863, Accuracy: 99.151611328125\n",
      "Epoch: 6, Batch: 128, Loss: 0.024739867076277733, Accuracy: 99.15213178294574\n",
      "Epoch: 6, Batch: 129, Loss: 0.010673483833670616, Accuracy: 99.15865384615384\n",
      "Epoch: 6, Batch: 130, Loss: 0.03168470785021782, Accuracy: 99.15911259541986\n",
      "Epoch: 6, Batch: 131, Loss: 0.027518456801772118, Accuracy: 99.15956439393939\n",
      "Epoch: 6, Batch: 132, Loss: 0.03643909841775894, Accuracy: 99.15413533834587\n",
      "Epoch: 6, Batch: 133, Loss: 0.006955922115594149, Accuracy: 99.16044776119402\n",
      "Epoch: 6, Batch: 134, Loss: 0.05593273043632507, Accuracy: 99.1550925925926\n",
      "Epoch: 6, Batch: 135, Loss: 0.03371867910027504, Accuracy: 99.14981617647058\n",
      "Epoch: 6, Batch: 136, Loss: 0.09263942390680313, Accuracy: 99.13321167883211\n",
      "Epoch: 6, Batch: 137, Loss: 0.05289391800761223, Accuracy: 99.12250905797102\n",
      "Epoch: 6, Batch: 138, Loss: 0.07133481651544571, Accuracy: 99.12320143884892\n",
      "Epoch: 6, Batch: 139, Loss: 0.050135288387537, Accuracy: 99.11830357142857\n",
      "Epoch: 6, Batch: 140, Loss: 0.007450826466083527, Accuracy: 99.12455673758865\n",
      "Epoch: 6, Batch: 141, Loss: 0.04368852451443672, Accuracy: 99.11971830985915\n",
      "Epoch: 6, Batch: 142, Loss: 0.005185213405638933, Accuracy: 99.12587412587412\n",
      "Epoch: 6, Batch: 143, Loss: 0.04657430946826935, Accuracy: 99.12651909722221\n",
      "Epoch: 6, Batch: 144, Loss: 0.007519317325204611, Accuracy: 99.13254310344828\n",
      "Epoch: 6, Batch: 145, Loss: 0.02902836911380291, Accuracy: 99.13313356164383\n",
      "Epoch: 6, Batch: 146, Loss: 0.037877947092056274, Accuracy: 99.12308673469387\n",
      "Epoch: 6, Batch: 147, Loss: 0.046242065727710724, Accuracy: 99.1184543918919\n",
      "Epoch: 6, Batch: 148, Loss: 0.010197748430073261, Accuracy: 99.12437080536914\n",
      "Epoch: 6, Batch: 149, Loss: 0.0159828532487154, Accuracy: 99.125\n",
      "Epoch: 6, Batch: 150, Loss: 0.04593397304415703, Accuracy: 99.12044701986756\n",
      "Epoch: 6, Batch: 151, Loss: 0.024012187495827675, Accuracy: 99.11595394736842\n",
      "Epoch: 6, Batch: 152, Loss: 0.014443917199969292, Accuracy: 99.11662581699346\n",
      "Epoch: 6, Batch: 153, Loss: 0.020964307710528374, Accuracy: 99.11728896103897\n",
      "Epoch: 6, Batch: 154, Loss: 0.020507173612713814, Accuracy: 99.1179435483871\n",
      "Epoch: 6, Batch: 155, Loss: 0.10866588354110718, Accuracy: 99.11358173076923\n",
      "Epoch: 6, Batch: 156, Loss: 0.028148328885436058, Accuracy: 99.11425159235668\n",
      "Epoch: 6, Batch: 157, Loss: 0.005452246870845556, Accuracy: 99.11985759493672\n",
      "Epoch: 6, Batch: 158, Loss: 0.020482199266552925, Accuracy: 99.12047955974843\n",
      "Epoch: 6, Batch: 159, Loss: 0.013017194345593452, Accuracy: 99.1259765625\n",
      "Epoch: 6, Batch: 160, Loss: 0.06546905636787415, Accuracy: 99.12250767805781\n",
      "Epoch: 6, Training Loss: 0.02903494787668543\n",
      "Epoch: 6, Validation Loss: 0.6251110181212425, Validation Accuracy: 85.3010164190774\n",
      "Epoch: 7, Batch: 0, Loss: 0.015475978143513203, Accuracy: 99.21875\n",
      "Epoch: 7, Batch: 1, Loss: 0.042624469846487045, Accuracy: 99.21875\n",
      "Epoch: 7, Batch: 2, Loss: 0.004988366272300482, Accuracy: 99.47916666666666\n",
      "Epoch: 7, Batch: 3, Loss: 0.031753022223711014, Accuracy: 99.4140625\n",
      "Epoch: 7, Batch: 4, Loss: 0.006796527188271284, Accuracy: 99.53125\n",
      "Epoch: 7, Batch: 5, Loss: 0.016639046370983124, Accuracy: 99.47916666666666\n",
      "Epoch: 7, Batch: 6, Loss: 0.015559106133878231, Accuracy: 99.44196428571429\n",
      "Epoch: 7, Batch: 7, Loss: 0.033464912325143814, Accuracy: 99.31640625\n",
      "Epoch: 7, Batch: 8, Loss: 0.01110342051833868, Accuracy: 99.39236111111111\n",
      "Epoch: 7, Batch: 9, Loss: 0.0038076178170740604, Accuracy: 99.453125\n",
      "Epoch: 7, Batch: 10, Loss: 0.0031390998046845198, Accuracy: 99.5028409090909\n",
      "Epoch: 7, Batch: 11, Loss: 0.0048144119791686535, Accuracy: 99.54427083333334\n",
      "Epoch: 7, Batch: 12, Loss: 0.0182472113519907, Accuracy: 99.51923076923077\n",
      "Epoch: 7, Batch: 13, Loss: 0.003739795181900263, Accuracy: 99.55357142857143\n",
      "Epoch: 7, Batch: 14, Loss: 0.001974696759134531, Accuracy: 99.58333333333333\n",
      "Epoch: 7, Batch: 15, Loss: 0.029386864975094795, Accuracy: 99.560546875\n",
      "Epoch: 7, Batch: 16, Loss: 0.09848490357398987, Accuracy: 99.44852941176471\n",
      "Epoch: 7, Batch: 17, Loss: 0.01054813526570797, Accuracy: 99.47916666666666\n",
      "Epoch: 7, Batch: 18, Loss: 0.0024189259856939316, Accuracy: 99.50657894736842\n",
      "Epoch: 7, Batch: 19, Loss: 0.03837670013308525, Accuracy: 99.453125\n",
      "Epoch: 7, Batch: 20, Loss: 0.01342733483761549, Accuracy: 99.44196428571429\n",
      "Epoch: 7, Batch: 21, Loss: 0.007105025462806225, Accuracy: 99.46732954545455\n",
      "Epoch: 7, Batch: 22, Loss: 0.008783032186329365, Accuracy: 99.49048913043478\n",
      "Epoch: 7, Batch: 23, Loss: 0.019140467047691345, Accuracy: 99.47916666666666\n",
      "Epoch: 7, Batch: 24, Loss: 0.01423340942710638, Accuracy: 99.46875\n",
      "Epoch: 7, Batch: 25, Loss: 0.005557077005505562, Accuracy: 99.4891826923077\n",
      "Epoch: 7, Batch: 26, Loss: 0.00423504039645195, Accuracy: 99.50810185185185\n",
      "Epoch: 7, Batch: 27, Loss: 0.03188864886760712, Accuracy: 99.49776785714286\n",
      "Epoch: 7, Batch: 28, Loss: 0.06263722479343414, Accuracy: 99.46120689655173\n",
      "Epoch: 7, Batch: 29, Loss: 0.05553212761878967, Accuracy: 99.42708333333333\n",
      "Epoch: 7, Batch: 30, Loss: 0.036435842514038086, Accuracy: 99.39516129032258\n",
      "Epoch: 7, Batch: 31, Loss: 0.014507858082652092, Accuracy: 99.3896484375\n",
      "Epoch: 7, Batch: 32, Loss: 0.006904718466103077, Accuracy: 99.40814393939394\n",
      "Epoch: 7, Batch: 33, Loss: 0.0070732757449150085, Accuracy: 99.42555147058823\n",
      "Epoch: 7, Batch: 34, Loss: 0.010685492306947708, Accuracy: 99.44196428571429\n",
      "Epoch: 7, Batch: 35, Loss: 0.014482789672911167, Accuracy: 99.43576388888889\n",
      "Epoch: 7, Batch: 36, Loss: 0.010621779598295689, Accuracy: 99.45101351351352\n",
      "Epoch: 7, Batch: 37, Loss: 0.012322509661316872, Accuracy: 99.44490131578947\n",
      "Epoch: 7, Batch: 38, Loss: 0.005610334686934948, Accuracy: 99.45913461538461\n",
      "Epoch: 7, Batch: 39, Loss: 0.00367268780246377, Accuracy: 99.47265625\n",
      "Epoch: 7, Batch: 40, Loss: 0.0019672876223921776, Accuracy: 99.48551829268293\n",
      "Epoch: 7, Batch: 41, Loss: 0.004994749557226896, Accuracy: 99.49776785714286\n",
      "Epoch: 7, Batch: 42, Loss: 0.007773522287607193, Accuracy: 99.50944767441861\n",
      "Epoch: 7, Batch: 43, Loss: 0.05599886178970337, Accuracy: 99.48508522727273\n",
      "Epoch: 7, Batch: 44, Loss: 0.06814894825220108, Accuracy: 99.44444444444444\n",
      "Epoch: 7, Batch: 45, Loss: 0.017010798677802086, Accuracy: 99.43953804347827\n",
      "Epoch: 7, Batch: 46, Loss: 0.004172932356595993, Accuracy: 99.45146276595744\n",
      "Epoch: 7, Batch: 47, Loss: 0.01692647859454155, Accuracy: 99.44661458333334\n",
      "Epoch: 7, Batch: 48, Loss: 0.05570458993315697, Accuracy: 99.42602040816327\n",
      "Epoch: 7, Batch: 49, Loss: 0.022654231637716293, Accuracy: 99.40625\n",
      "Epoch: 7, Batch: 50, Loss: 0.005344683770090342, Accuracy: 99.41789215686273\n",
      "Epoch: 7, Batch: 51, Loss: 0.003757925471290946, Accuracy: 99.42908653846155\n",
      "Epoch: 7, Batch: 52, Loss: 0.023037489503622055, Accuracy: 99.42511792452831\n",
      "Epoch: 7, Batch: 53, Loss: 0.029337948188185692, Accuracy: 99.42129629629629\n",
      "Epoch: 7, Batch: 54, Loss: 0.007669016253203154, Accuracy: 99.43181818181817\n",
      "Epoch: 7, Batch: 55, Loss: 0.002707585459575057, Accuracy: 99.44196428571429\n",
      "Epoch: 7, Batch: 56, Loss: 0.006863720249384642, Accuracy: 99.4517543859649\n",
      "Epoch: 7, Batch: 57, Loss: 0.0048065343871712685, Accuracy: 99.46120689655173\n",
      "Epoch: 7, Batch: 58, Loss: 0.003411093959584832, Accuracy: 99.47033898305084\n",
      "Epoch: 7, Batch: 59, Loss: 0.05478796735405922, Accuracy: 99.46614583333333\n",
      "Epoch: 7, Batch: 60, Loss: 0.00621282123029232, Accuracy: 99.4748975409836\n",
      "Epoch: 7, Batch: 61, Loss: 0.037058837711811066, Accuracy: 99.45816532258065\n",
      "Epoch: 7, Batch: 62, Loss: 0.009458346292376518, Accuracy: 99.46676587301587\n",
      "Epoch: 7, Batch: 63, Loss: 0.05777597427368164, Accuracy: 99.45068359375\n",
      "Epoch: 7, Batch: 64, Loss: 0.002553920028731227, Accuracy: 99.45913461538461\n",
      "Epoch: 7, Batch: 65, Loss: 0.005987233482301235, Accuracy: 99.46732954545455\n",
      "Epoch: 7, Batch: 66, Loss: 0.08209364861249924, Accuracy: 99.44029850746269\n",
      "Epoch: 7, Batch: 67, Loss: 0.014667987823486328, Accuracy: 99.43704044117648\n",
      "Epoch: 7, Batch: 68, Loss: 0.009270740672945976, Accuracy: 99.44519927536231\n",
      "Epoch: 7, Batch: 69, Loss: 0.009540311060845852, Accuracy: 99.453125\n",
      "Epoch: 7, Batch: 70, Loss: 0.0033070154022425413, Accuracy: 99.46082746478874\n",
      "Epoch: 7, Batch: 71, Loss: 0.008788470178842545, Accuracy: 99.46831597222221\n",
      "Epoch: 7, Batch: 72, Loss: 0.0066208853386342525, Accuracy: 99.4755993150685\n",
      "Epoch: 7, Batch: 73, Loss: 0.010526007041335106, Accuracy: 99.4826858108108\n",
      "Epoch: 7, Batch: 74, Loss: 0.028688902035355568, Accuracy: 99.46875\n",
      "Epoch: 7, Batch: 75, Loss: 0.002415250986814499, Accuracy: 99.47574013157895\n",
      "Epoch: 7, Batch: 76, Loss: 0.003718732623383403, Accuracy: 99.4825487012987\n",
      "Epoch: 7, Batch: 77, Loss: 0.0025264699943363667, Accuracy: 99.4891826923077\n",
      "Epoch: 7, Batch: 78, Loss: 0.01037898100912571, Accuracy: 99.48575949367088\n",
      "Epoch: 7, Batch: 79, Loss: 0.0332469716668129, Accuracy: 99.482421875\n",
      "Epoch: 7, Batch: 80, Loss: 0.05981581285595894, Accuracy: 99.46952160493827\n",
      "Epoch: 7, Batch: 81, Loss: 0.005708708893507719, Accuracy: 99.47599085365853\n",
      "Epoch: 7, Batch: 82, Loss: 0.0041374159045517445, Accuracy: 99.48230421686746\n",
      "Epoch: 7, Batch: 83, Loss: 0.0036944160237908363, Accuracy: 99.48846726190477\n",
      "Epoch: 7, Batch: 84, Loss: 0.004569937940686941, Accuracy: 99.49448529411765\n",
      "Epoch: 7, Batch: 85, Loss: 0.003430666634812951, Accuracy: 99.50036337209302\n",
      "Epoch: 7, Batch: 86, Loss: 0.0025362877640873194, Accuracy: 99.50610632183908\n",
      "Epoch: 7, Batch: 87, Loss: 0.03366679325699806, Accuracy: 99.5028409090909\n",
      "Epoch: 7, Batch: 88, Loss: 0.006884575355798006, Accuracy: 99.50842696629213\n",
      "Epoch: 7, Batch: 89, Loss: 0.013004621490836143, Accuracy: 99.50520833333333\n",
      "Epoch: 7, Batch: 90, Loss: 0.005754618439823389, Accuracy: 99.5106456043956\n",
      "Epoch: 7, Batch: 91, Loss: 0.05863459035754204, Accuracy: 99.50747282608695\n",
      "Epoch: 7, Batch: 92, Loss: 0.04569385200738907, Accuracy: 99.48756720430107\n",
      "Epoch: 7, Batch: 93, Loss: 0.01250861119478941, Accuracy: 99.4847074468085\n",
      "Epoch: 7, Batch: 94, Loss: 0.06378915160894394, Accuracy: 99.47368421052632\n",
      "Epoch: 7, Batch: 95, Loss: 0.009752326644957066, Accuracy: 99.47916666666666\n",
      "Epoch: 7, Batch: 96, Loss: 0.05672106146812439, Accuracy: 99.47648195876289\n",
      "Epoch: 7, Batch: 97, Loss: 0.037286337465047836, Accuracy: 99.46588010204081\n",
      "Epoch: 7, Batch: 98, Loss: 0.03390561044216156, Accuracy: 99.46338383838383\n",
      "Epoch: 7, Batch: 99, Loss: 0.00950376596301794, Accuracy: 99.4609375\n",
      "Epoch: 7, Batch: 100, Loss: 0.004950520116835833, Accuracy: 99.46627475247524\n",
      "Epoch: 7, Batch: 101, Loss: 0.0042275493033230305, Accuracy: 99.47150735294117\n",
      "Epoch: 7, Batch: 102, Loss: 0.008826280944049358, Accuracy: 99.47663834951457\n",
      "Epoch: 7, Batch: 103, Loss: 0.050055477768182755, Accuracy: 99.45913461538461\n",
      "Epoch: 7, Batch: 104, Loss: 0.03733918070793152, Accuracy: 99.44940476190476\n",
      "Epoch: 7, Batch: 105, Loss: 0.05691178888082504, Accuracy: 99.43248820754717\n",
      "Epoch: 7, Batch: 106, Loss: 0.010750128887593746, Accuracy: 99.4304906542056\n",
      "Epoch: 7, Batch: 107, Loss: 0.016923299059271812, Accuracy: 99.4285300925926\n",
      "Epoch: 7, Batch: 108, Loss: 0.005019773729145527, Accuracy: 99.43377293577981\n",
      "Epoch: 7, Batch: 109, Loss: 0.0056286766193807125, Accuracy: 99.43892045454545\n",
      "Epoch: 7, Batch: 110, Loss: 0.010493583977222443, Accuracy: 99.44397522522522\n",
      "Epoch: 7, Batch: 111, Loss: 0.03444720432162285, Accuracy: 99.43498883928571\n",
      "Epoch: 7, Batch: 112, Loss: 0.007377512753009796, Accuracy: 99.43998893805309\n",
      "Epoch: 7, Batch: 113, Loss: 0.012179006822407246, Accuracy: 99.44490131578947\n",
      "Epoch: 7, Batch: 114, Loss: 0.09282667934894562, Accuracy: 99.43614130434783\n",
      "Epoch: 7, Batch: 115, Loss: 0.005074140150099993, Accuracy: 99.44100215517241\n",
      "Epoch: 7, Batch: 116, Loss: 0.0429210402071476, Accuracy: 99.43910256410257\n",
      "Epoch: 7, Batch: 117, Loss: 0.011238853447139263, Accuracy: 99.44385593220339\n",
      "Epoch: 7, Batch: 118, Loss: 0.03171033412218094, Accuracy: 99.44196428571429\n",
      "Epoch: 7, Batch: 119, Loss: 0.006065947934985161, Accuracy: 99.44661458333334\n",
      "Epoch: 7, Batch: 120, Loss: 0.005300802178680897, Accuracy: 99.45118801652893\n",
      "Epoch: 7, Batch: 121, Loss: 0.0057749333791434765, Accuracy: 99.45568647540983\n",
      "Epoch: 7, Batch: 122, Loss: 0.010063155554234982, Accuracy: 99.4601117886179\n",
      "Epoch: 7, Batch: 123, Loss: 0.027334721758961678, Accuracy: 99.45816532258065\n",
      "Epoch: 7, Batch: 124, Loss: 0.06270352751016617, Accuracy: 99.45625\n",
      "Epoch: 7, Batch: 125, Loss: 0.01180557906627655, Accuracy: 99.46056547619048\n",
      "Epoch: 7, Batch: 126, Loss: 0.005451935343444347, Accuracy: 99.46481299212599\n",
      "Epoch: 7, Batch: 127, Loss: 0.019876083359122276, Accuracy: 99.462890625\n",
      "Epoch: 7, Batch: 128, Loss: 0.02375374734401703, Accuracy: 99.45494186046511\n",
      "Epoch: 7, Batch: 129, Loss: 0.0048986198380589485, Accuracy: 99.45913461538461\n",
      "Epoch: 7, Batch: 130, Loss: 0.01985115371644497, Accuracy: 99.45133587786259\n",
      "Epoch: 7, Batch: 131, Loss: 0.006091744173318148, Accuracy: 99.45549242424242\n",
      "Epoch: 7, Batch: 132, Loss: 0.005530335940420628, Accuracy: 99.45958646616542\n",
      "Epoch: 7, Batch: 133, Loss: 0.02579255774617195, Accuracy: 99.45778917910447\n",
      "Epoch: 7, Batch: 134, Loss: 0.023657837882637978, Accuracy: 99.45023148148148\n",
      "Epoch: 7, Batch: 135, Loss: 0.01610083132982254, Accuracy: 99.44852941176471\n",
      "Epoch: 7, Batch: 136, Loss: 0.05507615581154823, Accuracy: 99.44685218978103\n",
      "Epoch: 7, Batch: 137, Loss: 0.01157782506197691, Accuracy: 99.44519927536231\n",
      "Epoch: 7, Batch: 138, Loss: 0.010462719947099686, Accuracy: 99.44919064748201\n",
      "Epoch: 7, Batch: 139, Loss: 0.025563327595591545, Accuracy: 99.44754464285714\n",
      "Epoch: 7, Batch: 140, Loss: 0.00718247564509511, Accuracy: 99.45146276595744\n",
      "Epoch: 7, Batch: 141, Loss: 0.005425069946795702, Accuracy: 99.45532570422534\n",
      "Epoch: 7, Batch: 142, Loss: 0.004806314595043659, Accuracy: 99.45913461538461\n",
      "Epoch: 7, Batch: 143, Loss: 0.061207856982946396, Accuracy: 99.44661458333334\n",
      "Epoch: 7, Batch: 144, Loss: 0.009286094456911087, Accuracy: 99.45043103448276\n",
      "Epoch: 7, Batch: 145, Loss: 0.007856050506234169, Accuracy: 99.45419520547945\n",
      "Epoch: 7, Batch: 146, Loss: 0.004252591636031866, Accuracy: 99.4579081632653\n",
      "Epoch: 7, Batch: 147, Loss: 0.028430651873350143, Accuracy: 99.45101351351352\n",
      "Epoch: 7, Batch: 148, Loss: 0.0040628318674862385, Accuracy: 99.45469798657717\n",
      "Epoch: 7, Batch: 149, Loss: 0.009969526901841164, Accuracy: 99.453125\n",
      "Epoch: 7, Batch: 150, Loss: 0.025992171838879585, Accuracy: 99.45157284768213\n",
      "Epoch: 7, Batch: 151, Loss: 0.006518812850117683, Accuracy: 99.45518092105263\n",
      "Epoch: 7, Batch: 152, Loss: 0.03064582496881485, Accuracy: 99.45363562091504\n",
      "Epoch: 7, Batch: 153, Loss: 0.014332995750010014, Accuracy: 99.4521103896104\n",
      "Epoch: 7, Batch: 154, Loss: 0.01276050042361021, Accuracy: 99.45060483870968\n",
      "Epoch: 7, Batch: 155, Loss: 0.013916737399995327, Accuracy: 99.44911858974359\n",
      "Epoch: 7, Batch: 156, Loss: 0.03588901087641716, Accuracy: 99.44765127388536\n",
      "Epoch: 7, Batch: 157, Loss: 0.038366809487342834, Accuracy: 99.4412579113924\n",
      "Epoch: 7, Batch: 158, Loss: 0.023551471531391144, Accuracy: 99.43985849056604\n",
      "Epoch: 7, Batch: 159, Loss: 0.023777438327670097, Accuracy: 99.4384765625\n",
      "Epoch: 7, Batch: 160, Loss: 0.001084955525584519, Accuracy: 99.43937990542582\n",
      "Epoch: 7, Training Loss: 0.019578035338781774\n",
      "Epoch: 7, Validation Loss: 0.6567952513694764, Validation Accuracy: 84.75371383893668\n",
      "Epoch: 8, Batch: 0, Loss: 0.003015398047864437, Accuracy: 100.0\n",
      "Epoch: 8, Batch: 1, Loss: 0.005271110218018293, Accuracy: 100.0\n",
      "Epoch: 8, Batch: 2, Loss: 0.009814818389713764, Accuracy: 100.0\n",
      "Epoch: 8, Batch: 3, Loss: 0.008943394757807255, Accuracy: 100.0\n",
      "Epoch: 8, Batch: 4, Loss: 0.004555580671876669, Accuracy: 100.0\n",
      "Epoch: 8, Batch: 5, Loss: 0.009847622364759445, Accuracy: 100.0\n",
      "Epoch: 8, Batch: 6, Loss: 0.003258549841120839, Accuracy: 100.0\n",
      "Epoch: 8, Batch: 7, Loss: 0.00487438403069973, Accuracy: 100.0\n",
      "Epoch: 8, Batch: 8, Loss: 0.00911340955644846, Accuracy: 99.91319444444444\n",
      "Epoch: 8, Batch: 9, Loss: 0.02034883201122284, Accuracy: 99.84375\n",
      "Epoch: 8, Batch: 10, Loss: 0.0027487934567034245, Accuracy: 99.85795454545455\n",
      "Epoch: 8, Batch: 11, Loss: 0.004080604761838913, Accuracy: 99.86979166666666\n",
      "Epoch: 8, Batch: 12, Loss: 0.00348095060326159, Accuracy: 99.8798076923077\n",
      "Epoch: 8, Batch: 13, Loss: 0.004887399263679981, Accuracy: 99.88839285714286\n",
      "Epoch: 8, Batch: 14, Loss: 0.0017028345027938485, Accuracy: 99.89583333333333\n",
      "Epoch: 8, Batch: 15, Loss: 0.006931392941623926, Accuracy: 99.90234375\n",
      "Epoch: 8, Batch: 16, Loss: 0.026511913165450096, Accuracy: 99.86213235294117\n",
      "Epoch: 8, Batch: 17, Loss: 0.0016265608137473464, Accuracy: 99.86979166666666\n",
      "Epoch: 8, Batch: 18, Loss: 0.019623180851340294, Accuracy: 99.79440789473685\n",
      "Epoch: 8, Batch: 19, Loss: 0.007030684035271406, Accuracy: 99.8046875\n",
      "Epoch: 8, Batch: 20, Loss: 0.03225860372185707, Accuracy: 99.73958333333334\n",
      "Epoch: 8, Batch: 21, Loss: 0.0036188841331750154, Accuracy: 99.75142045454545\n",
      "Epoch: 8, Batch: 22, Loss: 0.020087791606783867, Accuracy: 99.72826086956522\n",
      "Epoch: 8, Batch: 23, Loss: 0.0017170571954920888, Accuracy: 99.73958333333334\n",
      "Epoch: 8, Batch: 24, Loss: 0.00278211641125381, Accuracy: 99.75\n",
      "Epoch: 8, Batch: 25, Loss: 0.010726433247327805, Accuracy: 99.7295673076923\n",
      "Epoch: 8, Batch: 26, Loss: 0.002369568683207035, Accuracy: 99.73958333333334\n",
      "Epoch: 8, Batch: 27, Loss: 0.0014115317026153207, Accuracy: 99.74888392857143\n",
      "Epoch: 8, Batch: 28, Loss: 0.002011239528656006, Accuracy: 99.75754310344827\n",
      "Epoch: 8, Batch: 29, Loss: 0.01102836336940527, Accuracy: 99.73958333333334\n",
      "Epoch: 8, Batch: 30, Loss: 0.005054468289017677, Accuracy: 99.74798387096774\n",
      "Epoch: 8, Batch: 31, Loss: 0.014473587274551392, Accuracy: 99.7314453125\n",
      "Epoch: 8, Batch: 32, Loss: 0.0013241586275398731, Accuracy: 99.73958333333334\n",
      "Epoch: 8, Batch: 33, Loss: 0.009754092432558537, Accuracy: 99.74724264705883\n",
      "Epoch: 8, Batch: 34, Loss: 0.0024118574801832438, Accuracy: 99.75446428571428\n",
      "Epoch: 8, Batch: 35, Loss: 0.004082550294697285, Accuracy: 99.76128472222221\n",
      "Epoch: 8, Batch: 36, Loss: 0.028104839846491814, Accuracy: 99.74662162162163\n",
      "Epoch: 8, Batch: 37, Loss: 0.0029182154685258865, Accuracy: 99.75328947368422\n",
      "Epoch: 8, Batch: 38, Loss: 0.0015026264591142535, Accuracy: 99.75961538461539\n",
      "Epoch: 8, Batch: 39, Loss: 0.016246983781456947, Accuracy: 99.7265625\n",
      "Epoch: 8, Batch: 40, Loss: 0.0017848776187747717, Accuracy: 99.73323170731707\n",
      "Epoch: 8, Batch: 41, Loss: 0.0009340193355455995, Accuracy: 99.73958333333334\n",
      "Epoch: 8, Batch: 42, Loss: 0.014383289031684399, Accuracy: 99.72747093023256\n",
      "Epoch: 8, Batch: 43, Loss: 0.0011459647212177515, Accuracy: 99.73366477272727\n",
      "Epoch: 8, Batch: 44, Loss: 0.013132051564753056, Accuracy: 99.72222222222223\n",
      "Epoch: 8, Batch: 45, Loss: 0.002214383101090789, Accuracy: 99.72826086956522\n",
      "Epoch: 8, Batch: 46, Loss: 0.008404119871556759, Accuracy: 99.71742021276596\n",
      "Epoch: 8, Batch: 47, Loss: 0.0027558475267142057, Accuracy: 99.72330729166666\n",
      "Epoch: 8, Batch: 48, Loss: 0.0038925609551370144, Accuracy: 99.72895408163265\n",
      "Epoch: 8, Batch: 49, Loss: 0.0012256408808752894, Accuracy: 99.734375\n",
      "Epoch: 8, Batch: 50, Loss: 0.0017697737785056233, Accuracy: 99.73958333333334\n",
      "Epoch: 8, Batch: 51, Loss: 0.00161702127661556, Accuracy: 99.74459134615384\n",
      "Epoch: 8, Batch: 52, Loss: 0.0023178085684776306, Accuracy: 99.74941037735849\n",
      "Epoch: 8, Batch: 53, Loss: 0.0008273583371192217, Accuracy: 99.75405092592592\n",
      "Epoch: 8, Batch: 54, Loss: 0.0016719346167519689, Accuracy: 99.75852272727272\n",
      "Epoch: 8, Batch: 55, Loss: 0.042688269168138504, Accuracy: 99.74888392857143\n",
      "Epoch: 8, Batch: 56, Loss: 0.03703567013144493, Accuracy: 99.72587719298247\n",
      "Epoch: 8, Batch: 57, Loss: 0.006421780213713646, Accuracy: 99.71713362068965\n",
      "Epoch: 8, Batch: 58, Loss: 0.002433303976431489, Accuracy: 99.7219279661017\n",
      "Epoch: 8, Batch: 59, Loss: 0.0018802299164235592, Accuracy: 99.7265625\n",
      "Epoch: 8, Batch: 60, Loss: 0.004191368352621794, Accuracy: 99.73104508196722\n",
      "Epoch: 8, Batch: 61, Loss: 0.010918738320469856, Accuracy: 99.72278225806451\n",
      "Epoch: 8, Batch: 62, Loss: 0.003465520218014717, Accuracy: 99.72718253968253\n",
      "Epoch: 8, Batch: 63, Loss: 0.0071633681654930115, Accuracy: 99.7314453125\n",
      "Epoch: 8, Batch: 64, Loss: 0.0015963902696967125, Accuracy: 99.73557692307692\n",
      "Epoch: 8, Batch: 65, Loss: 0.0056258500553667545, Accuracy: 99.73958333333334\n",
      "Epoch: 8, Batch: 66, Loss: 0.006150180473923683, Accuracy: 99.74347014925374\n",
      "Epoch: 8, Batch: 67, Loss: 0.00831583235412836, Accuracy: 99.74724264705883\n",
      "Epoch: 8, Batch: 68, Loss: 0.019092941656708717, Accuracy: 99.73958333333334\n",
      "Epoch: 8, Batch: 69, Loss: 0.005946916528046131, Accuracy: 99.74330357142858\n",
      "Epoch: 8, Batch: 70, Loss: 0.06762491166591644, Accuracy: 99.71390845070422\n",
      "Epoch: 8, Batch: 71, Loss: 0.008740732446312904, Accuracy: 99.70703125\n",
      "Epoch: 8, Batch: 72, Loss: 0.020142612978816032, Accuracy: 99.70034246575342\n",
      "Epoch: 8, Batch: 73, Loss: 0.0006794348009862006, Accuracy: 99.7043918918919\n",
      "Epoch: 8, Batch: 74, Loss: 0.004066592548042536, Accuracy: 99.70833333333333\n",
      "Epoch: 8, Batch: 75, Loss: 0.025389159098267555, Accuracy: 99.69161184210526\n",
      "Epoch: 8, Batch: 76, Loss: 0.0008735622395761311, Accuracy: 99.69561688311688\n",
      "Epoch: 8, Batch: 77, Loss: 0.004797774367034435, Accuracy: 99.69951923076923\n",
      "Epoch: 8, Batch: 78, Loss: 0.00949301291257143, Accuracy: 99.6934335443038\n",
      "Epoch: 8, Batch: 79, Loss: 0.0013765317853540182, Accuracy: 99.697265625\n",
      "Epoch: 8, Batch: 80, Loss: 0.03538752347230911, Accuracy: 99.68171296296296\n",
      "Epoch: 8, Batch: 81, Loss: 0.008308609016239643, Accuracy: 99.68559451219512\n",
      "Epoch: 8, Batch: 82, Loss: 0.004935098811984062, Accuracy: 99.68938253012048\n",
      "Epoch: 8, Batch: 83, Loss: 0.013680202886462212, Accuracy: 99.68377976190477\n",
      "Epoch: 8, Batch: 84, Loss: 0.016797946766018867, Accuracy: 99.67830882352942\n",
      "Epoch: 8, Batch: 85, Loss: 0.004956839606165886, Accuracy: 99.68204941860465\n",
      "Epoch: 8, Batch: 86, Loss: 0.011303325183689594, Accuracy: 99.6857040229885\n",
      "Epoch: 8, Batch: 87, Loss: 0.02105620875954628, Accuracy: 99.68039772727273\n",
      "Epoch: 8, Batch: 88, Loss: 0.00716016860678792, Accuracy: 99.68398876404494\n",
      "Epoch: 8, Batch: 89, Loss: 0.003092477098107338, Accuracy: 99.6875\n",
      "Epoch: 8, Batch: 90, Loss: 0.0031620103400200605, Accuracy: 99.69093406593407\n",
      "Epoch: 8, Batch: 91, Loss: 0.04131937772035599, Accuracy: 99.66881793478261\n",
      "Epoch: 8, Batch: 92, Loss: 0.0031226894352585077, Accuracy: 99.67237903225806\n",
      "Epoch: 8, Batch: 93, Loss: 0.04772397130727768, Accuracy: 99.66755319148936\n",
      "Epoch: 8, Batch: 94, Loss: 0.03198960795998573, Accuracy: 99.66282894736842\n",
      "Epoch: 8, Batch: 95, Loss: 0.01770015060901642, Accuracy: 99.65006510416666\n",
      "Epoch: 8, Batch: 96, Loss: 0.004909630864858627, Accuracy: 99.65367268041237\n",
      "Epoch: 8, Batch: 97, Loss: 0.0334901325404644, Accuracy: 99.64126275510205\n",
      "Epoch: 8, Batch: 98, Loss: 0.022336652502417564, Accuracy: 99.63699494949495\n",
      "Epoch: 8, Batch: 99, Loss: 0.07013433426618576, Accuracy: 99.625\n",
      "Epoch: 8, Batch: 100, Loss: 0.005569120403379202, Accuracy: 99.62871287128714\n",
      "Epoch: 8, Batch: 101, Loss: 0.04314902052283287, Accuracy: 99.6170343137255\n",
      "Epoch: 8, Batch: 102, Loss: 0.002227448159828782, Accuracy: 99.62075242718447\n",
      "Epoch: 8, Batch: 103, Loss: 0.00443945312872529, Accuracy: 99.62439903846155\n",
      "Epoch: 8, Batch: 104, Loss: 0.0050541735254228115, Accuracy: 99.62797619047619\n",
      "Epoch: 8, Batch: 105, Loss: 0.005165905691683292, Accuracy: 99.6314858490566\n",
      "Epoch: 8, Batch: 106, Loss: 0.008867351338267326, Accuracy: 99.6276285046729\n",
      "Epoch: 8, Batch: 107, Loss: 0.008945731446146965, Accuracy: 99.6238425925926\n",
      "Epoch: 8, Batch: 108, Loss: 0.006292169447988272, Accuracy: 99.62729357798165\n",
      "Epoch: 8, Batch: 109, Loss: 0.019094552844762802, Accuracy: 99.62357954545455\n",
      "Epoch: 8, Batch: 110, Loss: 0.02656329609453678, Accuracy: 99.61289414414415\n",
      "Epoch: 8, Batch: 111, Loss: 0.0041710021905601025, Accuracy: 99.61635044642857\n",
      "Epoch: 8, Batch: 112, Loss: 0.004087324254214764, Accuracy: 99.61974557522124\n",
      "Epoch: 8, Batch: 113, Loss: 0.024268783628940582, Accuracy: 99.61622807017544\n",
      "Epoch: 8, Batch: 114, Loss: 0.01438411045819521, Accuracy: 99.61277173913044\n",
      "Epoch: 8, Batch: 115, Loss: 0.024216536432504654, Accuracy: 99.60264008620689\n",
      "Epoch: 8, Batch: 116, Loss: 0.07244393229484558, Accuracy: 99.59268162393163\n",
      "Epoch: 8, Batch: 117, Loss: 0.008808741346001625, Accuracy: 99.59613347457628\n",
      "Epoch: 8, Batch: 118, Loss: 0.03564021363854408, Accuracy: 99.58639705882352\n",
      "Epoch: 8, Batch: 119, Loss: 0.10549329221248627, Accuracy: 99.5703125\n",
      "Epoch: 8, Batch: 120, Loss: 0.0018954399274662137, Accuracy: 99.57386363636364\n",
      "Epoch: 8, Batch: 121, Loss: 0.012782287783920765, Accuracy: 99.57095286885246\n",
      "Epoch: 8, Batch: 122, Loss: 0.005180036649107933, Accuracy: 99.57444105691057\n",
      "Epoch: 8, Batch: 123, Loss: 0.0038264428731054068, Accuracy: 99.57787298387096\n",
      "Epoch: 8, Batch: 124, Loss: 0.0964287519454956, Accuracy: 99.5625\n",
      "Epoch: 8, Batch: 125, Loss: 0.015027549117803574, Accuracy: 99.55977182539682\n",
      "Epoch: 8, Batch: 126, Loss: 0.019122501835227013, Accuracy: 99.55708661417323\n",
      "Epoch: 8, Batch: 127, Loss: 0.06386755406856537, Accuracy: 99.54833984375\n",
      "Epoch: 8, Batch: 128, Loss: 0.0017996750539168715, Accuracy: 99.55184108527132\n",
      "Epoch: 8, Batch: 129, Loss: 0.01936088129878044, Accuracy: 99.54927884615384\n",
      "Epoch: 8, Batch: 130, Loss: 0.007896697148680687, Accuracy: 99.54675572519083\n",
      "Epoch: 8, Batch: 131, Loss: 0.00923374854028225, Accuracy: 99.55018939393939\n",
      "Epoch: 8, Batch: 132, Loss: 0.010215949267148972, Accuracy: 99.54769736842105\n",
      "Epoch: 8, Batch: 133, Loss: 0.03544801473617554, Accuracy: 99.54524253731343\n",
      "Epoch: 8, Batch: 134, Loss: 0.047581177204847336, Accuracy: 99.54282407407408\n",
      "Epoch: 8, Batch: 135, Loss: 0.008997331373393536, Accuracy: 99.54618566176471\n",
      "Epoch: 8, Batch: 136, Loss: 0.00877493154257536, Accuracy: 99.54949817518248\n",
      "Epoch: 8, Batch: 137, Loss: 0.015499239787459373, Accuracy: 99.54710144927536\n",
      "Epoch: 8, Batch: 138, Loss: 0.005856140051037073, Accuracy: 99.55035971223022\n",
      "Epoch: 8, Batch: 139, Loss: 0.0119261983782053, Accuracy: 99.54799107142858\n",
      "Epoch: 8, Batch: 140, Loss: 0.047851983457803726, Accuracy: 99.5456560283688\n",
      "Epoch: 8, Batch: 141, Loss: 0.004497561603784561, Accuracy: 99.54885563380282\n",
      "Epoch: 8, Batch: 142, Loss: 0.035891104489564896, Accuracy: 99.5465472027972\n",
      "Epoch: 8, Batch: 143, Loss: 0.02991185337305069, Accuracy: 99.54427083333334\n",
      "Epoch: 8, Batch: 144, Loss: 0.03569304570555687, Accuracy: 99.53663793103448\n",
      "Epoch: 8, Batch: 145, Loss: 0.016429124400019646, Accuracy: 99.53446061643835\n",
      "Epoch: 8, Batch: 146, Loss: 0.031355831772089005, Accuracy: 99.53231292517006\n",
      "Epoch: 8, Batch: 147, Loss: 0.028067966923117638, Accuracy: 99.53019425675676\n",
      "Epoch: 8, Batch: 148, Loss: 0.014512456022202969, Accuracy: 99.53334731543623\n",
      "Epoch: 8, Batch: 149, Loss: 0.0036857728846371174, Accuracy: 99.53645833333333\n",
      "Epoch: 8, Batch: 150, Loss: 0.007058306597173214, Accuracy: 99.53952814569537\n",
      "Epoch: 8, Batch: 151, Loss: 0.06493604183197021, Accuracy: 99.5374177631579\n",
      "Epoch: 8, Batch: 152, Loss: 0.003960578702390194, Accuracy: 99.54044117647058\n",
      "Epoch: 8, Batch: 153, Loss: 0.007173200137913227, Accuracy: 99.54342532467533\n",
      "Epoch: 8, Batch: 154, Loss: 0.0335666798055172, Accuracy: 99.53125\n",
      "Epoch: 8, Batch: 155, Loss: 0.04360053315758705, Accuracy: 99.51923076923077\n",
      "Epoch: 8, Batch: 156, Loss: 0.005541206803172827, Accuracy: 99.52229299363057\n",
      "Epoch: 8, Batch: 157, Loss: 0.02147163264453411, Accuracy: 99.52037183544303\n",
      "Epoch: 8, Batch: 158, Loss: 0.014508667401969433, Accuracy: 99.51847484276729\n",
      "Epoch: 8, Batch: 159, Loss: 0.004352713469415903, Accuracy: 99.521484375\n",
      "Epoch: 8, Batch: 160, Loss: 0.022888919338583946, Accuracy: 99.52225418027592\n",
      "Epoch: 8, Training Loss: 0.014937046991215775\n",
      "Epoch: 8, Validation Loss: 0.6640172496438026, Validation Accuracy: 85.26192337763878\n",
      "Epoch: 9, Batch: 0, Loss: 0.0021314288023859262, Accuracy: 100.0\n",
      "Epoch: 9, Batch: 1, Loss: 0.009342005476355553, Accuracy: 100.0\n",
      "Epoch: 9, Batch: 2, Loss: 0.006671023089438677, Accuracy: 100.0\n",
      "Epoch: 9, Batch: 3, Loss: 0.005880643147975206, Accuracy: 100.0\n",
      "Epoch: 9, Batch: 4, Loss: 0.024699632078409195, Accuracy: 99.84375\n",
      "Epoch: 9, Batch: 5, Loss: 0.008846280165016651, Accuracy: 99.86979166666666\n",
      "Epoch: 9, Batch: 6, Loss: 0.006594997830688953, Accuracy: 99.88839285714286\n",
      "Epoch: 9, Batch: 7, Loss: 0.0021991096436977386, Accuracy: 99.90234375\n",
      "Epoch: 9, Batch: 8, Loss: 0.003727348055690527, Accuracy: 99.91319444444444\n",
      "Epoch: 9, Batch: 9, Loss: 0.0029310432728379965, Accuracy: 99.921875\n",
      "Epoch: 9, Batch: 10, Loss: 0.02608063817024231, Accuracy: 99.78693181818183\n",
      "Epoch: 9, Batch: 11, Loss: 0.002674340270459652, Accuracy: 99.8046875\n",
      "Epoch: 9, Batch: 12, Loss: 0.03147009760141373, Accuracy: 99.75961538461539\n",
      "Epoch: 9, Batch: 13, Loss: 0.011340726166963577, Accuracy: 99.72098214285714\n",
      "Epoch: 9, Batch: 14, Loss: 0.004012463614344597, Accuracy: 99.73958333333334\n",
      "Epoch: 9, Batch: 15, Loss: 0.001764418906532228, Accuracy: 99.755859375\n",
      "Epoch: 9, Batch: 16, Loss: 0.04097941890358925, Accuracy: 99.72426470588235\n",
      "Epoch: 9, Batch: 17, Loss: 0.004785569384694099, Accuracy: 99.73958333333334\n",
      "Epoch: 9, Batch: 18, Loss: 0.0029112708289176226, Accuracy: 99.75328947368422\n",
      "Epoch: 9, Batch: 19, Loss: 0.0033861766569316387, Accuracy: 99.765625\n",
      "Epoch: 9, Batch: 20, Loss: 0.0046458775177598, Accuracy: 99.77678571428571\n",
      "Epoch: 9, Batch: 21, Loss: 0.0013329553185030818, Accuracy: 99.78693181818183\n",
      "Epoch: 9, Batch: 22, Loss: 0.01808399148285389, Accuracy: 99.76222826086956\n",
      "Epoch: 9, Batch: 23, Loss: 0.0053507303819060326, Accuracy: 99.77213541666666\n",
      "Epoch: 9, Batch: 24, Loss: 0.009847522713243961, Accuracy: 99.75\n",
      "Epoch: 9, Batch: 25, Loss: 0.005555439740419388, Accuracy: 99.75961538461539\n",
      "Epoch: 9, Batch: 26, Loss: 0.04106728732585907, Accuracy: 99.73958333333334\n",
      "Epoch: 9, Batch: 27, Loss: 0.0019382903119549155, Accuracy: 99.74888392857143\n",
      "Epoch: 9, Batch: 28, Loss: 0.0023014312610030174, Accuracy: 99.75754310344827\n",
      "Epoch: 9, Batch: 29, Loss: 0.006782992277294397, Accuracy: 99.765625\n",
      "Epoch: 9, Batch: 30, Loss: 0.0061062052845954895, Accuracy: 99.77318548387096\n",
      "Epoch: 9, Batch: 31, Loss: 0.0019666431471705437, Accuracy: 99.7802734375\n",
      "Epoch: 9, Batch: 32, Loss: 0.002207026118412614, Accuracy: 99.78693181818183\n",
      "Epoch: 9, Batch: 33, Loss: 0.008103022351861, Accuracy: 99.79319852941177\n",
      "Epoch: 9, Batch: 34, Loss: 0.004805566277354956, Accuracy: 99.79910714285715\n",
      "Epoch: 9, Batch: 35, Loss: 0.0013580822851508856, Accuracy: 99.8046875\n",
      "Epoch: 9, Batch: 36, Loss: 0.003811728674918413, Accuracy: 99.80996621621621\n",
      "Epoch: 9, Batch: 37, Loss: 0.05050963908433914, Accuracy: 99.79440789473685\n",
      "Epoch: 9, Batch: 38, Loss: 0.017523687332868576, Accuracy: 99.77964743589743\n",
      "Epoch: 9, Batch: 39, Loss: 0.034814171493053436, Accuracy: 99.74609375\n",
      "Epoch: 9, Batch: 40, Loss: 0.003563147271052003, Accuracy: 99.75228658536585\n",
      "Epoch: 9, Batch: 41, Loss: 0.0020690083038061857, Accuracy: 99.75818452380952\n",
      "Epoch: 9, Batch: 42, Loss: 0.003583222394809127, Accuracy: 99.76380813953489\n",
      "Epoch: 9, Batch: 43, Loss: 0.0016989840660244226, Accuracy: 99.76917613636364\n",
      "Epoch: 9, Batch: 44, Loss: 0.013438772410154343, Accuracy: 99.75694444444444\n",
      "Epoch: 9, Batch: 45, Loss: 0.0037456825375556946, Accuracy: 99.76222826086956\n",
      "Epoch: 9, Batch: 46, Loss: 0.0024496426340192556, Accuracy: 99.76728723404256\n",
      "Epoch: 9, Batch: 47, Loss: 0.002112514106556773, Accuracy: 99.77213541666666\n",
      "Epoch: 9, Batch: 48, Loss: 0.0025524855591356754, Accuracy: 99.77678571428571\n",
      "Epoch: 9, Batch: 49, Loss: 0.0523095540702343, Accuracy: 99.765625\n",
      "Epoch: 9, Batch: 50, Loss: 0.001431688666343689, Accuracy: 99.77022058823529\n",
      "Epoch: 9, Batch: 51, Loss: 0.0011961370473727584, Accuracy: 99.77463942307693\n",
      "Epoch: 9, Batch: 52, Loss: 0.010057412087917328, Accuracy: 99.77889150943396\n",
      "Epoch: 9, Batch: 53, Loss: 0.002946696011349559, Accuracy: 99.78298611111111\n",
      "Epoch: 9, Batch: 54, Loss: 0.006003225687891245, Accuracy: 99.78693181818183\n",
      "Epoch: 9, Batch: 55, Loss: 0.0025561368092894554, Accuracy: 99.79073660714286\n",
      "Epoch: 9, Batch: 56, Loss: 0.011727647855877876, Accuracy: 99.78070175438597\n",
      "Epoch: 9, Batch: 57, Loss: 0.0016076869796961546, Accuracy: 99.78448275862068\n",
      "Epoch: 9, Batch: 58, Loss: 0.0006569581455551088, Accuracy: 99.78813559322035\n",
      "Epoch: 9, Batch: 59, Loss: 0.01461887452751398, Accuracy: 99.765625\n",
      "Epoch: 9, Batch: 60, Loss: 0.004515655804425478, Accuracy: 99.76946721311475\n",
      "Epoch: 9, Batch: 61, Loss: 0.007478343788534403, Accuracy: 99.77318548387096\n",
      "Epoch: 9, Batch: 62, Loss: 0.006819616537541151, Accuracy: 99.76438492063492\n",
      "Epoch: 9, Batch: 63, Loss: 0.001351213431917131, Accuracy: 99.76806640625\n",
      "Epoch: 9, Batch: 64, Loss: 0.0016880749026313424, Accuracy: 99.77163461538461\n",
      "Epoch: 9, Batch: 65, Loss: 0.0007789019728079438, Accuracy: 99.7750946969697\n",
      "Epoch: 9, Batch: 66, Loss: 0.0017603290034458041, Accuracy: 99.77845149253731\n",
      "Epoch: 9, Batch: 67, Loss: 0.0013824703637510538, Accuracy: 99.78170955882352\n",
      "Epoch: 9, Batch: 68, Loss: 0.0043110898695886135, Accuracy: 99.7848731884058\n",
      "Epoch: 9, Batch: 69, Loss: 0.04847676306962967, Accuracy: 99.77678571428571\n",
      "Epoch: 9, Batch: 70, Loss: 0.030609024688601494, Accuracy: 99.76892605633803\n",
      "Epoch: 9, Batch: 71, Loss: 0.06146048754453659, Accuracy: 99.75043402777779\n",
      "Epoch: 9, Batch: 72, Loss: 0.0018203622894361615, Accuracy: 99.75385273972603\n",
      "Epoch: 9, Batch: 73, Loss: 0.0076897707767784595, Accuracy: 99.75717905405406\n",
      "Epoch: 9, Batch: 74, Loss: 0.03517472371459007, Accuracy: 99.73958333333334\n",
      "Epoch: 9, Batch: 75, Loss: 0.0035559486132115126, Accuracy: 99.74300986842105\n",
      "Epoch: 9, Batch: 76, Loss: 0.009395190514624119, Accuracy: 99.7362012987013\n",
      "Epoch: 9, Batch: 77, Loss: 0.0018756347708404064, Accuracy: 99.73958333333334\n",
      "Epoch: 9, Batch: 78, Loss: 0.020919157192111015, Accuracy: 99.73299050632912\n",
      "Epoch: 9, Batch: 79, Loss: 0.018912844359874725, Accuracy: 99.7265625\n",
      "Epoch: 9, Batch: 80, Loss: 0.03450996056199074, Accuracy: 99.72029320987654\n",
      "Epoch: 9, Batch: 81, Loss: 0.0053818197920918465, Accuracy: 99.72370426829268\n",
      "Epoch: 9, Batch: 82, Loss: 0.027509747073054314, Accuracy: 99.71762048192771\n",
      "Epoch: 9, Batch: 83, Loss: 0.02115447260439396, Accuracy: 99.71168154761905\n",
      "Epoch: 9, Batch: 84, Loss: 0.0035082101821899414, Accuracy: 99.71507352941177\n",
      "Epoch: 9, Batch: 85, Loss: 0.026319675147533417, Accuracy: 99.70930232558139\n",
      "Epoch: 9, Batch: 86, Loss: 0.0030594293493777514, Accuracy: 99.71264367816092\n",
      "Epoch: 9, Batch: 87, Loss: 0.002606838010251522, Accuracy: 99.7159090909091\n",
      "Epoch: 9, Batch: 88, Loss: 0.002935404423624277, Accuracy: 99.71910112359551\n",
      "Epoch: 9, Batch: 89, Loss: 0.08780307322740555, Accuracy: 99.70486111111111\n",
      "Epoch: 9, Batch: 90, Loss: 0.046567246317863464, Accuracy: 99.69093406593407\n",
      "Epoch: 9, Batch: 91, Loss: 0.019487516954541206, Accuracy: 99.68580163043478\n",
      "Epoch: 9, Batch: 92, Loss: 0.0038145571015775204, Accuracy: 99.68918010752688\n",
      "Epoch: 9, Batch: 93, Loss: 0.027383798733353615, Accuracy: 99.6841755319149\n",
      "Epoch: 9, Batch: 94, Loss: 0.004352967720478773, Accuracy: 99.6875\n",
      "Epoch: 9, Batch: 95, Loss: 0.02758905477821827, Accuracy: 99.67447916666666\n",
      "Epoch: 9, Batch: 96, Loss: 0.009665844030678272, Accuracy: 99.66978092783505\n",
      "Epoch: 9, Batch: 97, Loss: 0.029176965355873108, Accuracy: 99.66517857142857\n",
      "Epoch: 9, Batch: 98, Loss: 0.0302200336009264, Accuracy: 99.6606691919192\n",
      "Epoch: 9, Batch: 99, Loss: 0.02586137130856514, Accuracy: 99.6484375\n",
      "Epoch: 9, Batch: 100, Loss: 0.042069725692272186, Accuracy: 99.63644801980197\n",
      "Epoch: 9, Batch: 101, Loss: 0.008411838673055172, Accuracy: 99.64001225490196\n",
      "Epoch: 9, Batch: 102, Loss: 0.0037386210169643164, Accuracy: 99.6435072815534\n",
      "Epoch: 9, Batch: 103, Loss: 0.03517227992415428, Accuracy: 99.63942307692307\n",
      "Epoch: 9, Batch: 104, Loss: 0.025015084072947502, Accuracy: 99.63541666666667\n",
      "Epoch: 9, Batch: 105, Loss: 0.024365397170186043, Accuracy: 99.6314858490566\n",
      "Epoch: 9, Batch: 106, Loss: 0.004380412865430117, Accuracy: 99.63492990654206\n",
      "Epoch: 9, Batch: 107, Loss: 0.02286798134446144, Accuracy: 99.63107638888889\n",
      "Epoch: 9, Batch: 108, Loss: 0.040880780667066574, Accuracy: 99.62729357798165\n",
      "Epoch: 9, Batch: 109, Loss: 0.003526001237332821, Accuracy: 99.63068181818183\n",
      "Epoch: 9, Batch: 110, Loss: 0.02623595856130123, Accuracy: 99.61993243243244\n",
      "Epoch: 9, Batch: 111, Loss: 0.014104447327554226, Accuracy: 99.61635044642857\n",
      "Epoch: 9, Batch: 112, Loss: 0.01451501902192831, Accuracy: 99.61283185840708\n",
      "Epoch: 9, Batch: 113, Loss: 0.015674665570259094, Accuracy: 99.609375\n",
      "Epoch: 9, Batch: 114, Loss: 0.006626838818192482, Accuracy: 99.61277173913044\n",
      "Epoch: 9, Batch: 115, Loss: 0.01526238489896059, Accuracy: 99.61610991379311\n",
      "Epoch: 9, Batch: 116, Loss: 0.00451205438002944, Accuracy: 99.61939102564102\n",
      "Epoch: 9, Batch: 117, Loss: 0.01690291427075863, Accuracy: 99.62261652542372\n",
      "Epoch: 9, Batch: 118, Loss: 0.00573175773024559, Accuracy: 99.62578781512606\n",
      "Epoch: 9, Batch: 119, Loss: 0.007531709969043732, Accuracy: 99.62890625\n",
      "Epoch: 9, Batch: 120, Loss: 0.021071558818221092, Accuracy: 99.61905991735537\n",
      "Epoch: 9, Batch: 121, Loss: 0.02365177683532238, Accuracy: 99.61577868852459\n",
      "Epoch: 9, Batch: 122, Loss: 0.022208498790860176, Accuracy: 99.61255081300813\n",
      "Epoch: 9, Batch: 123, Loss: 0.02902635931968689, Accuracy: 99.609375\n",
      "Epoch: 9, Batch: 124, Loss: 0.0019564726389944553, Accuracy: 99.6125\n",
      "Epoch: 9, Batch: 125, Loss: 0.008174655959010124, Accuracy: 99.61557539682539\n",
      "Epoch: 9, Batch: 126, Loss: 0.0191735178232193, Accuracy: 99.61245078740157\n",
      "Epoch: 9, Batch: 127, Loss: 0.004387977998703718, Accuracy: 99.615478515625\n",
      "Epoch: 9, Batch: 128, Loss: 0.00287085073068738, Accuracy: 99.61845930232558\n",
      "Epoch: 9, Batch: 129, Loss: 0.003868554951623082, Accuracy: 99.62139423076923\n",
      "Epoch: 9, Batch: 130, Loss: 0.002361972350627184, Accuracy: 99.62428435114504\n",
      "Epoch: 9, Batch: 131, Loss: 0.030932778492569923, Accuracy: 99.61529356060606\n",
      "Epoch: 9, Batch: 132, Loss: 0.013470199890434742, Accuracy: 99.61231203007519\n",
      "Epoch: 9, Batch: 133, Loss: 0.0015244964743033051, Accuracy: 99.6152052238806\n",
      "Epoch: 9, Batch: 134, Loss: 0.0015867302427068353, Accuracy: 99.61805555555556\n",
      "Epoch: 9, Batch: 135, Loss: 0.003349623177200556, Accuracy: 99.62086397058823\n",
      "Epoch: 9, Batch: 136, Loss: 0.008138014003634453, Accuracy: 99.6236313868613\n",
      "Epoch: 9, Batch: 137, Loss: 0.0031608629506081343, Accuracy: 99.62635869565217\n",
      "Epoch: 9, Batch: 138, Loss: 0.005932406987994909, Accuracy: 99.62904676258992\n",
      "Epoch: 9, Batch: 139, Loss: 0.0051321168430149555, Accuracy: 99.63169642857143\n",
      "Epoch: 9, Batch: 140, Loss: 0.005372191313654184, Accuracy: 99.6343085106383\n",
      "Epoch: 9, Batch: 141, Loss: 0.0012482642196118832, Accuracy: 99.6368838028169\n",
      "Epoch: 9, Batch: 142, Loss: 0.02214829809963703, Accuracy: 99.6284965034965\n",
      "Epoch: 9, Batch: 143, Loss: 0.07919693738222122, Accuracy: 99.62022569444444\n",
      "Epoch: 9, Batch: 144, Loss: 0.005216660443693399, Accuracy: 99.6228448275862\n",
      "Epoch: 9, Batch: 145, Loss: 0.058090366423130035, Accuracy: 99.62007705479452\n",
      "Epoch: 9, Batch: 146, Loss: 0.002571097109466791, Accuracy: 99.62266156462584\n",
      "Epoch: 9, Batch: 147, Loss: 0.004179851617664099, Accuracy: 99.62521114864865\n",
      "Epoch: 9, Batch: 148, Loss: 0.0019940463826060295, Accuracy: 99.62772651006712\n",
      "Epoch: 9, Batch: 149, Loss: 0.005767778027802706, Accuracy: 99.63020833333334\n",
      "Epoch: 9, Batch: 150, Loss: 0.06874910742044449, Accuracy: 99.62230960264901\n",
      "Epoch: 9, Batch: 151, Loss: 0.05210145190358162, Accuracy: 99.61965460526315\n",
      "Epoch: 9, Batch: 152, Loss: 0.013012281619012356, Accuracy: 99.6170343137255\n",
      "Epoch: 9, Batch: 153, Loss: 0.027348382398486137, Accuracy: 99.61444805194806\n",
      "Epoch: 9, Batch: 154, Loss: 0.0024949449580162764, Accuracy: 99.61693548387098\n",
      "Epoch: 9, Batch: 155, Loss: 0.006395169999450445, Accuracy: 99.61939102564102\n",
      "Epoch: 9, Batch: 156, Loss: 0.01891326531767845, Accuracy: 99.61683917197452\n",
      "Epoch: 9, Batch: 157, Loss: 0.057894445955753326, Accuracy: 99.59948575949366\n",
      "Epoch: 9, Batch: 158, Loss: 0.0029706498607993126, Accuracy: 99.60200471698113\n",
      "Epoch: 9, Batch: 159, Loss: 0.002587137511000037, Accuracy: 99.6044921875\n",
      "Epoch: 9, Batch: 160, Loss: 0.0138881616294384, Accuracy: 99.605128455126\n",
      "Epoch: 9, Training Loss: 0.014170160106750587\n",
      "Epoch: 9, Validation Loss: 0.6945355981588364, Validation Accuracy: 85.10555121188429\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses, train_acc, val_acc = train(model, train_loader, val_loader, num_epochs, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6438525174715504, 0.3750426643383429, 0.23797084918673733, 0.13217204519958228, 0.0703992367901417, 0.0447580324202452, 0.02903494787668543, 0.019578035338781774, 0.014937046991215775, 0.014170160106750587]\n",
      "[0.4588153839111328, 0.357867069542408, 0.3535968132317066, 0.399478055536747, 0.5004635065793991, 0.5388987690210343, 0.6251110181212425, 0.6567952513694764, 0.6640172496438026, 0.6945355981588364]\n",
      "[62.58470238385414, 83.69326768390776, 90.75708087554234, 95.51991420075075, 97.8793935553064, 98.70813630380734, 99.12250767805781, 99.43937990542582, 99.52225418027592, 99.605128455126]\n",
      "[78.81157154026583, 83.85457388584831, 85.69194683346365, 85.02736512900704, 84.71462079749804, 85.10555121188429, 85.3010164190774, 84.75371383893668, 85.26192337763878, 85.10555121188429]\n"
     ]
    }
   ],
   "source": [
    "print(train_losses)\n",
    "print(val_losses)\n",
    "print(train_acc)\n",
    "print(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(data)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "    print(\"Accuracy: {}\".format(correct/total))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8444444444444444\n"
     ]
    }
   ],
   "source": [
    "test(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
