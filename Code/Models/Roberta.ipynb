{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceType":"datasetVersion","sourceId":9966468,"datasetId":6106467,"databundleVersionId":10230770},{"sourceType":"datasetVersion","sourceId":9966433,"datasetId":6130994,"databundleVersionId":10230730}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-19T23:03:43.537435Z","iopub.execute_input":"2024-11-19T23:03:43.538041Z","iopub.status.idle":"2024-11-19T23:03:44.603970Z","shell.execute_reply.started":"2024-11-19T23:03:43.538011Z","shell.execute_reply":"2024-11-19T23:03:44.602964Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/anlp-datasets/preprocessed data/twitter/twitter_test.csv\n/kaggle/input/anlp-datasets/preprocessed data/twitter/twitter_dev.csv\n/kaggle/input/anlp-datasets/preprocessed data/twitter/twitter_train.csv\n/kaggle/input/anlp-datasets/preprocessed data/news Headlines/news_headlines_test.csv\n/kaggle/input/anlp-datasets/preprocessed data/news Headlines/news_headlines_train.csv\n/kaggle/input/anlp-datasets/preprocessed data/news Headlines/news_headlines_dev.csv\n/kaggle/input/anlp-datasets/preprocessed data/reddit/reddit_dev.csv\n/kaggle/input/anlp-datasets/preprocessed data/reddit/reddit_test.csv\n/kaggle/input/anlp-datasets/preprocessed data/reddit/reddit_train.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Twitter Dataset","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\nfrom transformers import Trainer, TrainingArguments\nfrom sklearn.metrics import accuracy_score, f1_score\nimport itertools\nimport warnings\n\nwarnings.filterwarnings('ignore')\n\n# Custom Dataset Class\nclass SarcasmDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {\n            'input_ids': torch.tensor(self.encodings['input_ids'][idx], dtype=torch.long),\n            'attention_mask': torch.tensor(self.encodings['attention_mask'][idx], dtype=torch.long),\n            'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n        }\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\n# Metrics Computation\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    return {\n        \"accuracy\": accuracy_score(y_true=labels, y_pred=predictions),\n        \"f1_score\": f1_score(y_true=labels, y_pred=predictions)\n    }\n\n# Custom Trainer Class\nclass CustomTrainer(Trainer):\n    def __init__(self, class_weights=None, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.class_weights = class_weights.float() if class_weights is not None else torch.tensor([1.0, 1.0], dtype=torch.float32)\n\n    def compute_loss(self, model, inputs, return_outputs=False):\n        inputs = {\n            'input_ids': inputs['input_ids'].long(),\n            'attention_mask': inputs['attention_mask'].long(),\n            'labels': inputs['labels'].long()\n        }\n        outputs = model(**inputs)\n        logits = outputs.get('logits')\n        class_weights = self.class_weights.to(logits.device)\n        loss_fct = nn.CrossEntropyLoss(weight=class_weights)\n        loss = loss_fct(logits.view(-1, self.model.config.num_labels), inputs['labels'].view(-1))\n        return (loss, outputs) if return_outputs else loss\n\n# Dataset Preparation\ndef prepare_datasets(tokenizer):\n    train = pd.read_csv('/kaggle/input/anlp-datasets/preprocessed data/twitter/twitter_train.csv')\n    val = pd.read_csv('/kaggle/input/anlp-datasets/preprocessed data/twitter/twitter_test.csv')\n\n    train_tweets = train['preprocessed_text'].tolist()\n    train_labels = train['Label'].apply(lambda x: 1 if x != 0 else 0).tolist()\n    val_tweets = val['preprocessed_text'].tolist()\n    val_labels = val['Label'].apply(lambda x: 1 if x != 0 else 0).tolist()\n\n    train_encodings = tokenizer(train_tweets, truncation=True, padding=True, max_length=128, return_tensors='pt')\n    val_encodings = tokenizer(val_tweets, truncation=True, padding=True, max_length=128, return_tensors='pt')\n\n    train_dataset = SarcasmDataset(train_encodings, train_labels)\n    val_dataset = SarcasmDataset(val_encodings, val_labels)\n\n    label_counts = pd.Series(train_labels).value_counts()\n    total_samples = len(train_labels)\n    class_weights = torch.tensor([\n        total_samples / (len(label_counts) * label_counts[0]),\n        total_samples / (len(label_counts) * label_counts[1])\n    ], dtype=torch.float32)\n\n    return train_dataset, val_dataset, class_weights\n\n# Hyperparameter Grid Search\ndef grid_search():\n    param_grid = {\n        \"learning_rate\": [1e-6, 5e-6, 1e-5],\n        \"batch_size\": [16, 32],\n        \"weight_decay\": [1e-4, 1e-2],\n        \"warmup_steps\": [100, 500],\n        \"num_epochs\": [2, 3]\n    }\n\n    param_combinations = list(itertools.product(*param_grid.values()))\n    param_names = list(param_grid.keys())\n\n    model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    model = AutoModelForSequenceClassification.from_pretrained(\n        model_name,\n        num_labels=2,\n        ignore_mismatched_sizes=True\n    )\n\n    train_dataset, val_dataset, class_weights = prepare_datasets(tokenizer)\n\n    best_f1 = 0\n    best_params = None\n\n    for combination in param_combinations:\n        params = dict(zip(param_names, combination))\n\n        training_args = TrainingArguments(\n            output_dir='/tmp/temp_trainer',\n            evaluation_strategy=\"steps\",\n            eval_steps=500,\n            num_train_epochs=params[\"num_epochs\"],\n            per_device_train_batch_size=params[\"batch_size\"],\n            per_device_eval_batch_size=params[\"batch_size\"] * 2,\n            warmup_steps=params[\"warmup_steps\"],\n            weight_decay=params[\"weight_decay\"],\n            learning_rate=params[\"learning_rate\"],\n            max_grad_norm=1.0,\n            save_strategy=\"no\",\n            report_to=\"none\"\n        )\n\n        trainer = CustomTrainer(\n            class_weights=class_weights,\n            model=model,\n            args=training_args,\n            train_dataset=train_dataset,\n            eval_dataset=val_dataset,\n            compute_metrics=compute_metrics,\n        )\n\n        trainer.train()\n        eval_results = trainer.evaluate()\n\n        print(f\"Params: {params}, F1 Score: {eval_results['eval_f1_score']}\")\n\n        if eval_results[\"eval_f1_score\"] > best_f1:\n            best_f1 = eval_results[\"eval_f1_score\"]\n            best_params = params\n\n    print(f\"Best F1 Score: {best_f1}\")\n    print(f\"Best Params: {best_params}\")\n\n    return best_params\n\n# Main Function\ndef main():\n    best_params = grid_search()\n    print(\"\\nTraining final model with best parameters...\")\n\n    model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    model = AutoModelForSequenceClassification.from_pretrained(\n        model_name,\n        num_labels=2,\n        ignore_mismatched_sizes=True\n    )\n\n    train_dataset, val_dataset, class_weights = prepare_datasets(tokenizer)\n\n    training_args = TrainingArguments(\n        output_dir='./final_model',\n        evaluation_strategy=\"steps\",\n        eval_steps=500,\n        num_train_epochs=best_params[\"num_epochs\"],\n        per_device_train_batch_size=best_params[\"batch_size\"],\n        per_device_eval_batch_size=best_params[\"batch_size\"] * 2,\n        warmup_steps=best_params[\"warmup_steps\"],\n        weight_decay=best_params[\"weight_decay\"],\n        learning_rate=best_params[\"learning_rate\"],\n        max_grad_norm=1.0,\n        save_strategy=\"epoch\",\n        save_total_limit=1\n    )\n\n    trainer = CustomTrainer(\n        class_weights=class_weights,\n        model=model,\n        args=training_args,\n        train_dataset=train_dataset,\n        eval_dataset=val_dataset,\n        compute_metrics=compute_metrics,\n    )\n\n    trainer.train()\n    final_results = trainer.evaluate()\n    print(f\"\\nFinal Model Results: {final_results}\")\n\n    trainer.save_model('./sarcasm_detector_model_tuned')\n    tokenizer.save_pretrained('./sarcasm_detector_model_tuned')\n\nif __name__ == '__main__':\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T19:32:58.341523Z","iopub.execute_input":"2024-11-20T19:32:58.342078Z","iopub.status.idle":"2024-11-20T20:54:29.735293Z","shell.execute_reply.started":"2024-11-20T19:32:58.342042Z","shell.execute_reply":"2024-11-20T20:54:29.734328Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/747 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39d0a760b89649d0b705a978b5ffb0e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"284a9888a743431d8c73020f250ea524"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e74bcf03d1a94816ab56f7dee14e21d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd4e10d6401e4e7caf776beb6ebf7ffd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00ff879d59b147e4b5343379fb04016a"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment and are newly initialized because the shapes did not match:\n- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='382' max='382' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [382/382 01:16, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [12/12 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Params: {'learning_rate': 1e-06, 'batch_size': 16, 'weight_decay': 0.0001, 'warmup_steps': 100, 'num_epochs': 2}, F1 Score: 0.6142131979695432\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='573' max='573' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [573/573 01:54, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1 Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.634600</td>\n      <td>0.631335</td>\n      <td>0.623037</td>\n      <td>0.623037</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [12/12 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Params: {'learning_rate': 1e-06, 'batch_size': 16, 'weight_decay': 0.0001, 'warmup_steps': 100, 'num_epochs': 3}, F1 Score: 0.6230366492146597\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='382' max='382' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [382/382 01:16, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [12/12 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Params: {'learning_rate': 1e-06, 'batch_size': 16, 'weight_decay': 0.0001, 'warmup_steps': 500, 'num_epochs': 2}, F1 Score: 0.6321243523316064\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='573' max='573' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [573/573 01:55, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1 Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.582700</td>\n      <td>0.597549</td>\n      <td>0.646597</td>\n      <td>0.677804</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [12/12 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Params: {'learning_rate': 1e-06, 'batch_size': 16, 'weight_decay': 0.0001, 'warmup_steps': 500, 'num_epochs': 3}, F1 Score: 0.6747572815533981\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='382' max='382' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [382/382 01:16, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [12/12 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Params: {'learning_rate': 1e-06, 'batch_size': 16, 'weight_decay': 0.01, 'warmup_steps': 100, 'num_epochs': 2}, F1 Score: 0.6923076923076923\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='573' max='573' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [573/573 01:55, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1 Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.516300</td>\n      <td>0.578450</td>\n      <td>0.664921</td>\n      <td>0.690821</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [12/12 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Params: {'learning_rate': 1e-06, 'batch_size': 16, 'weight_decay': 0.01, 'warmup_steps': 100, 'num_epochs': 3}, F1 Score: 0.6939759036144578\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='382' max='382' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [382/382 01:16, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [12/12 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Params: {'learning_rate': 1e-06, 'batch_size': 16, 'weight_decay': 0.01, 'warmup_steps': 500, 'num_epochs': 2}, F1 Score: 0.7121951219512195\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='573' max='573' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [573/573 01:55, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1 Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.466500</td>\n      <td>0.573676</td>\n      <td>0.685864</td>\n      <td>0.710145</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [12/12 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Params: {'learning_rate': 1e-06, 'batch_size': 16, 'weight_decay': 0.01, 'warmup_steps': 500, 'num_epochs': 3}, F1 Score: 0.714975845410628\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='192' max='192' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [192/192 01:09, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [6/6 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Params: {'learning_rate': 1e-06, 'batch_size': 32, 'weight_decay': 0.0001, 'warmup_steps': 100, 'num_epochs': 2}, F1 Score: 0.7104622871046228\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='288' max='288' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [288/288 01:44, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [6/6 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Params: {'learning_rate': 1e-06, 'batch_size': 32, 'weight_decay': 0.0001, 'warmup_steps': 100, 'num_epochs': 3}, F1 Score: 0.7101449275362319\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='192' max='192' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [192/192 01:09, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [6/6 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Params: {'learning_rate': 1e-06, 'batch_size': 32, 'weight_decay': 0.0001, 'warmup_steps': 500, 'num_epochs': 2}, F1 Score: 0.714975845410628\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='288' max='288' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [288/288 01:44, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [6/6 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Params: {'learning_rate': 1e-06, 'batch_size': 32, 'weight_decay': 0.0001, 'warmup_steps': 500, 'num_epochs': 3}, F1 Score: 0.7255369928400954\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='192' max='192' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [192/192 01:09, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [6/6 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Params: {'learning_rate': 1e-06, 'batch_size': 32, 'weight_decay': 0.01, 'warmup_steps': 100, 'num_epochs': 2}, F1 Score: 0.727710843373494\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='288' max='288' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [288/288 01:44, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [6/6 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Params: {'learning_rate': 1e-06, 'batch_size': 32, 'weight_decay': 0.01, 'warmup_steps': 100, 'num_epochs': 3}, F1 Score: 0.7299270072992701\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='192' max='192' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [192/192 01:09, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [6/6 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Params: {'learning_rate': 1e-06, 'batch_size': 32, 'weight_decay': 0.01, 'warmup_steps': 500, 'num_epochs': 2}, F1 Score: 0.7317073170731707\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='288' max='288' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [288/288 01:44, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [6/6 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Params: {'learning_rate': 1e-06, 'batch_size': 32, 'weight_decay': 0.01, 'warmup_steps': 500, 'num_epochs': 3}, F1 Score: 0.7228915662650603\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='382' max='382' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [382/382 01:16, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [12/12 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Params: {'learning_rate': 5e-06, 'batch_size': 16, 'weight_decay': 0.0001, 'warmup_steps': 100, 'num_epochs': 2}, F1 Score: 0.7070707070707071\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='573' max='573' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [573/573 01:55, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1 Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.201400</td>\n      <td>0.931062</td>\n      <td>0.704188</td>\n      <td>0.718204</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [12/12 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Params: {'learning_rate': 5e-06, 'batch_size': 16, 'weight_decay': 0.0001, 'warmup_steps': 100, 'num_epochs': 3}, F1 Score: 0.7192118226600985\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='382' max='382' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [382/382 01:16, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [12/12 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Params: {'learning_rate': 5e-06, 'batch_size': 16, 'weight_decay': 0.0001, 'warmup_steps': 500, 'num_epochs': 2}, F1 Score: 0.7207637231503579\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='573' max='573' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [573/573 01:55, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1 Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.074900</td>\n      <td>1.629211</td>\n      <td>0.696335</td>\n      <td>0.699482</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [12/12 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Params: {'learning_rate': 5e-06, 'batch_size': 16, 'weight_decay': 0.0001, 'warmup_steps': 500, 'num_epochs': 3}, F1 Score: 0.6969696969696969\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='382' max='382' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [382/382 01:16, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [12/12 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Params: {'learning_rate': 5e-06, 'batch_size': 16, 'weight_decay': 0.01, 'warmup_steps': 100, 'num_epochs': 2}, F1 Score: 0.7076923076923076\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='573' max='573' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [573/573 01:55, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1 Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.016800</td>\n      <td>2.279792</td>\n      <td>0.691099</td>\n      <td>0.691099</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [12/12 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Params: {'learning_rate': 5e-06, 'batch_size': 16, 'weight_decay': 0.01, 'warmup_steps': 100, 'num_epochs': 3}, F1 Score: 0.7178217821782177\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='382' max='382' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [382/382 01:16, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [12/12 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Params: {'learning_rate': 5e-06, 'batch_size': 16, 'weight_decay': 0.01, 'warmup_steps': 500, 'num_epochs': 2}, F1 Score: 0.727710843373494\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='573' max='573' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [573/573 01:55, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1 Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.010600</td>\n      <td>2.886394</td>\n      <td>0.685864</td>\n      <td>0.695431</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [12/12 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Params: {'learning_rate': 5e-06, 'batch_size': 16, 'weight_decay': 0.01, 'warmup_steps': 500, 'num_epochs': 3}, F1 Score: 0.6870229007633588\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='192' max='192' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [192/192 01:09, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [6/6 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Params: {'learning_rate': 5e-06, 'batch_size': 32, 'weight_decay': 0.0001, 'warmup_steps': 100, 'num_epochs': 2}, F1 Score: 0.6984924623115579\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='288' max='288' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [288/288 01:43, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [6/6 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Params: {'learning_rate': 5e-06, 'batch_size': 32, 'weight_decay': 0.0001, 'warmup_steps': 100, 'num_epochs': 3}, F1 Score: 0.7044334975369458\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='192' max='192' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [192/192 01:09, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [6/6 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Params: {'learning_rate': 5e-06, 'batch_size': 32, 'weight_decay': 0.0001, 'warmup_steps': 500, 'num_epochs': 2}, F1 Score: 0.7047619047619048\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='288' max='288' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [288/288 01:44, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [6/6 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Params: {'learning_rate': 5e-06, 'batch_size': 32, 'weight_decay': 0.0001, 'warmup_steps': 500, 'num_epochs': 3}, F1 Score: 0.702439024390244\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='192' max='192' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [192/192 01:09, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [6/6 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Params: {'learning_rate': 5e-06, 'batch_size': 32, 'weight_decay': 0.01, 'warmup_steps': 100, 'num_epochs': 2}, F1 Score: 0.7032418952618454\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='288' max='288' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [288/288 01:44, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [6/6 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Params: {'learning_rate': 5e-06, 'batch_size': 32, 'weight_decay': 0.01, 'warmup_steps': 100, 'num_epochs': 3}, F1 Score: 0.7111111111111111\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='192' max='192' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [192/192 01:09, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [6/6 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Params: {'learning_rate': 5e-06, 'batch_size': 32, 'weight_decay': 0.01, 'warmup_steps': 500, 'num_epochs': 2}, F1 Score: 0.6994818652849741\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='288' max='288' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [288/288 01:44, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [6/6 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Params: {'learning_rate': 5e-06, 'batch_size': 32, 'weight_decay': 0.01, 'warmup_steps': 500, 'num_epochs': 3}, F1 Score: 0.7064676616915422\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='382' max='382' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [382/382 01:16, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [12/12 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Params: {'learning_rate': 1e-05, 'batch_size': 16, 'weight_decay': 0.0001, 'warmup_steps': 100, 'num_epochs': 2}, F1 Score: 0.7037974683544304\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='573' max='573' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [573/573 01:55, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1 Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.021200</td>\n      <td>3.062853</td>\n      <td>0.714660</td>\n      <td>0.744731</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [12/12 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Params: {'learning_rate': 1e-05, 'batch_size': 16, 'weight_decay': 0.0001, 'warmup_steps': 100, 'num_epochs': 3}, F1 Score: 0.721153846153846\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='382' max='382' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [382/382 01:16, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [12/12 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Params: {'learning_rate': 1e-05, 'batch_size': 16, 'weight_decay': 0.0001, 'warmup_steps': 500, 'num_epochs': 2}, F1 Score: 0.730593607305936\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='573' max='573' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [573/573 01:55, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1 Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.028600</td>\n      <td>2.436673</td>\n      <td>0.735602</td>\n      <td>0.761229</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [12/12 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Params: {'learning_rate': 1e-05, 'batch_size': 16, 'weight_decay': 0.0001, 'warmup_steps': 500, 'num_epochs': 3}, F1 Score: 0.7233009708737863\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='382' max='382' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [382/382 01:16, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [12/12 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Params: {'learning_rate': 1e-05, 'batch_size': 16, 'weight_decay': 0.01, 'warmup_steps': 100, 'num_epochs': 2}, F1 Score: 0.7277227722772278\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='573' max='573' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [573/573 01:55, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1 Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.019100</td>\n      <td>2.940755</td>\n      <td>0.709424</td>\n      <td>0.733813</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [12/12 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Params: {'learning_rate': 1e-05, 'batch_size': 16, 'weight_decay': 0.01, 'warmup_steps': 100, 'num_epochs': 3}, F1 Score: 0.7272727272727273\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='382' max='382' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [382/382 01:16, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [12/12 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Params: {'learning_rate': 1e-05, 'batch_size': 16, 'weight_decay': 0.01, 'warmup_steps': 500, 'num_epochs': 2}, F1 Score: 0.7445887445887447\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='573' max='573' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [573/573 01:55, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1 Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.025800</td>\n      <td>3.307891</td>\n      <td>0.706806</td>\n      <td>0.726829</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [12/12 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Params: {'learning_rate': 1e-05, 'batch_size': 16, 'weight_decay': 0.01, 'warmup_steps': 500, 'num_epochs': 3}, F1 Score: 0.6977886977886977\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='192' max='192' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [192/192 01:09, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [6/6 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Params: {'learning_rate': 1e-05, 'batch_size': 32, 'weight_decay': 0.0001, 'warmup_steps': 100, 'num_epochs': 2}, F1 Score: 0.7205882352941178\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='288' max='288' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [288/288 01:44, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [6/6 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Params: {'learning_rate': 1e-05, 'batch_size': 32, 'weight_decay': 0.0001, 'warmup_steps': 100, 'num_epochs': 3}, F1 Score: 0.7106598984771574\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='192' max='192' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [192/192 01:09, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [6/6 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Params: {'learning_rate': 1e-05, 'batch_size': 32, 'weight_decay': 0.0001, 'warmup_steps': 500, 'num_epochs': 2}, F1 Score: 0.7268292682926829\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='288' max='288' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [288/288 01:44, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [6/6 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Params: {'learning_rate': 1e-05, 'batch_size': 32, 'weight_decay': 0.0001, 'warmup_steps': 500, 'num_epochs': 3}, F1 Score: 0.6904109589041096\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='192' max='192' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [192/192 01:09, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [6/6 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Params: {'learning_rate': 1e-05, 'batch_size': 32, 'weight_decay': 0.01, 'warmup_steps': 100, 'num_epochs': 2}, F1 Score: 0.7167919799498746\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='288' max='288' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [288/288 01:44, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [6/6 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Params: {'learning_rate': 1e-05, 'batch_size': 32, 'weight_decay': 0.01, 'warmup_steps': 100, 'num_epochs': 3}, F1 Score: 0.7227722772277227\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='192' max='192' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [192/192 01:09, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [6/6 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Params: {'learning_rate': 1e-05, 'batch_size': 32, 'weight_decay': 0.01, 'warmup_steps': 500, 'num_epochs': 2}, F1 Score: 0.7209876543209877\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='288' max='288' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [288/288 01:44, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [6/6 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Params: {'learning_rate': 1e-05, 'batch_size': 32, 'weight_decay': 0.01, 'warmup_steps': 500, 'num_epochs': 3}, F1 Score: 0.7517084282460138\nBest F1 Score: 0.7517084282460138\nBest Params: {'learning_rate': 1e-05, 'batch_size': 32, 'weight_decay': 0.01, 'warmup_steps': 500, 'num_epochs': 3}\n\nTraining final model with best parameters...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment and are newly initialized because the shapes did not match:\n- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01111294421111274, max=1.0)…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d734aac6400d42d987c43edf2326475c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241120_205227-pvg8u705</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/a_max98-iiit-hyderabad/huggingface/runs/pvg8u705' target=\"_blank\">./final_model</a></strong> to <a href='https://wandb.ai/a_max98-iiit-hyderabad/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/a_max98-iiit-hyderabad/huggingface' target=\"_blank\">https://wandb.ai/a_max98-iiit-hyderabad/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/a_max98-iiit-hyderabad/huggingface/runs/pvg8u705' target=\"_blank\">https://wandb.ai/a_max98-iiit-hyderabad/huggingface/runs/pvg8u705</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='288' max='288' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [288/288 01:56, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [6/6 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"\nFinal Model Results: {'eval_loss': 0.5825455784797668, 'eval_accuracy': 0.6780104712041884, 'eval_f1_score': 0.6870229007633588, 'eval_runtime': 0.5511, 'eval_samples_per_second': 693.12, 'eval_steps_per_second': 10.887, 'epoch': 3.0}\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"best_params = {'learning_rate': 1e-05, 'batch_size': 32, 'weight_decay': 0.01, 'warmup_steps': 500, 'num_epochs': 3}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T21:29:37.033104Z","iopub.execute_input":"2024-11-20T21:29:37.033451Z","iopub.status.idle":"2024-11-20T21:29:37.038488Z","shell.execute_reply.started":"2024-11-20T21:29:37.033423Z","shell.execute_reply":"2024-11-20T21:29:37.037713Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"### News HeadLines Dataset","metadata":{}},{"cell_type":"code","source":"def prepare_datasets(tokenizer):\n    train = pd.read_csv('/kaggle/input/anlp-datasets/preprocessed data/news_headlines/news_headlines_train.csv')\n    val = pd.read_csv('/kaggle/input/anlp-datasets/preprocessed data/news_headlines/news_headlines_dev.csv')\n\n    train_tweets = train['preprocessed_text'].tolist()\n    train_labels = train['label'].apply(lambda x: 1 if x != 0 else 0).tolist()\n    val_tweets = val['preprocessed_text'].tolist()\n    val_labels = val['label'].apply(lambda x: 1 if x != 0 else 0).tolist()\n\n    train_encodings = tokenizer(train_tweets, truncation=True, padding=True, max_length=128, return_tensors='pt')\n    val_encodings = tokenizer(val_tweets, truncation=True, padding=True, max_length=128, return_tensors='pt')\n\n    train_dataset = SarcasmDataset(train_encodings, train_labels)\n    val_dataset = SarcasmDataset(val_encodings, val_labels)\n\n    label_counts = pd.Series(train_labels).value_counts()\n    total_samples = len(train_labels)\n    class_weights = torch.tensor([\n        total_samples / (len(label_counts) * label_counts[0]),\n        total_samples / (len(label_counts) * label_counts[1])\n    ], dtype=torch.float32)\n\n    return train_dataset, val_dataset, class_weights","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T21:32:48.346962Z","iopub.execute_input":"2024-11-20T21:32:48.347618Z","iopub.status.idle":"2024-11-20T21:32:48.355180Z","shell.execute_reply.started":"2024-11-20T21:32:48.347587Z","shell.execute_reply":"2024-11-20T21:32:48.354342Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def prepare_news_headlines_dataset(tokenizer):\n    \"\"\"Prepare the dataset for the news headlines.\"\"\"\n    news_data = pd.read_csv('/kaggle/input/anlp-datasets/preprocessed data/news_headlines/news_headlines_dev.csv')\n    \n    news_tweets = news_data['preprocessed_text'].tolist()\n    news_labels = news_data['label'].apply(lambda x: 1 if x != 0 else 0).tolist()\n\n    news_encodings = tokenizer(news_tweets, truncation=True, padding=True, max_length=128, return_tensors='pt')\n    news_dataset = SarcasmDataset(news_encodings, news_labels)\n\n    return news_dataset\n\ndef train_on_news_headlines(best_params):\n    \"\"\"Train and evaluate the model on the news headlines dataset using the best parameters.\"\"\"\n    print(\"\\nTraining on News Headlines Dataset...\")\n\n    model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    model = AutoModelForSequenceClassification.from_pretrained(\n        model_name,\n        num_labels=2,\n        ignore_mismatched_sizes=True\n    )\n\n    train_dataset, val_dataset, class_weights = prepare_datasets(tokenizer)\n    news_dataset = prepare_news_headlines_dataset(tokenizer)\n\n    training_args = TrainingArguments(\n        output_dir='./final_model_news',\n        evaluation_strategy=\"steps\",\n        eval_steps=500,\n        num_train_epochs=best_params[\"num_epochs\"],\n        per_device_train_batch_size=best_params[\"batch_size\"],\n        per_device_eval_batch_size=best_params[\"batch_size\"] * 2,\n        warmup_steps=best_params[\"warmup_steps\"],\n        weight_decay=best_params[\"weight_decay\"],\n        learning_rate=best_params[\"learning_rate\"],\n        max_grad_norm=1.0,\n        save_strategy=\"epoch\",\n        save_total_limit=1,\n        logging_dir='./logs_news',\n        logging_steps=500,\n    )\n\n    trainer = CustomTrainer(\n        class_weights=class_weights,\n        model=model,\n        args=training_args,\n        train_dataset=news_dataset,\n        eval_dataset=val_dataset,\n        compute_metrics=compute_metrics,\n    )\n\n    trainer.train()\n    news_results = trainer.evaluate()\n    print(f\"\\nResults on News Headlines Dataset: {news_results}\")\n\n    trainer.save_model('./sarcasm_detector_model_news')\n    tokenizer.save_pretrained('./sarcasm_detector_model_news')\n\n# Update the main function to include training on news headlines dataset\ndef main():\n    # best_params = grid_search()\n    # print(\"\\nTraining final model with best parameters...\")\n\n    model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    model = AutoModelForSequenceClassification.from_pretrained(\n        model_name,\n        num_labels=2,\n        ignore_mismatched_sizes=True\n    )\n\n    train_dataset, val_dataset, class_weights = prepare_datasets(tokenizer)\n\n    training_args = TrainingArguments(\n        output_dir='./final_model',\n        evaluation_strategy=\"steps\",\n        eval_steps=500,\n        num_train_epochs=best_params[\"num_epochs\"],\n        per_device_train_batch_size=best_params[\"batch_size\"],\n        per_device_eval_batch_size=best_params[\"batch_size\"] * 2,\n        warmup_steps=best_params[\"warmup_steps\"],\n        weight_decay=best_params[\"weight_decay\"],\n        learning_rate=best_params[\"learning_rate\"],\n        max_grad_norm=1.0,\n        save_strategy=\"epoch\",\n        save_total_limit=1\n    )\n\n    trainer = CustomTrainer(\n        class_weights=class_weights,\n        model=model,\n        args=training_args,\n        train_dataset=train_dataset,\n        eval_dataset=val_dataset,\n        compute_metrics=compute_metrics,\n    )\n\n    trainer.train()\n    final_results = trainer.evaluate()\n    print(f\"\\nFinal Model Results: {final_results}\")\n\n    trainer.save_model('./sarcasm_detector_model_tuned')\n    tokenizer.save_pretrained('./sarcasm_detector_model_tuned')\n\n    # Train and evaluate on news headlines dataset\n    train_on_news_headlines(best_params)\n\nif __name__ == '__main__':\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T21:46:49.169847Z","iopub.execute_input":"2024-11-20T21:46:49.170234Z","iopub.status.idle":"2024-11-20T21:55:40.971659Z","shell.execute_reply.started":"2024-11-20T21:46:49.170201Z","shell.execute_reply":"2024-11-20T21:55:40.970716Z"}},"outputs":[{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment and are newly initialized because the shapes did not match:\n- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2004' max='2004' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2004/2004 07:50, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1 Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.487300</td>\n      <td>0.243117</td>\n      <td>0.901535</td>\n      <td>0.895676</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.218000</td>\n      <td>0.213803</td>\n      <td>0.921378</td>\n      <td>0.907895</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.162600</td>\n      <td>0.178787</td>\n      <td>0.940846</td>\n      <td>0.933669</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.121600</td>\n      <td>0.199604</td>\n      <td>0.935230</td>\n      <td>0.925847</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [42/42 00:02]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"\nFinal Model Results: {'eval_loss': 0.1996079981327057, 'eval_accuracy': 0.9352302508423811, 'eval_f1_score': 0.9258465495070723, 'eval_runtime': 2.8084, 'eval_samples_per_second': 951.077, 'eval_steps_per_second': 14.955, 'epoch': 3.0}\n\nTraining on News Headlines Dataset...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment and are newly initialized because the shapes did not match:\n- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='252' max='252' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [252/252 00:44, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [42/42 00:02]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"\nResults on News Headlines Dataset: {'eval_loss': 0.32278144359588623, 'eval_accuracy': 0.8723324597529015, 'eval_f1_score': 0.8597285067873303, 'eval_runtime': 2.7726, 'eval_samples_per_second': 963.346, 'eval_steps_per_second': 15.148, 'epoch': 3.0}\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}