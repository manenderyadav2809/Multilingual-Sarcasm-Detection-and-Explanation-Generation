{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T20:36:02.775606Z",
     "iopub.status.busy": "2024-11-19T20:36:02.775220Z",
     "iopub.status.idle": "2024-11-19T20:36:03.490659Z",
     "shell.execute_reply": "2024-11-19T20:36:03.489588Z",
     "shell.execute_reply.started": "2024-11-19T20:36:02.775570Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T20:30:03.327117Z",
     "iopub.status.busy": "2024-11-19T20:30:03.326722Z",
     "iopub.status.idle": "2024-11-19T20:30:03.338783Z",
     "shell.execute_reply": "2024-11-19T20:30:03.337562Z",
     "shell.execute_reply.started": "2024-11-19T20:30:03.327083Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def replace_emoticons(text):\n",
    "    \"\"\"\n",
    "    Replace common emoticons and emojis in the text with their textual descriptions.\n",
    "    \"\"\"\n",
    "    # Dictionary of common emoticons/emojis and their textual descriptions\n",
    "    emoticons_dict = {\n",
    "        r':\\)': 'Smile',\n",
    "        r':-\\)': 'Smile',\n",
    "        r':\\(': 'Sad',\n",
    "        r':-\\(': 'Sad',\n",
    "        r';\\)': 'Wink',\n",
    "        r';-\\)': 'Wink',\n",
    "        r':D': 'Laugh',\n",
    "        r':-D': 'Laugh',\n",
    "        r':P': 'Tongue',\n",
    "        r':-P': 'Tongue',\n",
    "        r':p': 'Tongue',\n",
    "        r':-p': 'Tongue',\n",
    "        r':O': 'Surprised',\n",
    "        r':-O': 'Surprised',\n",
    "        r':o': 'Surprised',\n",
    "        r':-o': 'Surprised',\n",
    "        r':\\|': 'Straight',\n",
    "        r':-\\|': 'Straight',\n",
    "        r':/': 'Skeptical',\n",
    "        r':-\\/': 'Skeptical',\n",
    "        r':\\\\': 'Skeptical',\n",
    "        r':-\\\\': 'Skeptical',\n",
    "        r':\\*': 'Kiss',\n",
    "        r':-\\*': 'Kiss',\n",
    "        r'>:\\(': 'Angry',\n",
    "        r'>:-\\(': 'Angry',\n",
    "        r':-\\]': 'Grin',\n",
    "        r'8\\)': 'Cool',\n",
    "        r'8-\\)': 'Cool',\n",
    "        r'O:\\)': 'Angel',\n",
    "        r'O:-\\)': 'Angel',\n",
    "        r'3:\\)': 'Devil',\n",
    "        r'3:-\\)': 'Devil',\n",
    "        r'B\\)': 'Cool',\n",
    "        r'B-\\)': 'Cool',\n",
    "        r'X\\(': 'Dead',\n",
    "        r'X-\\(': 'Dead',\n",
    "        r':\\'\\(': 'Crying',\n",
    "        r':\\'-\\(': 'Crying',\n",
    "        r':-\\[': 'Shy',\n",
    "        r'<3': 'Heart',\n",
    "        r'T_T': 'Crying',\n",
    "        r'\\\\o/': 'Celebration',\n",
    "        r'o/': 'Excited',\n",
    "        r'm/': 'Monkey',\n",
    "        r'-_-': 'Unamused',\n",
    "        r':yum:': 'Tasty',\n",
    "        r':X': 'Silent',\n",
    "        r'zzZ': 'Sleeping',\n",
    "        r'XD': 'Laughing',\n",
    "        r'XP': 'Playful',\n",
    "        r'n_n': 'Sleeping',\n",
    "        r'-_- zzz': 'Tired',\n",
    "        r':evil:': 'Evil',\n",
    "        r':mask:': 'Masked',\n",
    "        r'O_O': 'Shocked',\n",
    "        r':hear_no_evil:': 'Hear No Evil',\n",
    "        r'O:\\)': 'Innocent',\n",
    "        r'_/\\\\_': 'Bowing',\n",
    "        r'ðŸ˜': 'Heart Eyes',\n",
    "        r'ðŸ˜­': 'Crying Loudly',\n",
    "        r'ðŸ™': 'Praying',\n",
    "        r'ðŸ™Œ': 'Celebrating',\n",
    "        r'ðŸ™ˆ': 'See No Evil',\n",
    "        r'ðŸ˜’': 'Unamused',\n",
    "        r'ðŸ˜‹': 'Yummy',\n",
    "        r'ðŸ™Š': 'Speak No Evil',\n",
    "        r'ðŸ˜´': 'Sleeping',\n",
    "        r'ðŸ˜†': 'Laughing',\n",
    "        r'ðŸ˜œ': 'Winking Tongue Out',\n",
    "        r'ðŸ˜«': 'Exhausted',\n",
    "        r'ðŸ˜ˆ': 'Mischievous',\n",
    "        r'ðŸ˜·': 'Sick',\n",
    "        r'ðŸ˜²': 'Amazed',\n",
    "        r'ðŸ™‰': 'Hear No Evil',\n",
    "        r'ðŸ˜‡': 'Angel',\n",
    "        r'ðŸ™‡': 'Bowing'\n",
    "        # Add more emojis as needed\n",
    "    }\n",
    "\n",
    "    # Replace each emoticon or emoji with its description\n",
    "    for emoticon, description in emoticons_dict.items():\n",
    "        text = re.sub(re.escape(emoticon), description, text)\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T20:30:03.655474Z",
     "iopub.status.busy": "2024-11-19T20:30:03.654667Z",
     "iopub.status.idle": "2024-11-19T20:30:03.666216Z",
     "shell.execute_reply": "2024-11-19T20:30:03.665051Z",
     "shell.execute_reply.started": "2024-11-19T20:30:03.655433Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def replace_token(token):\n",
    "    \"\"\"\n",
    "    Replace tokens based on specific patterns.\n",
    "    \"\"\"\n",
    "    # Check for punctuations\n",
    "    if re.match(r'^[.,_-]+$', token):\n",
    "        return 'punctuation'\n",
    "\n",
    "    # Check for special characters\n",
    "    if re.match(r'^[@%&*=]+$', token):\n",
    "        return 'special'\n",
    "\n",
    "    # Check for currency symbols\n",
    "    if re.match(r'^[Â£$â‚¬Â¥â‚¹â‚½â‚©â‚ªâ‚«â‚´â‚¦â‚²â‚µâ‚®â‚±â‚­â‚ºâ‚¼â‚ â‚¡â‚¢â‚£â‚¤â‚¥â‚§â‚¨â‚©â‚ªâ‚«â‚¬â‚­â‚®â‚¯â‚°â‚±â‚²â‚³â‚´â‚µâ‚¶â‚·â‚¸â‚¹â‚ºâ‚»â‚¼â‚½â‚¾â‚¿]+$', token):\n",
    "        return 'currency'\n",
    "\n",
    "    return token\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Preprocess the text by applying various transformations.\n",
    "    \"\"\"\n",
    "    # Replace emoticons\n",
    "    text = replace_emoticons(text)\n",
    "\n",
    "    # Replace possible sarcasm expressions with possibility\n",
    "    text = re.sub(r'\\. \\.\\.', ' possibility ', text)\n",
    "    text = re.sub(r'\\. \\.\\.\\.', ' possibility ', text)\n",
    "\n",
    "    # Replace patterns like \"250,000\", \"3,600\" with \"NUM\"\n",
    "    text = re.sub(r'\\b\\d{1,3}(?:,\\d{3})*(?!\\d)', 'NUM', text)\n",
    "\n",
    "    # Replace alphanumeric patterns like \"r800\", \"23pts\" with \"ALPHANUM\"\n",
    "    text = re.sub(r'\\b(?:[a-zA-Z]+\\d+|\\d+[a-zA-Z]+)[a-zA-Z]*\\b', 'ALPHANUM', text)\n",
    "\n",
    "    # Replace range patterns like \"8-13\" with \"RANGE\"\n",
    "    text = re.sub(r'\\b\\d+-\\d+\\b', 'RANGE', text)\n",
    "\n",
    "    # Replace time patterns like 3:30, 1am, 2hrs, 2am, etc.\n",
    "    text = re.sub(r'(?:(\\d{1,2}:\\d{1,2})|(\\d{1,2}(?:am|pm))|(\\d{1,2}hrs))', 'time', text)\n",
    "\n",
    "    # Replace fractions or numbers like 1/2\n",
    "    text = re.sub(r'\\d{1,2}/\\d{1,2}', 'fraction', text)\n",
    "\n",
    "    # Replace year patterns like 2003\n",
    "    text = re.sub(r'\\b\\d{4}\\b', 'year', text)\n",
    "\n",
    "    # Replace amount patterns like 136k, 500k, 7million, 8.25, etc.\n",
    "    text = re.sub(r'(?:(\\d+(?:\\.\\d+)?(?:k|m|million|billion))|(\\d+\\.\\d{2}))', 'amount', text)\n",
    "\n",
    "    # Replace version patterns like 4.0\n",
    "    text = re.sub(r'\\d+\\.\\d+', 'version', text)\n",
    "\n",
    "    # Replace temperature patterns like 100.20, 971.2\n",
    "    text = re.sub(r'(?:(\\d+\\.\\d{1,2})|(\\d{2,3}\\.\\d))\\b', 'temperature', text)\n",
    "\n",
    "    # Replace time or duration patterns like 21st, 90s, 200yrs\n",
    "    text = re.sub(r'(?:(\\d{1,3}(st|nd|rd|th))|(\\d{1,2}s)|(\\d+yrs))', 'duration', text)\n",
    "\n",
    "    # Replace time patterns like 7:18, 12s, 24hr, 15minutes\n",
    "    text = re.sub(r'(?:(\\d{1,2}:\\d{1,2})|(\\d{1,2}s)|(\\d{1,2}hr)|(\\d{1,2}minutes))', 'time', text)\n",
    "\n",
    "    # Replace position patterns like 18th\n",
    "    text = re.sub(r'\\d{1,2}(st|nd|rd|th)', 'position', text)\n",
    "\n",
    "    # Replace speed patterns like 90kph\n",
    "    text = re.sub(r'\\d+kph', 'speed', text)\n",
    "\n",
    "    # Replace distance patterns like 155m\n",
    "    text = re.sub(r'\\d+m', 'distance', text)\n",
    "\n",
    "    # Replace URLs\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", 'URL', text, flags=re.MULTILINE)\n",
    "\n",
    "    # Replace standalone numbers\n",
    "    text = re.sub(r'\\b\\d+\\b', 'NUM', text)\n",
    "\n",
    "    # Replace hyphens with spaces to break into multiple tokens\n",
    "    text = text.replace(\"-\", ' ')\n",
    "\n",
    "    # Tokenize and replace tokens using replace_token function\n",
    "    tokens = text.split()\n",
    "    tokens = [replace_token(token) for token in tokens]\n",
    "    text = ' '.join(tokens)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T20:30:03.981923Z",
     "iopub.status.busy": "2024-11-19T20:30:03.981510Z",
     "iopub.status.idle": "2024-11-19T20:30:03.988448Z",
     "shell.execute_reply": "2024-11-19T20:30:03.987009Z",
     "shell.execute_reply.started": "2024-11-19T20:30:03.981843Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_dataset(file_path, text_column='text'):\n",
    "    \"\"\"\n",
    "    Load a dataset from a CSV file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        if text_column not in df.columns:\n",
    "            raise ValueError(f\"Column '{text_column}' not found in {file_path}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T20:30:04.333624Z",
     "iopub.status.busy": "2024-11-19T20:30:04.333206Z",
     "iopub.status.idle": "2024-11-19T20:30:04.339383Z",
     "shell.execute_reply": "2024-11-19T20:30:04.338106Z",
     "shell.execute_reply.started": "2024-11-19T20:30:04.333587Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess_dataset(df, text_column='text'):\n",
    "    \"\"\"\n",
    "    Apply preprocessing to the text column of the dataset.\n",
    "    \"\"\"\n",
    "    df['preprocessed_text'] = df[text_column].astype(str).apply(preprocess_text)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T20:30:04.681695Z",
     "iopub.status.busy": "2024-11-19T20:30:04.681304Z",
     "iopub.status.idle": "2024-11-19T20:30:04.687788Z",
     "shell.execute_reply": "2024-11-19T20:30:04.686356Z",
     "shell.execute_reply.started": "2024-11-19T20:30:04.681659Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def save_dataset(df, output_path):\n",
    "    \"\"\"\n",
    "    Save the preprocessed dataset to a CSV file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Preprocessed data saved to {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving to {output_path}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Headlines Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T17:14:26.582213Z",
     "iopub.status.busy": "2024-11-19T17:14:26.581877Z",
     "iopub.status.idle": "2024-11-19T17:14:32.319837Z",
     "shell.execute_reply": "2024-11-19T17:14:32.318777Z",
     "shell.execute_reply.started": "2024-11-19T17:14:26.582178Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/kaggle/input/anlp-headlines/Headlines.csv')\n",
    "processed_df = preprocess_dataset(df, text_column='headline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T17:14:32.321277Z",
     "iopub.status.busy": "2024-11-19T17:14:32.320971Z",
     "iopub.status.idle": "2024-11-19T17:14:32.340630Z",
     "shell.execute_reply": "2024-11-19T17:14:32.339542Z",
     "shell.execute_reply.started": "2024-11-19T17:14:32.321246Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess_labels(df, label_column='label'):\n",
    "    \"\"\"\n",
    "    Converts the label column to binary values: 1 for sarcastic, 0 for non-sarcastic.\n",
    "    \"\"\"\n",
    "    df['label'] = df[label_column].apply(lambda x: 1 if x.lower() == 'sarcastic' else 0)\n",
    "    return df\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "processed_df = preprocess_labels(df, label_column='label')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T17:14:32.342314Z",
     "iopub.status.busy": "2024-11-19T17:14:32.341985Z",
     "iopub.status.idle": "2024-11-19T17:14:32.498898Z",
     "shell.execute_reply": "2024-11-19T17:14:32.497177Z",
     "shell.execute_reply.started": "2024-11-19T17:14:32.342281Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Save the processed DataFrame to CSV\n",
    "output_path = '/kaggle/working/processed_news_headlines_preprocessed.csv'\n",
    "processed_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T17:14:32.503773Z",
     "iopub.status.busy": "2024-11-19T17:14:32.503277Z",
     "iopub.status.idle": "2024-11-19T17:14:32.532342Z",
     "shell.execute_reply": "2024-11-19T17:14:32.530878Z",
     "shell.execute_reply.started": "2024-11-19T17:14:32.503645Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>headline</th>\n",
       "      <th>valid</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>dateline nbc report inspired by actual events</td>\n",
       "      <td>False</td>\n",
       "      <td>dateline nbc report inspired by actual events</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>goldfish dying to be petted just once</td>\n",
       "      <td>False</td>\n",
       "      <td>goldfish dying to be petted just once</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>scalia's utter moral failure exposed</td>\n",
       "      <td>False</td>\n",
       "      <td>scalia's utter moral failure exposed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>video captures courthouse beating of inmate ac...</td>\n",
       "      <td>False</td>\n",
       "      <td>video captures courthouse beating of inmate ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>bernie sanders has a very lonely but very comm...</td>\n",
       "      <td>False</td>\n",
       "      <td>bernie sanders has a very lonely but very comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26704</th>\n",
       "      <td>0</td>\n",
       "      <td>kim kardashian channels cruella de vil, plus m...</td>\n",
       "      <td>True</td>\n",
       "      <td>kim kardashian channels cruella de vil, plus m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26705</th>\n",
       "      <td>1</td>\n",
       "      <td>students thankful standardized curriculum spar...</td>\n",
       "      <td>True</td>\n",
       "      <td>students thankful standardized curriculum spar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26706</th>\n",
       "      <td>1</td>\n",
       "      <td>mortgage market collapse threatens nation's ba...</td>\n",
       "      <td>True</td>\n",
       "      <td>mortgage market collapse threatens nation's ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26707</th>\n",
       "      <td>0</td>\n",
       "      <td>the outrageous dessert you can make in a slow ...</td>\n",
       "      <td>True</td>\n",
       "      <td>the outrageous dessert you can make in a slow ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26708</th>\n",
       "      <td>0</td>\n",
       "      <td>michelle obama hails 'black panther' for inspi...</td>\n",
       "      <td>True</td>\n",
       "      <td>michelle obama hails 'black panther' for inspi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26709 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                           headline  valid  \\\n",
       "0          1      dateline nbc report inspired by actual events  False   \n",
       "1          1              goldfish dying to be petted just once  False   \n",
       "2          0               scalia's utter moral failure exposed  False   \n",
       "3          0  video captures courthouse beating of inmate ac...  False   \n",
       "4          0  bernie sanders has a very lonely but very comm...  False   \n",
       "...      ...                                                ...    ...   \n",
       "26704      0  kim kardashian channels cruella de vil, plus m...   True   \n",
       "26705      1  students thankful standardized curriculum spar...   True   \n",
       "26706      1  mortgage market collapse threatens nation's ba...   True   \n",
       "26707      0  the outrageous dessert you can make in a slow ...   True   \n",
       "26708      0  michelle obama hails 'black panther' for inspi...   True   \n",
       "\n",
       "                                       preprocessed_text  \n",
       "0          dateline nbc report inspired by actual events  \n",
       "1                  goldfish dying to be petted just once  \n",
       "2                   scalia's utter moral failure exposed  \n",
       "3      video captures courthouse beating of inmate ac...  \n",
       "4      bernie sanders has a very lonely but very comm...  \n",
       "...                                                  ...  \n",
       "26704  kim kardashian channels cruella de vil, plus m...  \n",
       "26705  students thankful standardized curriculum spar...  \n",
       "26706  mortgage market collapse threatens nation's ba...  \n",
       "26707  the outrageous dessert you can make in a slow ...  \n",
       "26708  michelle obama hails 'black panther' for inspi...  \n",
       "\n",
       "[26709 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T17:14:32.534045Z",
     "iopub.status.busy": "2024-11-19T17:14:32.533607Z",
     "iopub.status.idle": "2024-11-19T17:14:33.180192Z",
     "shell.execute_reply": "2024-11-19T17:14:33.179030Z",
     "shell.execute_reply.started": "2024-11-19T17:14:32.534000Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T17:14:33.182004Z",
     "iopub.status.busy": "2024-11-19T17:14:33.181526Z",
     "iopub.status.idle": "2024-11-19T17:14:33.348854Z",
     "shell.execute_reply": "2024-11-19T17:14:33.347636Z",
     "shell.execute_reply.started": "2024-11-19T17:14:33.181965Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set saved to /kaggle/working/news_headlines_train.csv\n",
      "Development set saved to /kaggle/working/news_headlines_dev.csv\n",
      "Test set saved to /kaggle/working/news_headlines_test.csv\n"
     ]
    }
   ],
   "source": [
    "train, remaining = train_test_split(processed_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the remaining 20% equally into dev (10%) and test (10%)\n",
    "dev, test = train_test_split(remaining, test_size=0.5, random_state=42)\n",
    "\n",
    "# Save the splits into separate CSV files\n",
    "train_path = '/kaggle/working/news_headlines_train.csv'\n",
    "dev_path = '/kaggle/working/news_headlines_dev.csv'\n",
    "test_path = '/kaggle/working/news_headlines_test.csv'\n",
    "\n",
    "train.to_csv(train_path, index=False)\n",
    "dev.to_csv(dev_path, index=False)\n",
    "test.to_csv(test_path, index=False)\n",
    "\n",
    "print(f\"Training set saved to {train_path}\")\n",
    "print(f\"Development set saved to {dev_path}\")\n",
    "print(f\"Test set saved to {test_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T17:14:33.350504Z",
     "iopub.status.busy": "2024-11-19T17:14:33.350126Z",
     "iopub.status.idle": "2024-11-19T17:14:34.306442Z",
     "shell.execute_reply": "2024-11-19T17:14:34.305346Z",
     "shell.execute_reply.started": "2024-11-19T17:14:33.350444Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/kaggle/input/se4meval-task-3-irony-detection/SemEval2018-Task3-master/datasets/train/SemEval2018-T3-train-taskA_emoji.txt',sep='\\t')\n",
    "processed_df = preprocess_dataset(df, text_column='Tweet text')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T17:14:34.308101Z",
     "iopub.status.busy": "2024-11-19T17:14:34.307681Z",
     "iopub.status.idle": "2024-11-19T17:14:34.325776Z",
     "shell.execute_reply": "2024-11-19T17:14:34.324536Z",
     "shell.execute_reply.started": "2024-11-19T17:14:34.308060Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet index</th>\n",
       "      <th>Label</th>\n",
       "      <th>Tweet text</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sweet United Nations video. Just in time for C...</td>\n",
       "      <td>Sweet United Nations video. Just in time for C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>@mrdahl87 We are rumored to have talked to Erv...</td>\n",
       "      <td>@ALPHANUM We are rumored to have talked to Erv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Hey there! Nice to see you Minnesota/ND Winter...</td>\n",
       "      <td>Hey there! Nice to see you Minnesota/ND Winter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3 episodes left I'm dying over here</td>\n",
       "      <td>NUM episodes left I'm dying over here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>I can't breathe! was chosen as the most notabl...</td>\n",
       "      <td>I can't breathe! was chosen as the most notabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3812</th>\n",
       "      <td>3830</td>\n",
       "      <td>0</td>\n",
       "      <td>@banditelli regarding what the PSU president does</td>\n",
       "      <td>@banditelli regarding what the PSU president does</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3813</th>\n",
       "      <td>3831</td>\n",
       "      <td>0</td>\n",
       "      <td>@banditelli But still bothers me that I see no...</td>\n",
       "      <td>@banditelli But still bothers me that I see no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3814</th>\n",
       "      <td>3832</td>\n",
       "      <td>0</td>\n",
       "      <td>well now that i've listened to all of into the...</td>\n",
       "      <td>well now that i've listened to all of into the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3815</th>\n",
       "      <td>3833</td>\n",
       "      <td>0</td>\n",
       "      <td>Hummingbirds #Are  #Experts #at #Hovering #Aft...</td>\n",
       "      <td>Hummingbirds #Are #Experts #at #Hovering #Afte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3816</th>\n",
       "      <td>3834</td>\n",
       "      <td>0</td>\n",
       "      <td>Only thing missing now is a session at the gym...</td>\n",
       "      <td>Only thing missing now is a session at the gym...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3817 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Tweet index  Label                                         Tweet text  \\\n",
       "0               1      1  Sweet United Nations video. Just in time for C...   \n",
       "1               2      1  @mrdahl87 We are rumored to have talked to Erv...   \n",
       "2               3      1  Hey there! Nice to see you Minnesota/ND Winter...   \n",
       "3               4      0                3 episodes left I'm dying over here   \n",
       "4               5      1  I can't breathe! was chosen as the most notabl...   \n",
       "...           ...    ...                                                ...   \n",
       "3812         3830      0  @banditelli regarding what the PSU president does   \n",
       "3813         3831      0  @banditelli But still bothers me that I see no...   \n",
       "3814         3832      0  well now that i've listened to all of into the...   \n",
       "3815         3833      0  Hummingbirds #Are  #Experts #at #Hovering #Aft...   \n",
       "3816         3834      0  Only thing missing now is a session at the gym...   \n",
       "\n",
       "                                      preprocessed_text  \n",
       "0     Sweet United Nations video. Just in time for C...  \n",
       "1     @ALPHANUM We are rumored to have talked to Erv...  \n",
       "2     Hey there! Nice to see you Minnesota/ND Winter...  \n",
       "3                 NUM episodes left I'm dying over here  \n",
       "4     I can't breathe! was chosen as the most notabl...  \n",
       "...                                                 ...  \n",
       "3812  @banditelli regarding what the PSU president does  \n",
       "3813  @banditelli But still bothers me that I see no...  \n",
       "3814  well now that i've listened to all of into the...  \n",
       "3815  Hummingbirds #Are #Experts #at #Hovering #Afte...  \n",
       "3816  Only thing missing now is a session at the gym...  \n",
       "\n",
       "[3817 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T17:14:34.327603Z",
     "iopub.status.busy": "2024-11-19T17:14:34.327177Z",
     "iopub.status.idle": "2024-11-19T17:14:34.374635Z",
     "shell.execute_reply": "2024-11-19T17:14:34.373383Z",
     "shell.execute_reply.started": "2024-11-19T17:14:34.327567Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set saved to /kaggle/working/twitter_train.csv\n",
      "Development set saved to /kaggle/working/twitter_dev.csv\n",
      "Test set saved to /kaggle/working/twitter_test.csv\n"
     ]
    }
   ],
   "source": [
    "train, remaining = train_test_split(processed_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the remaining 20% equally into dev (10%) and test (10%)\n",
    "dev, test = train_test_split(remaining, test_size=0.5, random_state=42)\n",
    "\n",
    "# Save the splits into separate CSV files\n",
    "train_path = '/kaggle/working/twitter_train.csv'\n",
    "dev_path = '/kaggle/working/twitter_dev.csv'\n",
    "test_path = '/kaggle/working/twitter_test.csv'\n",
    "\n",
    "train.to_csv(train_path, index=False)\n",
    "dev.to_csv(dev_path, index=False)\n",
    "test.to_csv(test_path, index=False)\n",
    "\n",
    "print(f\"Training set saved to {train_path}\")\n",
    "print(f\"Development set saved to {dev_path}\")\n",
    "print(f\"Test set saved to {test_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T20:30:26.434171Z",
     "iopub.status.busy": "2024-11-19T20:30:26.433686Z",
     "iopub.status.idle": "2024-11-19T20:30:35.601266Z",
     "shell.execute_reply": "2024-11-19T20:30:35.600179Z",
     "shell.execute_reply.started": "2024-11-19T20:30:26.434130Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_reddit = pd.read_csv('/kaggle/input/sarcasm/train-balanced-sarcasm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T20:30:35.603186Z",
     "iopub.status.busy": "2024-11-19T20:30:35.602843Z",
     "iopub.status.idle": "2024-11-19T20:30:35.611490Z",
     "shell.execute_reply": "2024-11-19T20:30:35.610215Z",
     "shell.execute_reply.started": "2024-11-19T20:30:35.603154Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['label', 'comment', 'author', 'subreddit', 'score', 'ups', 'downs',\n",
       "       'date', 'created_utc', 'parent_comment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reddit.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T20:30:35.613804Z",
     "iopub.status.busy": "2024-11-19T20:30:35.613192Z",
     "iopub.status.idle": "2024-11-19T20:30:35.656708Z",
     "shell.execute_reply": "2024-11-19T20:30:35.655687Z",
     "shell.execute_reply.started": "2024-11-19T20:30:35.613768Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = df_reddit[['label', 'comment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T20:30:35.659686Z",
     "iopub.status.busy": "2024-11-19T20:30:35.659228Z",
     "iopub.status.idle": "2024-11-19T20:30:35.676367Z",
     "shell.execute_reply": "2024-11-19T20:30:35.675325Z",
     "shell.execute_reply.started": "2024-11-19T20:30:35.659637Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NC and NH.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>You do know west teams play against west teams...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>They were underdogs earlier today, but since G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>This meme isn't funny none of the \"new york ni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I could use one of those tools.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010821</th>\n",
       "      <td>1</td>\n",
       "      <td>I'm sure that Iran and N. Korea have the techn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010822</th>\n",
       "      <td>1</td>\n",
       "      <td>whatever you do, don't vote green!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010823</th>\n",
       "      <td>1</td>\n",
       "      <td>Perhaps this is an atheist conspiracy to make ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010824</th>\n",
       "      <td>1</td>\n",
       "      <td>The Slavs got their own country - it is called...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010825</th>\n",
       "      <td>1</td>\n",
       "      <td>values, as in capitalism .. there is good mone...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1010826 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                                            comment\n",
       "0            0                                         NC and NH.\n",
       "1            0  You do know west teams play against west teams...\n",
       "2            0  They were underdogs earlier today, but since G...\n",
       "3            0  This meme isn't funny none of the \"new york ni...\n",
       "4            0                    I could use one of those tools.\n",
       "...        ...                                                ...\n",
       "1010821      1  I'm sure that Iran and N. Korea have the techn...\n",
       "1010822      1                 whatever you do, don't vote green!\n",
       "1010823      1  Perhaps this is an atheist conspiracy to make ...\n",
       "1010824      1  The Slavs got their own country - it is called...\n",
       "1010825      1  values, as in capitalism .. there is good mone...\n",
       "\n",
       "[1010826 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T20:30:35.678122Z",
     "iopub.status.busy": "2024-11-19T20:30:35.677766Z",
     "iopub.status.idle": "2024-11-19T20:33:54.774669Z",
     "shell.execute_reply": "2024-11-19T20:33:54.773546Z",
     "shell.execute_reply.started": "2024-11-19T20:30:35.678088Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30/698171031.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['preprocessed_text'] = df[text_column].astype(str).apply(preprocess_text)\n"
     ]
    }
   ],
   "source": [
    "df = preprocess_dataset(df, text_column='comment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T20:33:54.777562Z",
     "iopub.status.busy": "2024-11-19T20:33:54.777115Z",
     "iopub.status.idle": "2024-11-19T20:33:54.790079Z",
     "shell.execute_reply": "2024-11-19T20:33:54.788828Z",
     "shell.execute_reply.started": "2024-11-19T20:33:54.777515Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NC and NH.</td>\n",
       "      <td>NC and NH.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>You do know west teams play against west teams...</td>\n",
       "      <td>You do know west teams play against west teams...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>They were underdogs earlier today, but since G...</td>\n",
       "      <td>They were underdogs earlier today, but since G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>This meme isn't funny none of the \"new york ni...</td>\n",
       "      <td>This meme isn't funny none of the \"new york ni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I could use one of those tools.</td>\n",
       "      <td>I could use one of those tools.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010821</th>\n",
       "      <td>1</td>\n",
       "      <td>I'm sure that Iran and N. Korea have the techn...</td>\n",
       "      <td>I'm sure that Iran and N. Korea have the techn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010822</th>\n",
       "      <td>1</td>\n",
       "      <td>whatever you do, don't vote green!</td>\n",
       "      <td>whatever you do, don't vote green!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010823</th>\n",
       "      <td>1</td>\n",
       "      <td>Perhaps this is an atheist conspiracy to make ...</td>\n",
       "      <td>Perhaps this is an atheist conspiracy to make ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010824</th>\n",
       "      <td>1</td>\n",
       "      <td>The Slavs got their own country - it is called...</td>\n",
       "      <td>The Slavs got their own country it is called K...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010825</th>\n",
       "      <td>1</td>\n",
       "      <td>values, as in capitalism .. there is good mone...</td>\n",
       "      <td>values, as in capitalism punctuation there is ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1010826 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                                            comment  \\\n",
       "0            0                                         NC and NH.   \n",
       "1            0  You do know west teams play against west teams...   \n",
       "2            0  They were underdogs earlier today, but since G...   \n",
       "3            0  This meme isn't funny none of the \"new york ni...   \n",
       "4            0                    I could use one of those tools.   \n",
       "...        ...                                                ...   \n",
       "1010821      1  I'm sure that Iran and N. Korea have the techn...   \n",
       "1010822      1                 whatever you do, don't vote green!   \n",
       "1010823      1  Perhaps this is an atheist conspiracy to make ...   \n",
       "1010824      1  The Slavs got their own country - it is called...   \n",
       "1010825      1  values, as in capitalism .. there is good mone...   \n",
       "\n",
       "                                         preprocessed_text  \n",
       "0                                               NC and NH.  \n",
       "1        You do know west teams play against west teams...  \n",
       "2        They were underdogs earlier today, but since G...  \n",
       "3        This meme isn't funny none of the \"new york ni...  \n",
       "4                          I could use one of those tools.  \n",
       "...                                                    ...  \n",
       "1010821  I'm sure that Iran and N. Korea have the techn...  \n",
       "1010822                 whatever you do, don't vote green!  \n",
       "1010823  Perhaps this is an atheist conspiracy to make ...  \n",
       "1010824  The Slavs got their own country it is called K...  \n",
       "1010825  values, as in capitalism punctuation there is ...  \n",
       "\n",
       "[1010826 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T20:37:01.252253Z",
     "iopub.status.busy": "2024-11-19T20:37:01.251799Z",
     "iopub.status.idle": "2024-11-19T20:37:06.609586Z",
     "shell.execute_reply": "2024-11-19T20:37:06.608457Z",
     "shell.execute_reply.started": "2024-11-19T20:37:01.252215Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set saved to /kaggle/working/reddit_train.csv\n",
      "Development set saved to /kaggle/working/reddit_dev.csv\n",
      "Test set saved to /kaggle/working/reddit_test.csv\n"
     ]
    }
   ],
   "source": [
    "train, remaining = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the remaining 20% equally into dev (10%) and test (10%)\n",
    "dev, test = train_test_split(remaining, test_size=0.5, random_state=42)\n",
    "\n",
    "# Save the splits into separate CSV files\n",
    "train_path = '/kaggle/working/reddit_train.csv'\n",
    "dev_path = '/kaggle/working/reddit_dev.csv'\n",
    "test_path = '/kaggle/working/reddit_test.csv'\n",
    "\n",
    "train.to_csv(train_path, index=False)\n",
    "dev.to_csv(dev_path, index=False)\n",
    "test.to_csv(test_path, index=False)\n",
    "\n",
    "print(f\"Training set saved to {train_path}\")\n",
    "print(f\"Development set saved to {dev_path}\")\n",
    "print(f\"Test set saved to {test_path}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1309,
     "sourceId": 36545,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 30764,
     "sourceId": 533474,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5832583,
     "sourceId": 9569218,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6061985,
     "sourceId": 9874300,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6063223,
     "sourceId": 9876027,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
